{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Walking the Gradient\n",
    "\n",
    "Paolo Perrotta, Programming Machine Learning: From Coding to Deep Learning (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load plot_loss_with_slices\n",
    "# Plot the loss on a dataset with two input variables, and the slices of its partial derivatives.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "def predict(X, w, b):\n",
    "    return X * w + b"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, w, b):\n",
    "    return np.average((predict(X, w, b) - Y) ** 2)\n",
    "\n",
    "def loss_gradients(X, Y, w, b):\n",
    "    w_gradient = 2 * np.average(X * (predict(X, w, b) - Y))\n",
    "    b_gradient = 2 * np.average(predict(X, w, b) - Y)\n",
    "    return (w_gradient, b_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_history(X, Y, iterations, lr, precision, initial_w, initial_b):\n",
    "    w, b = initial_w, initial_b\n",
    "\n",
    "    previous_loss = loss(X, Y, w, b)\n",
    "    history = [[w, b, previous_loss]]\n",
    "    for i in range(0, iterations):\n",
    "        print(\"Iteration %4d => Loss: %.10f\" % (i, loss(X, Y, w, b)))\n",
    "        w_gradient, b_gradient = loss_gradients(X, Y, w, b)\n",
    "        w -= lr * w_gradient\n",
    "        b -= lr * b_gradient\n",
    "\n",
    "        current_loss = loss(X, Y, w, b)\n",
    "        history.append([w, b, previous_loss])\n",
    "\n",
    "        if (abs(current_loss - previous_loss) < precision):\n",
    "            return w, b, history\n",
    "\n",
    "        previous_loss = current_loss\n",
    "\n",
    "    raise Exception(\"Couldn't converge within %d iterations\" % iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 => Loss: 812.8666666667\n",
      "Iteration    1 => Loss: 302.5769561564\n",
      "Iteration    2 => Loss: 141.9840903267\n",
      "Iteration    3 => Loss: 91.4213766211\n",
      "Iteration    4 => Loss: 75.4790576522\n",
      "Iteration    5 => Loss: 70.4298834852\n",
      "Iteration    6 => Loss: 68.8082102709\n",
      "Iteration    7 => Loss: 68.2650157314\n",
      "Iteration    8 => Loss: 68.0611933727\n",
      "Iteration    9 => Loss: 67.9641875162\n",
      "Iteration   10 => Loss: 67.9008258073\n",
      "Iteration   11 => Loss: 67.8480849450\n",
      "Iteration   12 => Loss: 67.7987207420\n",
      "Iteration   13 => Loss: 67.7504538190\n",
      "Iteration   14 => Loss: 67.7025669451\n",
      "Iteration   15 => Loss: 67.6548344110\n",
      "Iteration   16 => Loss: 67.6071851614\n",
      "Iteration   17 => Loss: 67.5595968023\n",
      "Iteration   18 => Loss: 67.5120622506\n",
      "Iteration   19 => Loss: 67.4645792410\n",
      "Iteration   20 => Loss: 67.4171470238\n",
      "Iteration   21 => Loss: 67.3697653264\n",
      "Iteration   22 => Loss: 67.3224340264\n",
      "Iteration   23 => Loss: 67.2751530484\n",
      "Iteration   24 => Loss: 67.2279223323\n",
      "Iteration   25 => Loss: 67.1807418223\n",
      "Iteration   26 => Loss: 67.1336114646\n",
      "Iteration   27 => Loss: 67.0865312055\n",
      "Iteration   28 => Loss: 67.0395009918\n",
      "Iteration   29 => Loss: 66.9925207702\n",
      "Iteration   30 => Loss: 66.9455904876\n",
      "Iteration   31 => Loss: 66.8987100909\n",
      "Iteration   32 => Loss: 66.8518795270\n",
      "Iteration   33 => Loss: 66.8050987431\n",
      "Iteration   34 => Loss: 66.7583676861\n",
      "Iteration   35 => Loss: 66.7116863032\n",
      "Iteration   36 => Loss: 66.6650545417\n",
      "Iteration   37 => Loss: 66.6184723487\n",
      "Iteration   38 => Loss: 66.5719396716\n",
      "Iteration   39 => Loss: 66.5254564578\n",
      "Iteration   40 => Loss: 66.4790226546\n",
      "Iteration   41 => Loss: 66.4326382096\n",
      "Iteration   42 => Loss: 66.3863030702\n",
      "Iteration   43 => Loss: 66.3400171842\n",
      "Iteration   44 => Loss: 66.2937804990\n",
      "Iteration   45 => Loss: 66.2475929625\n",
      "Iteration   46 => Loss: 66.2014545223\n",
      "Iteration   47 => Loss: 66.1553651263\n",
      "Iteration   48 => Loss: 66.1093247223\n",
      "Iteration   49 => Loss: 66.0633332584\n",
      "Iteration   50 => Loss: 66.0173906823\n",
      "Iteration   51 => Loss: 65.9714969423\n",
      "Iteration   52 => Loss: 65.9256519863\n",
      "Iteration   53 => Loss: 65.8798557626\n",
      "Iteration   54 => Loss: 65.8341082192\n",
      "Iteration   55 => Loss: 65.7884093045\n",
      "Iteration   56 => Loss: 65.7427589668\n",
      "Iteration   57 => Loss: 65.6971571545\n",
      "Iteration   58 => Loss: 65.6516038159\n",
      "Iteration   59 => Loss: 65.6060988995\n",
      "Iteration   60 => Loss: 65.5606423539\n",
      "Iteration   61 => Loss: 65.5152341276\n",
      "Iteration   62 => Loss: 65.4698741693\n",
      "Iteration   63 => Loss: 65.4245624277\n",
      "Iteration   64 => Loss: 65.3792988515\n",
      "Iteration   65 => Loss: 65.3340833895\n",
      "Iteration   66 => Loss: 65.2889159906\n",
      "Iteration   67 => Loss: 65.2437966037\n",
      "Iteration   68 => Loss: 65.1987251777\n",
      "Iteration   69 => Loss: 65.1537016617\n",
      "Iteration   70 => Loss: 65.1087260047\n",
      "Iteration   71 => Loss: 65.0637981559\n",
      "Iteration   72 => Loss: 65.0189180645\n",
      "Iteration   73 => Loss: 64.9740856796\n",
      "Iteration   74 => Loss: 64.9293009507\n",
      "Iteration   75 => Loss: 64.8845638269\n",
      "Iteration   76 => Loss: 64.8398742577\n",
      "Iteration   77 => Loss: 64.7952321926\n",
      "Iteration   78 => Loss: 64.7506375811\n",
      "Iteration   79 => Loss: 64.7060903727\n",
      "Iteration   80 => Loss: 64.6615905170\n",
      "Iteration   81 => Loss: 64.6171379637\n",
      "Iteration   82 => Loss: 64.5727326626\n",
      "Iteration   83 => Loss: 64.5283745633\n",
      "Iteration   84 => Loss: 64.4840636158\n",
      "Iteration   85 => Loss: 64.4397997699\n",
      "Iteration   86 => Loss: 64.3955829754\n",
      "Iteration   87 => Loss: 64.3514131825\n",
      "Iteration   88 => Loss: 64.3072903412\n",
      "Iteration   89 => Loss: 64.2632144015\n",
      "Iteration   90 => Loss: 64.2191853136\n",
      "Iteration   91 => Loss: 64.1752030276\n",
      "Iteration   92 => Loss: 64.1312674939\n",
      "Iteration   93 => Loss: 64.0873786628\n",
      "Iteration   94 => Loss: 64.0435364845\n",
      "Iteration   95 => Loss: 63.9997409096\n",
      "Iteration   96 => Loss: 63.9559918884\n",
      "Iteration   97 => Loss: 63.9122893714\n",
      "Iteration   98 => Loss: 63.8686333094\n",
      "Iteration   99 => Loss: 63.8250236528\n",
      "Iteration  100 => Loss: 63.7814603523\n",
      "Iteration  101 => Loss: 63.7379433587\n",
      "Iteration  102 => Loss: 63.6944726228\n",
      "Iteration  103 => Loss: 63.6510480953\n",
      "Iteration  104 => Loss: 63.6076697271\n",
      "Iteration  105 => Loss: 63.5643374693\n",
      "Iteration  106 => Loss: 63.5210512727\n",
      "Iteration  107 => Loss: 63.4778110884\n",
      "Iteration  108 => Loss: 63.4346168675\n",
      "Iteration  109 => Loss: 63.3914685612\n",
      "Iteration  110 => Loss: 63.3483661206\n",
      "Iteration  111 => Loss: 63.3053094970\n",
      "Iteration  112 => Loss: 63.2622986416\n",
      "Iteration  113 => Loss: 63.2193335059\n",
      "Iteration  114 => Loss: 63.1764140412\n",
      "Iteration  115 => Loss: 63.1335401990\n",
      "Iteration  116 => Loss: 63.0907119307\n",
      "Iteration  117 => Loss: 63.0479291880\n",
      "Iteration  118 => Loss: 63.0051919225\n",
      "Iteration  119 => Loss: 62.9625000857\n",
      "Iteration  120 => Loss: 62.9198536295\n",
      "Iteration  121 => Loss: 62.8772525055\n",
      "Iteration  122 => Loss: 62.8346966657\n",
      "Iteration  123 => Loss: 62.7921860618\n",
      "Iteration  124 => Loss: 62.7497206457\n",
      "Iteration  125 => Loss: 62.7073003695\n",
      "Iteration  126 => Loss: 62.6649251852\n",
      "Iteration  127 => Loss: 62.6225950447\n",
      "Iteration  128 => Loss: 62.5803099003\n",
      "Iteration  129 => Loss: 62.5380697042\n",
      "Iteration  130 => Loss: 62.4958744084\n",
      "Iteration  131 => Loss: 62.4537239654\n",
      "Iteration  132 => Loss: 62.4116183273\n",
      "Iteration  133 => Loss: 62.3695574467\n",
      "Iteration  134 => Loss: 62.3275412759\n",
      "Iteration  135 => Loss: 62.2855697674\n",
      "Iteration  136 => Loss: 62.2436428737\n",
      "Iteration  137 => Loss: 62.2017605474\n",
      "Iteration  138 => Loss: 62.1599227412\n",
      "Iteration  139 => Loss: 62.1181294076\n",
      "Iteration  140 => Loss: 62.0763804995\n",
      "Iteration  141 => Loss: 62.0346759695\n",
      "Iteration  142 => Loss: 61.9930157706\n",
      "Iteration  143 => Loss: 61.9513998556\n",
      "Iteration  144 => Loss: 61.9098281775\n",
      "Iteration  145 => Loss: 61.8683006891\n",
      "Iteration  146 => Loss: 61.8268173436\n",
      "Iteration  147 => Loss: 61.7853780940\n",
      "Iteration  148 => Loss: 61.7439828935\n",
      "Iteration  149 => Loss: 61.7026316951\n",
      "Iteration  150 => Loss: 61.6613244522\n",
      "Iteration  151 => Loss: 61.6200611181\n",
      "Iteration  152 => Loss: 61.5788416459\n",
      "Iteration  153 => Loss: 61.5376659892\n",
      "Iteration  154 => Loss: 61.4965341014\n",
      "Iteration  155 => Loss: 61.4554459358\n",
      "Iteration  156 => Loss: 61.4144014462\n",
      "Iteration  157 => Loss: 61.3734005859\n",
      "Iteration  158 => Loss: 61.3324433087\n",
      "Iteration  159 => Loss: 61.2915295682\n",
      "Iteration  160 => Loss: 61.2506593181\n",
      "Iteration  161 => Loss: 61.2098325123\n",
      "Iteration  162 => Loss: 61.1690491044\n",
      "Iteration  163 => Loss: 61.1283090485\n",
      "Iteration  164 => Loss: 61.0876122984\n",
      "Iteration  165 => Loss: 61.0469588080\n",
      "Iteration  166 => Loss: 61.0063485315\n",
      "Iteration  167 => Loss: 60.9657814228\n",
      "Iteration  168 => Loss: 60.9252574361\n",
      "Iteration  169 => Loss: 60.8847765255\n",
      "Iteration  170 => Loss: 60.8443386453\n",
      "Iteration  171 => Loss: 60.8039437497\n",
      "Iteration  172 => Loss: 60.7635917930\n",
      "Iteration  173 => Loss: 60.7232827296\n",
      "Iteration  174 => Loss: 60.6830165138\n",
      "Iteration  175 => Loss: 60.6427931002\n",
      "Iteration  176 => Loss: 60.6026124432\n",
      "Iteration  177 => Loss: 60.5624744975\n",
      "Iteration  178 => Loss: 60.5223792174\n",
      "Iteration  179 => Loss: 60.4823265579\n",
      "Iteration  180 => Loss: 60.4423164734\n",
      "Iteration  181 => Loss: 60.4023489188\n",
      "Iteration  182 => Loss: 60.3624238489\n",
      "Iteration  183 => Loss: 60.3225412185\n",
      "Iteration  184 => Loss: 60.2827009825\n",
      "Iteration  185 => Loss: 60.2429030957\n",
      "Iteration  186 => Loss: 60.2031475133\n",
      "Iteration  187 => Loss: 60.1634341903\n",
      "Iteration  188 => Loss: 60.1237630816\n",
      "Iteration  189 => Loss: 60.0841341425\n",
      "Iteration  190 => Loss: 60.0445473282\n",
      "Iteration  191 => Loss: 60.0050025937\n",
      "Iteration  192 => Loss: 59.9654998945\n",
      "Iteration  193 => Loss: 59.9260391858\n",
      "Iteration  194 => Loss: 59.8866204230\n",
      "Iteration  195 => Loss: 59.8472435616\n",
      "Iteration  196 => Loss: 59.8079085568\n",
      "Iteration  197 => Loss: 59.7686153644\n",
      "Iteration  198 => Loss: 59.7293639398\n",
      "Iteration  199 => Loss: 59.6901542386\n",
      "Iteration  200 => Loss: 59.6509862165\n",
      "Iteration  201 => Loss: 59.6118598292\n",
      "Iteration  202 => Loss: 59.5727750323\n",
      "Iteration  203 => Loss: 59.5337317818\n",
      "Iteration  204 => Loss: 59.4947300335\n",
      "Iteration  205 => Loss: 59.4557697432\n",
      "Iteration  206 => Loss: 59.4168508668\n",
      "Iteration  207 => Loss: 59.3779733604\n",
      "Iteration  208 => Loss: 59.3391371799\n",
      "Iteration  209 => Loss: 59.3003422815\n",
      "Iteration  210 => Loss: 59.2615886212\n",
      "Iteration  211 => Loss: 59.2228761552\n",
      "Iteration  212 => Loss: 59.1842048398\n",
      "Iteration  213 => Loss: 59.1455746312\n",
      "Iteration  214 => Loss: 59.1069854856\n",
      "Iteration  215 => Loss: 59.0684373595\n",
      "Iteration  216 => Loss: 59.0299302092\n",
      "Iteration  217 => Loss: 58.9914639913\n",
      "Iteration  218 => Loss: 58.9530386620\n",
      "Iteration  219 => Loss: 58.9146541781\n",
      "Iteration  220 => Loss: 58.8763104961\n",
      "Iteration  221 => Loss: 58.8380075726\n",
      "Iteration  222 => Loss: 58.7997453643\n",
      "Iteration  223 => Loss: 58.7615238279\n",
      "Iteration  224 => Loss: 58.7233429202\n",
      "Iteration  225 => Loss: 58.6852025980\n",
      "Iteration  226 => Loss: 58.6471028182\n",
      "Iteration  227 => Loss: 58.6090435376\n",
      "Iteration  228 => Loss: 58.5710247132\n",
      "Iteration  229 => Loss: 58.5330463020\n",
      "Iteration  230 => Loss: 58.4951082610\n",
      "Iteration  231 => Loss: 58.4572105474\n",
      "Iteration  232 => Loss: 58.4193531183\n",
      "Iteration  233 => Loss: 58.3815359308\n",
      "Iteration  234 => Loss: 58.3437589421\n",
      "Iteration  235 => Loss: 58.3060221096\n",
      "Iteration  236 => Loss: 58.2683253906\n",
      "Iteration  237 => Loss: 58.2306687423\n",
      "Iteration  238 => Loss: 58.1930521223\n",
      "Iteration  239 => Loss: 58.1554754879\n",
      "Iteration  240 => Loss: 58.1179387967\n",
      "Iteration  241 => Loss: 58.0804420063\n",
      "Iteration  242 => Loss: 58.0429850741\n",
      "Iteration  243 => Loss: 58.0055679578\n",
      "Iteration  244 => Loss: 57.9681906151\n",
      "Iteration  245 => Loss: 57.9308530038\n",
      "Iteration  246 => Loss: 57.8935550815\n",
      "Iteration  247 => Loss: 57.8562968061\n",
      "Iteration  248 => Loss: 57.8190781355\n",
      "Iteration  249 => Loss: 57.7818990276\n",
      "Iteration  250 => Loss: 57.7447594402\n",
      "Iteration  251 => Loss: 57.7076593315\n",
      "Iteration  252 => Loss: 57.6705986593\n",
      "Iteration  253 => Loss: 57.6335773819\n",
      "Iteration  254 => Loss: 57.5965954573\n",
      "Iteration  255 => Loss: 57.5596528437\n",
      "Iteration  256 => Loss: 57.5227494993\n",
      "Iteration  257 => Loss: 57.4858853824\n",
      "Iteration  258 => Loss: 57.4490604513\n",
      "Iteration  259 => Loss: 57.4122746643\n",
      "Iteration  260 => Loss: 57.3755279798\n",
      "Iteration  261 => Loss: 57.3388203562\n",
      "Iteration  262 => Loss: 57.3021517521\n",
      "Iteration  263 => Loss: 57.2655221259\n",
      "Iteration  264 => Loss: 57.2289314362\n",
      "Iteration  265 => Loss: 57.1923796417\n",
      "Iteration  266 => Loss: 57.1558667009\n",
      "Iteration  267 => Loss: 57.1193925726\n",
      "Iteration  268 => Loss: 57.0829572156\n",
      "Iteration  269 => Loss: 57.0465605885\n",
      "Iteration  270 => Loss: 57.0102026503\n",
      "Iteration  271 => Loss: 56.9738833598\n",
      "Iteration  272 => Loss: 56.9376026760\n",
      "Iteration  273 => Loss: 56.9013605577\n",
      "Iteration  274 => Loss: 56.8651569640\n",
      "Iteration  275 => Loss: 56.8289918540\n",
      "Iteration  276 => Loss: 56.7928651868\n",
      "Iteration  277 => Loss: 56.7567769214\n",
      "Iteration  278 => Loss: 56.7207270170\n",
      "Iteration  279 => Loss: 56.6847154330\n",
      "Iteration  280 => Loss: 56.6487421285\n",
      "Iteration  281 => Loss: 56.6128070629\n",
      "Iteration  282 => Loss: 56.5769101954\n",
      "Iteration  283 => Loss: 56.5410514856\n",
      "Iteration  284 => Loss: 56.5052308929\n",
      "Iteration  285 => Loss: 56.4694483766\n",
      "Iteration  286 => Loss: 56.4337038964\n",
      "Iteration  287 => Loss: 56.3979974119\n",
      "Iteration  288 => Loss: 56.3623288825\n",
      "Iteration  289 => Loss: 56.3266982681\n",
      "Iteration  290 => Loss: 56.2911055282\n",
      "Iteration  291 => Loss: 56.2555506227\n",
      "Iteration  292 => Loss: 56.2200335113\n",
      "Iteration  293 => Loss: 56.1845541538\n",
      "Iteration  294 => Loss: 56.1491125101\n",
      "Iteration  295 => Loss: 56.1137085402\n",
      "Iteration  296 => Loss: 56.0783422039\n",
      "Iteration  297 => Loss: 56.0430134612\n",
      "Iteration  298 => Loss: 56.0077222723\n",
      "Iteration  299 => Loss: 55.9724685972\n",
      "Iteration  300 => Loss: 55.9372523959\n",
      "Iteration  301 => Loss: 55.9020736288\n",
      "Iteration  302 => Loss: 55.8669322559\n",
      "Iteration  303 => Loss: 55.8318282375\n",
      "Iteration  304 => Loss: 55.7967615340\n",
      "Iteration  305 => Loss: 55.7617321056\n",
      "Iteration  306 => Loss: 55.7267399128\n",
      "Iteration  307 => Loss: 55.6917849159\n",
      "Iteration  308 => Loss: 55.6568670755\n",
      "Iteration  309 => Loss: 55.6219863520\n",
      "Iteration  310 => Loss: 55.5871427059\n",
      "Iteration  311 => Loss: 55.5523360979\n",
      "Iteration  312 => Loss: 55.5175664886\n",
      "Iteration  313 => Loss: 55.4828338386\n",
      "Iteration  314 => Loss: 55.4481381087\n",
      "Iteration  315 => Loss: 55.4134792597\n",
      "Iteration  316 => Loss: 55.3788572522\n",
      "Iteration  317 => Loss: 55.3442720472\n",
      "Iteration  318 => Loss: 55.3097236056\n",
      "Iteration  319 => Loss: 55.2752118882\n",
      "Iteration  320 => Loss: 55.2407368560\n",
      "Iteration  321 => Loss: 55.2062984701\n",
      "Iteration  322 => Loss: 55.1718966914\n",
      "Iteration  323 => Loss: 55.1375314811\n",
      "Iteration  324 => Loss: 55.1032028003\n",
      "Iteration  325 => Loss: 55.0689106101\n",
      "Iteration  326 => Loss: 55.0346548718\n",
      "Iteration  327 => Loss: 55.0004355467\n",
      "Iteration  328 => Loss: 54.9662525959\n",
      "Iteration  329 => Loss: 54.9321059809\n",
      "Iteration  330 => Loss: 54.8979956630\n",
      "Iteration  331 => Loss: 54.8639216037\n",
      "Iteration  332 => Loss: 54.8298837644\n",
      "Iteration  333 => Loss: 54.7958821065\n",
      "Iteration  334 => Loss: 54.7619165918\n",
      "Iteration  335 => Loss: 54.7279871816\n",
      "Iteration  336 => Loss: 54.6940938377\n",
      "Iteration  337 => Loss: 54.6602365216\n",
      "Iteration  338 => Loss: 54.6264151952\n",
      "Iteration  339 => Loss: 54.5926298202\n",
      "Iteration  340 => Loss: 54.5588803582\n",
      "Iteration  341 => Loss: 54.5251667713\n",
      "Iteration  342 => Loss: 54.4914890211\n",
      "Iteration  343 => Loss: 54.4578470697\n",
      "Iteration  344 => Loss: 54.4242408790\n",
      "Iteration  345 => Loss: 54.3906704109\n",
      "Iteration  346 => Loss: 54.3571356276\n",
      "Iteration  347 => Loss: 54.3236364910\n",
      "Iteration  348 => Loss: 54.2901729632\n",
      "Iteration  349 => Loss: 54.2567450065\n",
      "Iteration  350 => Loss: 54.2233525830\n",
      "Iteration  351 => Loss: 54.1899956549\n",
      "Iteration  352 => Loss: 54.1566741846\n",
      "Iteration  353 => Loss: 54.1233881342\n",
      "Iteration  354 => Loss: 54.0901374662\n",
      "Iteration  355 => Loss: 54.0569221430\n",
      "Iteration  356 => Loss: 54.0237421270\n",
      "Iteration  357 => Loss: 53.9905973806\n",
      "Iteration  358 => Loss: 53.9574878663\n",
      "Iteration  359 => Loss: 53.9244135468\n",
      "Iteration  360 => Loss: 53.8913743846\n",
      "Iteration  361 => Loss: 53.8583703423\n",
      "Iteration  362 => Loss: 53.8254013826\n",
      "Iteration  363 => Loss: 53.7924674682\n",
      "Iteration  364 => Loss: 53.7595685618\n",
      "Iteration  365 => Loss: 53.7267046263\n",
      "Iteration  366 => Loss: 53.6938756245\n",
      "Iteration  367 => Loss: 53.6610815192\n",
      "Iteration  368 => Loss: 53.6283222733\n",
      "Iteration  369 => Loss: 53.5955978498\n",
      "Iteration  370 => Loss: 53.5629082117\n",
      "Iteration  371 => Loss: 53.5302533220\n",
      "Iteration  372 => Loss: 53.4976331437\n",
      "Iteration  373 => Loss: 53.4650476400\n",
      "Iteration  374 => Loss: 53.4324967739\n",
      "Iteration  375 => Loss: 53.3999805088\n",
      "Iteration  376 => Loss: 53.3674988078\n",
      "Iteration  377 => Loss: 53.3350516341\n",
      "Iteration  378 => Loss: 53.3026389510\n",
      "Iteration  379 => Loss: 53.2702607220\n",
      "Iteration  380 => Loss: 53.2379169103\n",
      "Iteration  381 => Loss: 53.2056074795\n",
      "Iteration  382 => Loss: 53.1733323928\n",
      "Iteration  383 => Loss: 53.1410916139\n",
      "Iteration  384 => Loss: 53.1088851063\n",
      "Iteration  385 => Loss: 53.0767128334\n",
      "Iteration  386 => Loss: 53.0445747591\n",
      "Iteration  387 => Loss: 53.0124708468\n",
      "Iteration  388 => Loss: 52.9804010603\n",
      "Iteration  389 => Loss: 52.9483653633\n",
      "Iteration  390 => Loss: 52.9163637195\n",
      "Iteration  391 => Loss: 52.8843960929\n",
      "Iteration  392 => Loss: 52.8524624471\n",
      "Iteration  393 => Loss: 52.8205627461\n",
      "Iteration  394 => Loss: 52.7886969539\n",
      "Iteration  395 => Loss: 52.7568650342\n",
      "Iteration  396 => Loss: 52.7250669513\n",
      "Iteration  397 => Loss: 52.6933026690\n",
      "Iteration  398 => Loss: 52.6615721515\n",
      "Iteration  399 => Loss: 52.6298753629\n",
      "Iteration  400 => Loss: 52.5982122672\n",
      "Iteration  401 => Loss: 52.5665828288\n",
      "Iteration  402 => Loss: 52.5349870118\n",
      "Iteration  403 => Loss: 52.5034247805\n",
      "Iteration  404 => Loss: 52.4718960991\n",
      "Iteration  405 => Loss: 52.4404009321\n",
      "Iteration  406 => Loss: 52.4089392437\n",
      "Iteration  407 => Loss: 52.3775109985\n",
      "Iteration  408 => Loss: 52.3461161608\n",
      "Iteration  409 => Loss: 52.3147546952\n",
      "Iteration  410 => Loss: 52.2834265661\n",
      "Iteration  411 => Loss: 52.2521317382\n",
      "Iteration  412 => Loss: 52.2208701760\n",
      "Iteration  413 => Loss: 52.1896418442\n",
      "Iteration  414 => Loss: 52.1584467075\n",
      "Iteration  415 => Loss: 52.1272847305\n",
      "Iteration  416 => Loss: 52.0961558780\n",
      "Iteration  417 => Loss: 52.0650601149\n",
      "Iteration  418 => Loss: 52.0339974059\n",
      "Iteration  419 => Loss: 52.0029677158\n",
      "Iteration  420 => Loss: 51.9719710097\n",
      "Iteration  421 => Loss: 51.9410072524\n",
      "Iteration  422 => Loss: 51.9100764090\n",
      "Iteration  423 => Loss: 51.8791784443\n",
      "Iteration  424 => Loss: 51.8483133236\n",
      "Iteration  425 => Loss: 51.8174810118\n",
      "Iteration  426 => Loss: 51.7866814741\n",
      "Iteration  427 => Loss: 51.7559146757\n",
      "Iteration  428 => Loss: 51.7251805817\n",
      "Iteration  429 => Loss: 51.6944791574\n",
      "Iteration  430 => Loss: 51.6638103680\n",
      "Iteration  431 => Loss: 51.6331741790\n",
      "Iteration  432 => Loss: 51.6025705555\n",
      "Iteration  433 => Loss: 51.5719994631\n",
      "Iteration  434 => Loss: 51.5414608671\n",
      "Iteration  435 => Loss: 51.5109547329\n",
      "Iteration  436 => Loss: 51.4804810261\n",
      "Iteration  437 => Loss: 51.4500397123\n",
      "Iteration  438 => Loss: 51.4196307569\n",
      "Iteration  439 => Loss: 51.3892541256\n",
      "Iteration  440 => Loss: 51.3589097839\n",
      "Iteration  441 => Loss: 51.3285976977\n",
      "Iteration  442 => Loss: 51.2983178326\n",
      "Iteration  443 => Loss: 51.2680701543\n",
      "Iteration  444 => Loss: 51.2378546287\n",
      "Iteration  445 => Loss: 51.2076712216\n",
      "Iteration  446 => Loss: 51.1775198987\n",
      "Iteration  447 => Loss: 51.1474006261\n",
      "Iteration  448 => Loss: 51.1173133696\n",
      "Iteration  449 => Loss: 51.0872580953\n",
      "Iteration  450 => Loss: 51.0572347690\n",
      "Iteration  451 => Loss: 51.0272433569\n",
      "Iteration  452 => Loss: 50.9972838251\n",
      "Iteration  453 => Loss: 50.9673561396\n",
      "Iteration  454 => Loss: 50.9374602666\n",
      "Iteration  455 => Loss: 50.9075961722\n",
      "Iteration  456 => Loss: 50.8777638228\n",
      "Iteration  457 => Loss: 50.8479631845\n",
      "Iteration  458 => Loss: 50.8181942237\n",
      "Iteration  459 => Loss: 50.7884569066\n",
      "Iteration  460 => Loss: 50.7587511997\n",
      "Iteration  461 => Loss: 50.7290770693\n",
      "Iteration  462 => Loss: 50.6994344819\n",
      "Iteration  463 => Loss: 50.6698234039\n",
      "Iteration  464 => Loss: 50.6402438018\n",
      "Iteration  465 => Loss: 50.6106956423\n",
      "Iteration  466 => Loss: 50.5811788918\n",
      "Iteration  467 => Loss: 50.5516935170\n",
      "Iteration  468 => Loss: 50.5222394845\n",
      "Iteration  469 => Loss: 50.4928167611\n",
      "Iteration  470 => Loss: 50.4634253133\n",
      "Iteration  471 => Loss: 50.4340651081\n",
      "Iteration  472 => Loss: 50.4047361121\n",
      "Iteration  473 => Loss: 50.3754382922\n",
      "Iteration  474 => Loss: 50.3461716153\n",
      "Iteration  475 => Loss: 50.3169360483\n",
      "Iteration  476 => Loss: 50.2877315580\n",
      "Iteration  477 => Loss: 50.2585581115\n",
      "Iteration  478 => Loss: 50.2294156757\n",
      "Iteration  479 => Loss: 50.2003042177\n",
      "Iteration  480 => Loss: 50.1712237046\n",
      "Iteration  481 => Loss: 50.1421741035\n",
      "Iteration  482 => Loss: 50.1131553814\n",
      "Iteration  483 => Loss: 50.0841675057\n",
      "Iteration  484 => Loss: 50.0552104434\n",
      "Iteration  485 => Loss: 50.0262841619\n",
      "Iteration  486 => Loss: 49.9973886284\n",
      "Iteration  487 => Loss: 49.9685238103\n",
      "Iteration  488 => Loss: 49.9396896748\n",
      "Iteration  489 => Loss: 49.9108861894\n",
      "Iteration  490 => Loss: 49.8821133215\n",
      "Iteration  491 => Loss: 49.8533710386\n",
      "Iteration  492 => Loss: 49.8246593081\n",
      "Iteration  493 => Loss: 49.7959780975\n",
      "Iteration  494 => Loss: 49.7673273745\n",
      "Iteration  495 => Loss: 49.7387071065\n",
      "Iteration  496 => Loss: 49.7101172614\n",
      "Iteration  497 => Loss: 49.6815578066\n",
      "Iteration  498 => Loss: 49.6530287099\n",
      "Iteration  499 => Loss: 49.6245299390\n",
      "Iteration  500 => Loss: 49.5960614617\n",
      "Iteration  501 => Loss: 49.5676232458\n",
      "Iteration  502 => Loss: 49.5392152591\n",
      "Iteration  503 => Loss: 49.5108374695\n",
      "Iteration  504 => Loss: 49.4824898449\n",
      "Iteration  505 => Loss: 49.4541723532\n",
      "Iteration  506 => Loss: 49.4258849625\n",
      "Iteration  507 => Loss: 49.3976276406\n",
      "Iteration  508 => Loss: 49.3694003556\n",
      "Iteration  509 => Loss: 49.3412030756\n",
      "Iteration  510 => Loss: 49.3130357688\n",
      "Iteration  511 => Loss: 49.2848984032\n",
      "Iteration  512 => Loss: 49.2567909470\n",
      "Iteration  513 => Loss: 49.2287133685\n",
      "Iteration  514 => Loss: 49.2006656358\n",
      "Iteration  515 => Loss: 49.1726477172\n",
      "Iteration  516 => Loss: 49.1446595812\n",
      "Iteration  517 => Loss: 49.1167011959\n",
      "Iteration  518 => Loss: 49.0887725298\n",
      "Iteration  519 => Loss: 49.0608735512\n",
      "Iteration  520 => Loss: 49.0330042287\n",
      "Iteration  521 => Loss: 49.0051645307\n",
      "Iteration  522 => Loss: 48.9773544257\n",
      "Iteration  523 => Loss: 48.9495738822\n",
      "Iteration  524 => Loss: 48.9218228689\n",
      "Iteration  525 => Loss: 48.8941013543\n",
      "Iteration  526 => Loss: 48.8664093071\n",
      "Iteration  527 => Loss: 48.8387466959\n",
      "Iteration  528 => Loss: 48.8111134895\n",
      "Iteration  529 => Loss: 48.7835096566\n",
      "Iteration  530 => Loss: 48.7559351660\n",
      "Iteration  531 => Loss: 48.7283899866\n",
      "Iteration  532 => Loss: 48.7008740870\n",
      "Iteration  533 => Loss: 48.6733874363\n",
      "Iteration  534 => Loss: 48.6459300033\n",
      "Iteration  535 => Loss: 48.6185017569\n",
      "Iteration  536 => Loss: 48.5911026662\n",
      "Iteration  537 => Loss: 48.5637327002\n",
      "Iteration  538 => Loss: 48.5363918278\n",
      "Iteration  539 => Loss: 48.5090800182\n",
      "Iteration  540 => Loss: 48.4817972405\n",
      "Iteration  541 => Loss: 48.4545434638\n",
      "Iteration  542 => Loss: 48.4273186573\n",
      "Iteration  543 => Loss: 48.4001227902\n",
      "Iteration  544 => Loss: 48.3729558317\n",
      "Iteration  545 => Loss: 48.3458177511\n",
      "Iteration  546 => Loss: 48.3187085177\n",
      "Iteration  547 => Loss: 48.2916281008\n",
      "Iteration  548 => Loss: 48.2645764699\n",
      "Iteration  549 => Loss: 48.2375535943\n",
      "Iteration  550 => Loss: 48.2105594434\n",
      "Iteration  551 => Loss: 48.1835939867\n",
      "Iteration  552 => Loss: 48.1566571937\n",
      "Iteration  553 => Loss: 48.1297490340\n",
      "Iteration  554 => Loss: 48.1028694770\n",
      "Iteration  555 => Loss: 48.0760184925\n",
      "Iteration  556 => Loss: 48.0491960500\n",
      "Iteration  557 => Loss: 48.0224021192\n",
      "Iteration  558 => Loss: 47.9956366697\n",
      "Iteration  559 => Loss: 47.9688996714\n",
      "Iteration  560 => Loss: 47.9421910939\n",
      "Iteration  561 => Loss: 47.9155109071\n",
      "Iteration  562 => Loss: 47.8888590807\n",
      "Iteration  563 => Loss: 47.8622355847\n",
      "Iteration  564 => Loss: 47.8356403889\n",
      "Iteration  565 => Loss: 47.8090734632\n",
      "Iteration  566 => Loss: 47.7825347776\n",
      "Iteration  567 => Loss: 47.7560243020\n",
      "Iteration  568 => Loss: 47.7295420065\n",
      "Iteration  569 => Loss: 47.7030878611\n",
      "Iteration  570 => Loss: 47.6766618360\n",
      "Iteration  571 => Loss: 47.6502639011\n",
      "Iteration  572 => Loss: 47.6238940267\n",
      "Iteration  573 => Loss: 47.5975521829\n",
      "Iteration  574 => Loss: 47.5712383399\n",
      "Iteration  575 => Loss: 47.5449524680\n",
      "Iteration  576 => Loss: 47.5186945373\n",
      "Iteration  577 => Loss: 47.4924645184\n",
      "Iteration  578 => Loss: 47.4662623813\n",
      "Iteration  579 => Loss: 47.4400880966\n",
      "Iteration  580 => Loss: 47.4139416346\n",
      "Iteration  581 => Loss: 47.3878229657\n",
      "Iteration  582 => Loss: 47.3617320604\n",
      "Iteration  583 => Loss: 47.3356688892\n",
      "Iteration  584 => Loss: 47.3096334226\n",
      "Iteration  585 => Loss: 47.2836256312\n",
      "Iteration  586 => Loss: 47.2576454854\n",
      "Iteration  587 => Loss: 47.2316929561\n",
      "Iteration  588 => Loss: 47.2057680136\n",
      "Iteration  589 => Loss: 47.1798706289\n",
      "Iteration  590 => Loss: 47.1540007725\n",
      "Iteration  591 => Loss: 47.1281584153\n",
      "Iteration  592 => Loss: 47.1023435279\n",
      "Iteration  593 => Loss: 47.0765560812\n",
      "Iteration  594 => Loss: 47.0507960460\n",
      "Iteration  595 => Loss: 47.0250633932\n",
      "Iteration  596 => Loss: 46.9993580936\n",
      "Iteration  597 => Loss: 46.9736801182\n",
      "Iteration  598 => Loss: 46.9480294380\n",
      "Iteration  599 => Loss: 46.9224060239\n",
      "Iteration  600 => Loss: 46.8968098469\n",
      "Iteration  601 => Loss: 46.8712408782\n",
      "Iteration  602 => Loss: 46.8456990887\n",
      "Iteration  603 => Loss: 46.8201844495\n",
      "Iteration  604 => Loss: 46.7946969319\n",
      "Iteration  605 => Loss: 46.7692365070\n",
      "Iteration  606 => Loss: 46.7438031460\n",
      "Iteration  607 => Loss: 46.7183968201\n",
      "Iteration  608 => Loss: 46.6930175006\n",
      "Iteration  609 => Loss: 46.6676651588\n",
      "Iteration  610 => Loss: 46.6423397659\n",
      "Iteration  611 => Loss: 46.6170412935\n",
      "Iteration  612 => Loss: 46.5917697127\n",
      "Iteration  613 => Loss: 46.5665249951\n",
      "Iteration  614 => Loss: 46.5413071121\n",
      "Iteration  615 => Loss: 46.5161160352\n",
      "Iteration  616 => Loss: 46.4909517359\n",
      "Iteration  617 => Loss: 46.4658141857\n",
      "Iteration  618 => Loss: 46.4407033561\n",
      "Iteration  619 => Loss: 46.4156192189\n",
      "Iteration  620 => Loss: 46.3905617455\n",
      "Iteration  621 => Loss: 46.3655309077\n",
      "Iteration  622 => Loss: 46.3405266772\n",
      "Iteration  623 => Loss: 46.3155490256\n",
      "Iteration  624 => Loss: 46.2905979248\n",
      "Iteration  625 => Loss: 46.2656733464\n",
      "Iteration  626 => Loss: 46.2407752623\n",
      "Iteration  627 => Loss: 46.2159036444\n",
      "Iteration  628 => Loss: 46.1910584644\n",
      "Iteration  629 => Loss: 46.1662396944\n",
      "Iteration  630 => Loss: 46.1414473062\n",
      "Iteration  631 => Loss: 46.1166812717\n",
      "Iteration  632 => Loss: 46.0919415631\n",
      "Iteration  633 => Loss: 46.0672281522\n",
      "Iteration  634 => Loss: 46.0425410112\n",
      "Iteration  635 => Loss: 46.0178801120\n",
      "Iteration  636 => Loss: 45.9932454269\n",
      "Iteration  637 => Loss: 45.9686369279\n",
      "Iteration  638 => Loss: 45.9440545872\n",
      "Iteration  639 => Loss: 45.9194983771\n",
      "Iteration  640 => Loss: 45.8949682696\n",
      "Iteration  641 => Loss: 45.8704642372\n",
      "Iteration  642 => Loss: 45.8459862520\n",
      "Iteration  643 => Loss: 45.8215342864\n",
      "Iteration  644 => Loss: 45.7971083127\n",
      "Iteration  645 => Loss: 45.7727083033\n",
      "Iteration  646 => Loss: 45.7483342306\n",
      "Iteration  647 => Loss: 45.7239860670\n",
      "Iteration  648 => Loss: 45.6996637850\n",
      "Iteration  649 => Loss: 45.6753673571\n",
      "Iteration  650 => Loss: 45.6510967557\n",
      "Iteration  651 => Loss: 45.6268519535\n",
      "Iteration  652 => Loss: 45.6026329230\n",
      "Iteration  653 => Loss: 45.5784396368\n",
      "Iteration  654 => Loss: 45.5542720676\n",
      "Iteration  655 => Loss: 45.5301301879\n",
      "Iteration  656 => Loss: 45.5060139706\n",
      "Iteration  657 => Loss: 45.4819233883\n",
      "Iteration  658 => Loss: 45.4578584138\n",
      "Iteration  659 => Loss: 45.4338190198\n",
      "Iteration  660 => Loss: 45.4098051792\n",
      "Iteration  661 => Loss: 45.3858168648\n",
      "Iteration  662 => Loss: 45.3618540495\n",
      "Iteration  663 => Loss: 45.3379167062\n",
      "Iteration  664 => Loss: 45.3140048077\n",
      "Iteration  665 => Loss: 45.2901183270\n",
      "Iteration  666 => Loss: 45.2662572372\n",
      "Iteration  667 => Loss: 45.2424215113\n",
      "Iteration  668 => Loss: 45.2186111221\n",
      "Iteration  669 => Loss: 45.1948260430\n",
      "Iteration  670 => Loss: 45.1710662468\n",
      "Iteration  671 => Loss: 45.1473317069\n",
      "Iteration  672 => Loss: 45.1236223962\n",
      "Iteration  673 => Loss: 45.0999382880\n",
      "Iteration  674 => Loss: 45.0762793555\n",
      "Iteration  675 => Loss: 45.0526455720\n",
      "Iteration  676 => Loss: 45.0290369107\n",
      "Iteration  677 => Loss: 45.0054533449\n",
      "Iteration  678 => Loss: 44.9818948479\n",
      "Iteration  679 => Loss: 44.9583613931\n",
      "Iteration  680 => Loss: 44.9348529539\n",
      "Iteration  681 => Loss: 44.9113695036\n",
      "Iteration  682 => Loss: 44.8879110157\n",
      "Iteration  683 => Loss: 44.8644774638\n",
      "Iteration  684 => Loss: 44.8410688211\n",
      "Iteration  685 => Loss: 44.8176850614\n",
      "Iteration  686 => Loss: 44.7943261581\n",
      "Iteration  687 => Loss: 44.7709920849\n",
      "Iteration  688 => Loss: 44.7476828152\n",
      "Iteration  689 => Loss: 44.7243983228\n",
      "Iteration  690 => Loss: 44.7011385814\n",
      "Iteration  691 => Loss: 44.6779035645\n",
      "Iteration  692 => Loss: 44.6546932460\n",
      "Iteration  693 => Loss: 44.6315075995\n",
      "Iteration  694 => Loss: 44.6083465989\n",
      "Iteration  695 => Loss: 44.5852102180\n",
      "Iteration  696 => Loss: 44.5620984305\n",
      "Iteration  697 => Loss: 44.5390112104\n",
      "Iteration  698 => Loss: 44.5159485315\n",
      "Iteration  699 => Loss: 44.4929103677\n",
      "Iteration  700 => Loss: 44.4698966930\n",
      "Iteration  701 => Loss: 44.4469074814\n",
      "Iteration  702 => Loss: 44.4239427068\n",
      "Iteration  703 => Loss: 44.4010023433\n",
      "Iteration  704 => Loss: 44.3780863649\n",
      "Iteration  705 => Loss: 44.3551947457\n",
      "Iteration  706 => Loss: 44.3323274598\n",
      "Iteration  707 => Loss: 44.3094844813\n",
      "Iteration  708 => Loss: 44.2866657844\n",
      "Iteration  709 => Loss: 44.2638713434\n",
      "Iteration  710 => Loss: 44.2411011323\n",
      "Iteration  711 => Loss: 44.2183551255\n",
      "Iteration  712 => Loss: 44.1956332972\n",
      "Iteration  713 => Loss: 44.1729356217\n",
      "Iteration  714 => Loss: 44.1502620734\n",
      "Iteration  715 => Loss: 44.1276126266\n",
      "Iteration  716 => Loss: 44.1049872556\n",
      "Iteration  717 => Loss: 44.0823859349\n",
      "Iteration  718 => Loss: 44.0598086390\n",
      "Iteration  719 => Loss: 44.0372553423\n",
      "Iteration  720 => Loss: 44.0147260192\n",
      "Iteration  721 => Loss: 43.9922206443\n",
      "Iteration  722 => Loss: 43.9697391922\n",
      "Iteration  723 => Loss: 43.9472816373\n",
      "Iteration  724 => Loss: 43.9248479544\n",
      "Iteration  725 => Loss: 43.9024381180\n",
      "Iteration  726 => Loss: 43.8800521028\n",
      "Iteration  727 => Loss: 43.8576898834\n",
      "Iteration  728 => Loss: 43.8353514346\n",
      "Iteration  729 => Loss: 43.8130367311\n",
      "Iteration  730 => Loss: 43.7907457476\n",
      "Iteration  731 => Loss: 43.7684784590\n",
      "Iteration  732 => Loss: 43.7462348401\n",
      "Iteration  733 => Loss: 43.7240148656\n",
      "Iteration  734 => Loss: 43.7018185105\n",
      "Iteration  735 => Loss: 43.6796457497\n",
      "Iteration  736 => Loss: 43.6574965580\n",
      "Iteration  737 => Loss: 43.6353709104\n",
      "Iteration  738 => Loss: 43.6132687820\n",
      "Iteration  739 => Loss: 43.5911901476\n",
      "Iteration  740 => Loss: 43.5691349824\n",
      "Iteration  741 => Loss: 43.5471032613\n",
      "Iteration  742 => Loss: 43.5250949595\n",
      "Iteration  743 => Loss: 43.5031100520\n",
      "Iteration  744 => Loss: 43.4811485140\n",
      "Iteration  745 => Loss: 43.4592103207\n",
      "Iteration  746 => Loss: 43.4372954472\n",
      "Iteration  747 => Loss: 43.4154038688\n",
      "Iteration  748 => Loss: 43.3935355606\n",
      "Iteration  749 => Loss: 43.3716904980\n",
      "Iteration  750 => Loss: 43.3498686562\n",
      "Iteration  751 => Loss: 43.3280700106\n",
      "Iteration  752 => Loss: 43.3062945364\n",
      "Iteration  753 => Loss: 43.2845422092\n",
      "Iteration  754 => Loss: 43.2628130042\n",
      "Iteration  755 => Loss: 43.2411068969\n",
      "Iteration  756 => Loss: 43.2194238627\n",
      "Iteration  757 => Loss: 43.1977638771\n",
      "Iteration  758 => Loss: 43.1761269156\n",
      "Iteration  759 => Loss: 43.1545129538\n",
      "Iteration  760 => Loss: 43.1329219671\n",
      "Iteration  761 => Loss: 43.1113539312\n",
      "Iteration  762 => Loss: 43.0898088217\n",
      "Iteration  763 => Loss: 43.0682866141\n",
      "Iteration  764 => Loss: 43.0467872842\n",
      "Iteration  765 => Loss: 43.0253108077\n",
      "Iteration  766 => Loss: 43.0038571601\n",
      "Iteration  767 => Loss: 42.9824263174\n",
      "Iteration  768 => Loss: 42.9610182551\n",
      "Iteration  769 => Loss: 42.9396329492\n",
      "Iteration  770 => Loss: 42.9182703755\n",
      "Iteration  771 => Loss: 42.8969305096\n",
      "Iteration  772 => Loss: 42.8756133276\n",
      "Iteration  773 => Loss: 42.8543188053\n",
      "Iteration  774 => Loss: 42.8330469187\n",
      "Iteration  775 => Loss: 42.8117976436\n",
      "Iteration  776 => Loss: 42.7905709560\n",
      "Iteration  777 => Loss: 42.7693668320\n",
      "Iteration  778 => Loss: 42.7481852475\n",
      "Iteration  779 => Loss: 42.7270261785\n",
      "Iteration  780 => Loss: 42.7058896012\n",
      "Iteration  781 => Loss: 42.6847754916\n",
      "Iteration  782 => Loss: 42.6636838259\n",
      "Iteration  783 => Loss: 42.6426145802\n",
      "Iteration  784 => Loss: 42.6215677306\n",
      "Iteration  785 => Loss: 42.6005432534\n",
      "Iteration  786 => Loss: 42.5795411248\n",
      "Iteration  787 => Loss: 42.5585613209\n",
      "Iteration  788 => Loss: 42.5376038182\n",
      "Iteration  789 => Loss: 42.5166685929\n",
      "Iteration  790 => Loss: 42.4957556212\n",
      "Iteration  791 => Loss: 42.4748648796\n",
      "Iteration  792 => Loss: 42.4539963444\n",
      "Iteration  793 => Loss: 42.4331499920\n",
      "Iteration  794 => Loss: 42.4123257988\n",
      "Iteration  795 => Loss: 42.3915237414\n",
      "Iteration  796 => Loss: 42.3707437960\n",
      "Iteration  797 => Loss: 42.3499859393\n",
      "Iteration  798 => Loss: 42.3292501478\n",
      "Iteration  799 => Loss: 42.3085363979\n",
      "Iteration  800 => Loss: 42.2878446664\n",
      "Iteration  801 => Loss: 42.2671749297\n",
      "Iteration  802 => Loss: 42.2465271645\n",
      "Iteration  803 => Loss: 42.2259013475\n",
      "Iteration  804 => Loss: 42.2052974552\n",
      "Iteration  805 => Loss: 42.1847154645\n",
      "Iteration  806 => Loss: 42.1641553519\n",
      "Iteration  807 => Loss: 42.1436170943\n",
      "Iteration  808 => Loss: 42.1231006685\n",
      "Iteration  809 => Loss: 42.1026060512\n",
      "Iteration  810 => Loss: 42.0821332192\n",
      "Iteration  811 => Loss: 42.0616821494\n",
      "Iteration  812 => Loss: 42.0412528187\n",
      "Iteration  813 => Loss: 42.0208452039\n",
      "Iteration  814 => Loss: 42.0004592820\n",
      "Iteration  815 => Loss: 41.9800950299\n",
      "Iteration  816 => Loss: 41.9597524245\n",
      "Iteration  817 => Loss: 41.9394314429\n",
      "Iteration  818 => Loss: 41.9191320621\n",
      "Iteration  819 => Loss: 41.8988542591\n",
      "Iteration  820 => Loss: 41.8785980109\n",
      "Iteration  821 => Loss: 41.8583632947\n",
      "Iteration  822 => Loss: 41.8381500876\n",
      "Iteration  823 => Loss: 41.8179583667\n",
      "Iteration  824 => Loss: 41.7977881092\n",
      "Iteration  825 => Loss: 41.7776392922\n",
      "Iteration  826 => Loss: 41.7575118930\n",
      "Iteration  827 => Loss: 41.7374058888\n",
      "Iteration  828 => Loss: 41.7173212568\n",
      "Iteration  829 => Loss: 41.6972579744\n",
      "Iteration  830 => Loss: 41.6772160189\n",
      "Iteration  831 => Loss: 41.6571953674\n",
      "Iteration  832 => Loss: 41.6371959976\n",
      "Iteration  833 => Loss: 41.6172178866\n",
      "Iteration  834 => Loss: 41.5972610119\n",
      "Iteration  835 => Loss: 41.5773253510\n",
      "Iteration  836 => Loss: 41.5574108813\n",
      "Iteration  837 => Loss: 41.5375175802\n",
      "Iteration  838 => Loss: 41.5176454252\n",
      "Iteration  839 => Loss: 41.4977943940\n",
      "Iteration  840 => Loss: 41.4779644640\n",
      "Iteration  841 => Loss: 41.4581556127\n",
      "Iteration  842 => Loss: 41.4383678179\n",
      "Iteration  843 => Loss: 41.4186010571\n",
      "Iteration  844 => Loss: 41.3988553079\n",
      "Iteration  845 => Loss: 41.3791305480\n",
      "Iteration  846 => Loss: 41.3594267551\n",
      "Iteration  847 => Loss: 41.3397439069\n",
      "Iteration  848 => Loss: 41.3200819812\n",
      "Iteration  849 => Loss: 41.3004409557\n",
      "Iteration  850 => Loss: 41.2808208082\n",
      "Iteration  851 => Loss: 41.2612215165\n",
      "Iteration  852 => Loss: 41.2416430584\n",
      "Iteration  853 => Loss: 41.2220854118\n",
      "Iteration  854 => Loss: 41.2025485546\n",
      "Iteration  855 => Loss: 41.1830324646\n",
      "Iteration  856 => Loss: 41.1635371198\n",
      "Iteration  857 => Loss: 41.1440624982\n",
      "Iteration  858 => Loss: 41.1246085776\n",
      "Iteration  859 => Loss: 41.1051753362\n",
      "Iteration  860 => Loss: 41.0857627519\n",
      "Iteration  861 => Loss: 41.0663708028\n",
      "Iteration  862 => Loss: 41.0469994668\n",
      "Iteration  863 => Loss: 41.0276487222\n",
      "Iteration  864 => Loss: 41.0083185471\n",
      "Iteration  865 => Loss: 40.9890089195\n",
      "Iteration  866 => Loss: 40.9697198176\n",
      "Iteration  867 => Loss: 40.9504512196\n",
      "Iteration  868 => Loss: 40.9312031038\n",
      "Iteration  869 => Loss: 40.9119754483\n",
      "Iteration  870 => Loss: 40.8927682313\n",
      "Iteration  871 => Loss: 40.8735814313\n",
      "Iteration  872 => Loss: 40.8544150264\n",
      "Iteration  873 => Loss: 40.8352689949\n",
      "Iteration  874 => Loss: 40.8161433153\n",
      "Iteration  875 => Loss: 40.7970379659\n",
      "Iteration  876 => Loss: 40.7779529251\n",
      "Iteration  877 => Loss: 40.7588881713\n",
      "Iteration  878 => Loss: 40.7398436828\n",
      "Iteration  879 => Loss: 40.7208194383\n",
      "Iteration  880 => Loss: 40.7018154162\n",
      "Iteration  881 => Loss: 40.6828315949\n",
      "Iteration  882 => Loss: 40.6638679530\n",
      "Iteration  883 => Loss: 40.6449244691\n",
      "Iteration  884 => Loss: 40.6260011217\n",
      "Iteration  885 => Loss: 40.6070978894\n",
      "Iteration  886 => Loss: 40.5882147508\n",
      "Iteration  887 => Loss: 40.5693516846\n",
      "Iteration  888 => Loss: 40.5505086695\n",
      "Iteration  889 => Loss: 40.5316856840\n",
      "Iteration  890 => Loss: 40.5128827071\n",
      "Iteration  891 => Loss: 40.4940997172\n",
      "Iteration  892 => Loss: 40.4753366933\n",
      "Iteration  893 => Loss: 40.4565936141\n",
      "Iteration  894 => Loss: 40.4378704584\n",
      "Iteration  895 => Loss: 40.4191672050\n",
      "Iteration  896 => Loss: 40.4004838328\n",
      "Iteration  897 => Loss: 40.3818203206\n",
      "Iteration  898 => Loss: 40.3631766473\n",
      "Iteration  899 => Loss: 40.3445527918\n",
      "Iteration  900 => Loss: 40.3259487331\n",
      "Iteration  901 => Loss: 40.3073644501\n",
      "Iteration  902 => Loss: 40.2887999218\n",
      "Iteration  903 => Loss: 40.2702551273\n",
      "Iteration  904 => Loss: 40.2517300454\n",
      "Iteration  905 => Loss: 40.2332246553\n",
      "Iteration  906 => Loss: 40.2147389360\n",
      "Iteration  907 => Loss: 40.1962728667\n",
      "Iteration  908 => Loss: 40.1778264264\n",
      "Iteration  909 => Loss: 40.1593995943\n",
      "Iteration  910 => Loss: 40.1409923495\n",
      "Iteration  911 => Loss: 40.1226046713\n",
      "Iteration  912 => Loss: 40.1042365387\n",
      "Iteration  913 => Loss: 40.0858879311\n",
      "Iteration  914 => Loss: 40.0675588276\n",
      "Iteration  915 => Loss: 40.0492492076\n",
      "Iteration  916 => Loss: 40.0309590504\n",
      "Iteration  917 => Loss: 40.0126883351\n",
      "Iteration  918 => Loss: 39.9944370413\n",
      "Iteration  919 => Loss: 39.9762051482\n",
      "Iteration  920 => Loss: 39.9579926352\n",
      "Iteration  921 => Loss: 39.9397994818\n",
      "Iteration  922 => Loss: 39.9216256672\n",
      "Iteration  923 => Loss: 39.9034711711\n",
      "Iteration  924 => Loss: 39.8853359728\n",
      "Iteration  925 => Loss: 39.8672200518\n",
      "Iteration  926 => Loss: 39.8491233877\n",
      "Iteration  927 => Loss: 39.8310459599\n",
      "Iteration  928 => Loss: 39.8129877481\n",
      "Iteration  929 => Loss: 39.7949487317\n",
      "Iteration  930 => Loss: 39.7769288904\n",
      "Iteration  931 => Loss: 39.7589282039\n",
      "Iteration  932 => Loss: 39.7409466517\n",
      "Iteration  933 => Loss: 39.7229842135\n",
      "Iteration  934 => Loss: 39.7050408690\n",
      "Iteration  935 => Loss: 39.6871165979\n",
      "Iteration  936 => Loss: 39.6692113799\n",
      "Iteration  937 => Loss: 39.6513251948\n",
      "Iteration  938 => Loss: 39.6334580223\n",
      "Iteration  939 => Loss: 39.6156098422\n",
      "Iteration  940 => Loss: 39.5977806344\n",
      "Iteration  941 => Loss: 39.5799703786\n",
      "Iteration  942 => Loss: 39.5621790548\n",
      "Iteration  943 => Loss: 39.5444066427\n",
      "Iteration  944 => Loss: 39.5266531224\n",
      "Iteration  945 => Loss: 39.5089184737\n",
      "Iteration  946 => Loss: 39.4912026765\n",
      "Iteration  947 => Loss: 39.4735057109\n",
      "Iteration  948 => Loss: 39.4558275567\n",
      "Iteration  949 => Loss: 39.4381681940\n",
      "Iteration  950 => Loss: 39.4205276029\n",
      "Iteration  951 => Loss: 39.4029057634\n",
      "Iteration  952 => Loss: 39.3853026555\n",
      "Iteration  953 => Loss: 39.3677182593\n",
      "Iteration  954 => Loss: 39.3501525549\n",
      "Iteration  955 => Loss: 39.3326055226\n",
      "Iteration  956 => Loss: 39.3150771423\n",
      "Iteration  957 => Loss: 39.2975673944\n",
      "Iteration  958 => Loss: 39.2800762589\n",
      "Iteration  959 => Loss: 39.2626037161\n",
      "Iteration  960 => Loss: 39.2451497463\n",
      "Iteration  961 => Loss: 39.2277143297\n",
      "Iteration  962 => Loss: 39.2102974466\n",
      "Iteration  963 => Loss: 39.1928990772\n",
      "Iteration  964 => Loss: 39.1755192019\n",
      "Iteration  965 => Loss: 39.1581578011\n",
      "Iteration  966 => Loss: 39.1408148551\n",
      "Iteration  967 => Loss: 39.1234903442\n",
      "Iteration  968 => Loss: 39.1061842490\n",
      "Iteration  969 => Loss: 39.0888965497\n",
      "Iteration  970 => Loss: 39.0716272270\n",
      "Iteration  971 => Loss: 39.0543762611\n",
      "Iteration  972 => Loss: 39.0371436326\n",
      "Iteration  973 => Loss: 39.0199293221\n",
      "Iteration  974 => Loss: 39.0027333100\n",
      "Iteration  975 => Loss: 38.9855555769\n",
      "Iteration  976 => Loss: 38.9683961034\n",
      "Iteration  977 => Loss: 38.9512548700\n",
      "Iteration  978 => Loss: 38.9341318574\n",
      "Iteration  979 => Loss: 38.9170270462\n",
      "Iteration  980 => Loss: 38.8999404171\n",
      "Iteration  981 => Loss: 38.8828719506\n",
      "Iteration  982 => Loss: 38.8658216276\n",
      "Iteration  983 => Loss: 38.8487894287\n",
      "Iteration  984 => Loss: 38.8317753347\n",
      "Iteration  985 => Loss: 38.8147793263\n",
      "Iteration  986 => Loss: 38.7978013843\n",
      "Iteration  987 => Loss: 38.7808414895\n",
      "Iteration  988 => Loss: 38.7638996227\n",
      "Iteration  989 => Loss: 38.7469757647\n",
      "Iteration  990 => Loss: 38.7300698965\n",
      "Iteration  991 => Loss: 38.7131819988\n",
      "Iteration  992 => Loss: 38.6963120526\n",
      "Iteration  993 => Loss: 38.6794600388\n",
      "Iteration  994 => Loss: 38.6626259383\n",
      "Iteration  995 => Loss: 38.6458097321\n",
      "Iteration  996 => Loss: 38.6290114012\n",
      "Iteration  997 => Loss: 38.6122309266\n",
      "Iteration  998 => Loss: 38.5954682892\n",
      "Iteration  999 => Loss: 38.5787234702\n",
      "Iteration 1000 => Loss: 38.5619964506\n",
      "Iteration 1001 => Loss: 38.5452872114\n",
      "Iteration 1002 => Loss: 38.5285957338\n",
      "Iteration 1003 => Loss: 38.5119219989\n",
      "Iteration 1004 => Loss: 38.4952659878\n",
      "Iteration 1005 => Loss: 38.4786276817\n",
      "Iteration 1006 => Loss: 38.4620070617\n",
      "Iteration 1007 => Loss: 38.4454041091\n",
      "Iteration 1008 => Loss: 38.4288188051\n",
      "Iteration 1009 => Loss: 38.4122511310\n",
      "Iteration 1010 => Loss: 38.3957010679\n",
      "Iteration 1011 => Loss: 38.3791685972\n",
      "Iteration 1012 => Loss: 38.3626537001\n",
      "Iteration 1013 => Loss: 38.3461563581\n",
      "Iteration 1014 => Loss: 38.3296765523\n",
      "Iteration 1015 => Loss: 38.3132142643\n",
      "Iteration 1016 => Loss: 38.2967694753\n",
      "Iteration 1017 => Loss: 38.2803421667\n",
      "Iteration 1018 => Loss: 38.2639323201\n",
      "Iteration 1019 => Loss: 38.2475399168\n",
      "Iteration 1020 => Loss: 38.2311649382\n",
      "Iteration 1021 => Loss: 38.2148073659\n",
      "Iteration 1022 => Loss: 38.1984671813\n",
      "Iteration 1023 => Loss: 38.1821443661\n",
      "Iteration 1024 => Loss: 38.1658389016\n",
      "Iteration 1025 => Loss: 38.1495507695\n",
      "Iteration 1026 => Loss: 38.1332799513\n",
      "Iteration 1027 => Loss: 38.1170264286\n",
      "Iteration 1028 => Loss: 38.1007901832\n",
      "Iteration 1029 => Loss: 38.0845711964\n",
      "Iteration 1030 => Loss: 38.0683694502\n",
      "Iteration 1031 => Loss: 38.0521849260\n",
      "Iteration 1032 => Loss: 38.0360176057\n",
      "Iteration 1033 => Loss: 38.0198674708\n",
      "Iteration 1034 => Loss: 38.0037345032\n",
      "Iteration 1035 => Loss: 37.9876186847\n",
      "Iteration 1036 => Loss: 37.9715199969\n",
      "Iteration 1037 => Loss: 37.9554384216\n",
      "Iteration 1038 => Loss: 37.9393739407\n",
      "Iteration 1039 => Loss: 37.9233265361\n",
      "Iteration 1040 => Loss: 37.9072961894\n",
      "Iteration 1041 => Loss: 37.8912828827\n",
      "Iteration 1042 => Loss: 37.8752865978\n",
      "Iteration 1043 => Loss: 37.8593073167\n",
      "Iteration 1044 => Loss: 37.8433450211\n",
      "Iteration 1045 => Loss: 37.8273996931\n",
      "Iteration 1046 => Loss: 37.8114713147\n",
      "Iteration 1047 => Loss: 37.7955598678\n",
      "Iteration 1048 => Loss: 37.7796653344\n",
      "Iteration 1049 => Loss: 37.7637876966\n",
      "Iteration 1050 => Loss: 37.7479269364\n",
      "Iteration 1051 => Loss: 37.7320830358\n",
      "Iteration 1052 => Loss: 37.7162559770\n",
      "Iteration 1053 => Loss: 37.7004457420\n",
      "Iteration 1054 => Loss: 37.6846523129\n",
      "Iteration 1055 => Loss: 37.6688756719\n",
      "Iteration 1056 => Loss: 37.6531158011\n",
      "Iteration 1057 => Loss: 37.6373726828\n",
      "Iteration 1058 => Loss: 37.6216462991\n",
      "Iteration 1059 => Loss: 37.6059366321\n",
      "Iteration 1060 => Loss: 37.5902436642\n",
      "Iteration 1061 => Loss: 37.5745673776\n",
      "Iteration 1062 => Loss: 37.5589077546\n",
      "Iteration 1063 => Loss: 37.5432647774\n",
      "Iteration 1064 => Loss: 37.5276384283\n",
      "Iteration 1065 => Loss: 37.5120286898\n",
      "Iteration 1066 => Loss: 37.4964355440\n",
      "Iteration 1067 => Loss: 37.4808589734\n",
      "Iteration 1068 => Loss: 37.4652989604\n",
      "Iteration 1069 => Loss: 37.4497554874\n",
      "Iteration 1070 => Loss: 37.4342285368\n",
      "Iteration 1071 => Loss: 37.4187180909\n",
      "Iteration 1072 => Loss: 37.4032241324\n",
      "Iteration 1073 => Loss: 37.3877466435\n",
      "Iteration 1074 => Loss: 37.3722856070\n",
      "Iteration 1075 => Loss: 37.3568410051\n",
      "Iteration 1076 => Loss: 37.3414128206\n",
      "Iteration 1077 => Loss: 37.3260010359\n",
      "Iteration 1078 => Loss: 37.3106056336\n",
      "Iteration 1079 => Loss: 37.2952265963\n",
      "Iteration 1080 => Loss: 37.2798639066\n",
      "Iteration 1081 => Loss: 37.2645175470\n",
      "Iteration 1082 => Loss: 37.2491875004\n",
      "Iteration 1083 => Loss: 37.2338737492\n",
      "Iteration 1084 => Loss: 37.2185762763\n",
      "Iteration 1085 => Loss: 37.2032950642\n",
      "Iteration 1086 => Loss: 37.1880300958\n",
      "Iteration 1087 => Loss: 37.1727813536\n",
      "Iteration 1088 => Loss: 37.1575488206\n",
      "Iteration 1089 => Loss: 37.1423324794\n",
      "Iteration 1090 => Loss: 37.1271323129\n",
      "Iteration 1091 => Loss: 37.1119483038\n",
      "Iteration 1092 => Loss: 37.0967804350\n",
      "Iteration 1093 => Loss: 37.0816286894\n",
      "Iteration 1094 => Loss: 37.0664930497\n",
      "Iteration 1095 => Loss: 37.0513734988\n",
      "Iteration 1096 => Loss: 37.0362700198\n",
      "Iteration 1097 => Loss: 37.0211825954\n",
      "Iteration 1098 => Loss: 37.0061112086\n",
      "Iteration 1099 => Loss: 36.9910558424\n",
      "Iteration 1100 => Loss: 36.9760164797\n",
      "Iteration 1101 => Loss: 36.9609931036\n",
      "Iteration 1102 => Loss: 36.9459856969\n",
      "Iteration 1103 => Loss: 36.9309942429\n",
      "Iteration 1104 => Loss: 36.9160187244\n",
      "Iteration 1105 => Loss: 36.9010591246\n",
      "Iteration 1106 => Loss: 36.8861154265\n",
      "Iteration 1107 => Loss: 36.8711876133\n",
      "Iteration 1108 => Loss: 36.8562756680\n",
      "Iteration 1109 => Loss: 36.8413795738\n",
      "Iteration 1110 => Loss: 36.8264993138\n",
      "Iteration 1111 => Loss: 36.8116348712\n",
      "Iteration 1112 => Loss: 36.7967862292\n",
      "Iteration 1113 => Loss: 36.7819533710\n",
      "Iteration 1114 => Loss: 36.7671362798\n",
      "Iteration 1115 => Loss: 36.7523349389\n",
      "Iteration 1116 => Loss: 36.7375493314\n",
      "Iteration 1117 => Loss: 36.7227794408\n",
      "Iteration 1118 => Loss: 36.7080252502\n",
      "Iteration 1119 => Loss: 36.6932867431\n",
      "Iteration 1120 => Loss: 36.6785639026\n",
      "Iteration 1121 => Loss: 36.6638567122\n",
      "Iteration 1122 => Loss: 36.6491651553\n",
      "Iteration 1123 => Loss: 36.6344892151\n",
      "Iteration 1124 => Loss: 36.6198288752\n",
      "Iteration 1125 => Loss: 36.6051841189\n",
      "Iteration 1126 => Loss: 36.5905549297\n",
      "Iteration 1127 => Loss: 36.5759412910\n",
      "Iteration 1128 => Loss: 36.5613431862\n",
      "Iteration 1129 => Loss: 36.5467605990\n",
      "Iteration 1130 => Loss: 36.5321935127\n",
      "Iteration 1131 => Loss: 36.5176419110\n",
      "Iteration 1132 => Loss: 36.5031057772\n",
      "Iteration 1133 => Loss: 36.4885850951\n",
      "Iteration 1134 => Loss: 36.4740798482\n",
      "Iteration 1135 => Loss: 36.4595900200\n",
      "Iteration 1136 => Loss: 36.4451155942\n",
      "Iteration 1137 => Loss: 36.4306565544\n",
      "Iteration 1138 => Loss: 36.4162128843\n",
      "Iteration 1139 => Loss: 36.4017845674\n",
      "Iteration 1140 => Loss: 36.3873715876\n",
      "Iteration 1141 => Loss: 36.3729739285\n",
      "Iteration 1142 => Loss: 36.3585915737\n",
      "Iteration 1143 => Loss: 36.3442245071\n",
      "Iteration 1144 => Loss: 36.3298727124\n",
      "Iteration 1145 => Loss: 36.3155361734\n",
      "Iteration 1146 => Loss: 36.3012148738\n",
      "Iteration 1147 => Loss: 36.2869087974\n",
      "Iteration 1148 => Loss: 36.2726179281\n",
      "Iteration 1149 => Loss: 36.2583422496\n",
      "Iteration 1150 => Loss: 36.2440817459\n",
      "Iteration 1151 => Loss: 36.2298364008\n",
      "Iteration 1152 => Loss: 36.2156061983\n",
      "Iteration 1153 => Loss: 36.2013911221\n",
      "Iteration 1154 => Loss: 36.1871911562\n",
      "Iteration 1155 => Loss: 36.1730062846\n",
      "Iteration 1156 => Loss: 36.1588364913\n",
      "Iteration 1157 => Loss: 36.1446817601\n",
      "Iteration 1158 => Loss: 36.1305420751\n",
      "Iteration 1159 => Loss: 36.1164174203\n",
      "Iteration 1160 => Loss: 36.1023077796\n",
      "Iteration 1161 => Loss: 36.0882131373\n",
      "Iteration 1162 => Loss: 36.0741334772\n",
      "Iteration 1163 => Loss: 36.0600687835\n",
      "Iteration 1164 => Loss: 36.0460190403\n",
      "Iteration 1165 => Loss: 36.0319842317\n",
      "Iteration 1166 => Loss: 36.0179643418\n",
      "Iteration 1167 => Loss: 36.0039593547\n",
      "Iteration 1168 => Loss: 35.9899692546\n",
      "Iteration 1169 => Loss: 35.9759940257\n",
      "Iteration 1170 => Loss: 35.9620336522\n",
      "Iteration 1171 => Loss: 35.9480881182\n",
      "Iteration 1172 => Loss: 35.9341574081\n",
      "Iteration 1173 => Loss: 35.9202415060\n",
      "Iteration 1174 => Loss: 35.9063403962\n",
      "Iteration 1175 => Loss: 35.8924540630\n",
      "Iteration 1176 => Loss: 35.8785824907\n",
      "Iteration 1177 => Loss: 35.8647256636\n",
      "Iteration 1178 => Loss: 35.8508835660\n",
      "Iteration 1179 => Loss: 35.8370561822\n",
      "Iteration 1180 => Loss: 35.8232434966\n",
      "Iteration 1181 => Loss: 35.8094454937\n",
      "Iteration 1182 => Loss: 35.7956621577\n",
      "Iteration 1183 => Loss: 35.7818934731\n",
      "Iteration 1184 => Loss: 35.7681394244\n",
      "Iteration 1185 => Loss: 35.7543999959\n",
      "Iteration 1186 => Loss: 35.7406751721\n",
      "Iteration 1187 => Loss: 35.7269649375\n",
      "Iteration 1188 => Loss: 35.7132692766\n",
      "Iteration 1189 => Loss: 35.6995881739\n",
      "Iteration 1190 => Loss: 35.6859216139\n",
      "Iteration 1191 => Loss: 35.6722695812\n",
      "Iteration 1192 => Loss: 35.6586320603\n",
      "Iteration 1193 => Loss: 35.6450090358\n",
      "Iteration 1194 => Loss: 35.6314004923\n",
      "Iteration 1195 => Loss: 35.6178064144\n",
      "Iteration 1196 => Loss: 35.6042267867\n",
      "Iteration 1197 => Loss: 35.5906615938\n",
      "Iteration 1198 => Loss: 35.5771108205\n",
      "Iteration 1199 => Loss: 35.5635744513\n",
      "Iteration 1200 => Loss: 35.5500524710\n",
      "Iteration 1201 => Loss: 35.5365448643\n",
      "Iteration 1202 => Loss: 35.5230516159\n",
      "Iteration 1203 => Loss: 35.5095727106\n",
      "Iteration 1204 => Loss: 35.4961081330\n",
      "Iteration 1205 => Loss: 35.4826578680\n",
      "Iteration 1206 => Loss: 35.4692219003\n",
      "Iteration 1207 => Loss: 35.4558002148\n",
      "Iteration 1208 => Loss: 35.4423927962\n",
      "Iteration 1209 => Loss: 35.4289996295\n",
      "Iteration 1210 => Loss: 35.4156206994\n",
      "Iteration 1211 => Loss: 35.4022559908\n",
      "Iteration 1212 => Loss: 35.3889054886\n",
      "Iteration 1213 => Loss: 35.3755691777\n",
      "Iteration 1214 => Loss: 35.3622470430\n",
      "Iteration 1215 => Loss: 35.3489390695\n",
      "Iteration 1216 => Loss: 35.3356452421\n",
      "Iteration 1217 => Loss: 35.3223655457\n",
      "Iteration 1218 => Loss: 35.3090999654\n",
      "Iteration 1219 => Loss: 35.2958484861\n",
      "Iteration 1220 => Loss: 35.2826110928\n",
      "Iteration 1221 => Loss: 35.2693877706\n",
      "Iteration 1222 => Loss: 35.2561785045\n",
      "Iteration 1223 => Loss: 35.2429832796\n",
      "Iteration 1224 => Loss: 35.2298020809\n",
      "Iteration 1225 => Loss: 35.2166348936\n",
      "Iteration 1226 => Loss: 35.2034817027\n",
      "Iteration 1227 => Loss: 35.1903424934\n",
      "Iteration 1228 => Loss: 35.1772172507\n",
      "Iteration 1229 => Loss: 35.1641059599\n",
      "Iteration 1230 => Loss: 35.1510086062\n",
      "Iteration 1231 => Loss: 35.1379251746\n",
      "Iteration 1232 => Loss: 35.1248556505\n",
      "Iteration 1233 => Loss: 35.1118000190\n",
      "Iteration 1234 => Loss: 35.0987582653\n",
      "Iteration 1235 => Loss: 35.0857303748\n",
      "Iteration 1236 => Loss: 35.0727163326\n",
      "Iteration 1237 => Loss: 35.0597161241\n",
      "Iteration 1238 => Loss: 35.0467297345\n",
      "Iteration 1239 => Loss: 35.0337571492\n",
      "Iteration 1240 => Loss: 35.0207983534\n",
      "Iteration 1241 => Loss: 35.0078533326\n",
      "Iteration 1242 => Loss: 34.9949220721\n",
      "Iteration 1243 => Loss: 34.9820045572\n",
      "Iteration 1244 => Loss: 34.9691007733\n",
      "Iteration 1245 => Loss: 34.9562107060\n",
      "Iteration 1246 => Loss: 34.9433343404\n",
      "Iteration 1247 => Loss: 34.9304716622\n",
      "Iteration 1248 => Loss: 34.9176226568\n",
      "Iteration 1249 => Loss: 34.9047873095\n",
      "Iteration 1250 => Loss: 34.8919656060\n",
      "Iteration 1251 => Loss: 34.8791575316\n",
      "Iteration 1252 => Loss: 34.8663630720\n",
      "Iteration 1253 => Loss: 34.8535822126\n",
      "Iteration 1254 => Loss: 34.8408149390\n",
      "Iteration 1255 => Loss: 34.8280612367\n",
      "Iteration 1256 => Loss: 34.8153210914\n",
      "Iteration 1257 => Loss: 34.8025944885\n",
      "Iteration 1258 => Loss: 34.7898814138\n",
      "Iteration 1259 => Loss: 34.7771818527\n",
      "Iteration 1260 => Loss: 34.7644957911\n",
      "Iteration 1261 => Loss: 34.7518232145\n",
      "Iteration 1262 => Loss: 34.7391641085\n",
      "Iteration 1263 => Loss: 34.7265184589\n",
      "Iteration 1264 => Loss: 34.7138862514\n",
      "Iteration 1265 => Loss: 34.7012674716\n",
      "Iteration 1266 => Loss: 34.6886621053\n",
      "Iteration 1267 => Loss: 34.6760701383\n",
      "Iteration 1268 => Loss: 34.6634915562\n",
      "Iteration 1269 => Loss: 34.6509263449\n",
      "Iteration 1270 => Loss: 34.6383744902\n",
      "Iteration 1271 => Loss: 34.6258359778\n",
      "Iteration 1272 => Loss: 34.6133107936\n",
      "Iteration 1273 => Loss: 34.6007989234\n",
      "Iteration 1274 => Loss: 34.5883003531\n",
      "Iteration 1275 => Loss: 34.5758150685\n",
      "Iteration 1276 => Loss: 34.5633430554\n",
      "Iteration 1277 => Loss: 34.5508842999\n",
      "Iteration 1278 => Loss: 34.5384387877\n",
      "Iteration 1279 => Loss: 34.5260065049\n",
      "Iteration 1280 => Loss: 34.5135874373\n",
      "Iteration 1281 => Loss: 34.5011815709\n",
      "Iteration 1282 => Loss: 34.4887888917\n",
      "Iteration 1283 => Loss: 34.4764093856\n",
      "Iteration 1284 => Loss: 34.4640430387\n",
      "Iteration 1285 => Loss: 34.4516898369\n",
      "Iteration 1286 => Loss: 34.4393497664\n",
      "Iteration 1287 => Loss: 34.4270228131\n",
      "Iteration 1288 => Loss: 34.4147089630\n",
      "Iteration 1289 => Loss: 34.4024082024\n",
      "Iteration 1290 => Loss: 34.3901205171\n",
      "Iteration 1291 => Loss: 34.3778458935\n",
      "Iteration 1292 => Loss: 34.3655843175\n",
      "Iteration 1293 => Loss: 34.3533357752\n",
      "Iteration 1294 => Loss: 34.3411002530\n",
      "Iteration 1295 => Loss: 34.3288777368\n",
      "Iteration 1296 => Loss: 34.3166682129\n",
      "Iteration 1297 => Loss: 34.3044716675\n",
      "Iteration 1298 => Loss: 34.2922880867\n",
      "Iteration 1299 => Loss: 34.2801174568\n",
      "Iteration 1300 => Loss: 34.2679597641\n",
      "Iteration 1301 => Loss: 34.2558149947\n",
      "Iteration 1302 => Loss: 34.2436831349\n",
      "Iteration 1303 => Loss: 34.2315641711\n",
      "Iteration 1304 => Loss: 34.2194580894\n",
      "Iteration 1305 => Loss: 34.2073648763\n",
      "Iteration 1306 => Loss: 34.1952845180\n",
      "Iteration 1307 => Loss: 34.1832170008\n",
      "Iteration 1308 => Loss: 34.1711623112\n",
      "Iteration 1309 => Loss: 34.1591204354\n",
      "Iteration 1310 => Loss: 34.1470913599\n",
      "Iteration 1311 => Loss: 34.1350750711\n",
      "Iteration 1312 => Loss: 34.1230715553\n",
      "Iteration 1313 => Loss: 34.1110807990\n",
      "Iteration 1314 => Loss: 34.0991027886\n",
      "Iteration 1315 => Loss: 34.0871375106\n",
      "Iteration 1316 => Loss: 34.0751849514\n",
      "Iteration 1317 => Loss: 34.0632450976\n",
      "Iteration 1318 => Loss: 34.0513179355\n",
      "Iteration 1319 => Loss: 34.0394034518\n",
      "Iteration 1320 => Loss: 34.0275016329\n",
      "Iteration 1321 => Loss: 34.0156124654\n",
      "Iteration 1322 => Loss: 34.0037359359\n",
      "Iteration 1323 => Loss: 33.9918720308\n",
      "Iteration 1324 => Loss: 33.9800207368\n",
      "Iteration 1325 => Loss: 33.9681820405\n",
      "Iteration 1326 => Loss: 33.9563559284\n",
      "Iteration 1327 => Loss: 33.9445423873\n",
      "Iteration 1328 => Loss: 33.9327414037\n",
      "Iteration 1329 => Loss: 33.9209529643\n",
      "Iteration 1330 => Loss: 33.9091770558\n",
      "Iteration 1331 => Loss: 33.8974136648\n",
      "Iteration 1332 => Loss: 33.8856627781\n",
      "Iteration 1333 => Loss: 33.8739243822\n",
      "Iteration 1334 => Loss: 33.8621984641\n",
      "Iteration 1335 => Loss: 33.8504850103\n",
      "Iteration 1336 => Loss: 33.8387840077\n",
      "Iteration 1337 => Loss: 33.8270954431\n",
      "Iteration 1338 => Loss: 33.8154193031\n",
      "Iteration 1339 => Loss: 33.8037555746\n",
      "Iteration 1340 => Loss: 33.7921042444\n",
      "Iteration 1341 => Loss: 33.7804652993\n",
      "Iteration 1342 => Loss: 33.7688387262\n",
      "Iteration 1343 => Loss: 33.7572245119\n",
      "Iteration 1344 => Loss: 33.7456226432\n",
      "Iteration 1345 => Loss: 33.7340331071\n",
      "Iteration 1346 => Loss: 33.7224558904\n",
      "Iteration 1347 => Loss: 33.7108909800\n",
      "Iteration 1348 => Loss: 33.6993383629\n",
      "Iteration 1349 => Loss: 33.6877980260\n",
      "Iteration 1350 => Loss: 33.6762699562\n",
      "Iteration 1351 => Loss: 33.6647541405\n",
      "Iteration 1352 => Loss: 33.6532505659\n",
      "Iteration 1353 => Loss: 33.6417592193\n",
      "Iteration 1354 => Loss: 33.6302800878\n",
      "Iteration 1355 => Loss: 33.6188131584\n",
      "Iteration 1356 => Loss: 33.6073584181\n",
      "Iteration 1357 => Loss: 33.5959158539\n",
      "Iteration 1358 => Loss: 33.5844854529\n",
      "Iteration 1359 => Loss: 33.5730672022\n",
      "Iteration 1360 => Loss: 33.5616610888\n",
      "Iteration 1361 => Loss: 33.5502670999\n",
      "Iteration 1362 => Loss: 33.5388852226\n",
      "Iteration 1363 => Loss: 33.5275154439\n",
      "Iteration 1364 => Loss: 33.5161577511\n",
      "Iteration 1365 => Loss: 33.5048121313\n",
      "Iteration 1366 => Loss: 33.4934785716\n",
      "Iteration 1367 => Loss: 33.4821570593\n",
      "Iteration 1368 => Loss: 33.4708475815\n",
      "Iteration 1369 => Loss: 33.4595501254\n",
      "Iteration 1370 => Loss: 33.4482646783\n",
      "Iteration 1371 => Loss: 33.4369912274\n",
      "Iteration 1372 => Loss: 33.4257297599\n",
      "Iteration 1373 => Loss: 33.4144802631\n",
      "Iteration 1374 => Loss: 33.4032427243\n",
      "Iteration 1375 => Loss: 33.3920171308\n",
      "Iteration 1376 => Loss: 33.3808034698\n",
      "Iteration 1377 => Loss: 33.3696017287\n",
      "Iteration 1378 => Loss: 33.3584118948\n",
      "Iteration 1379 => Loss: 33.3472339555\n",
      "Iteration 1380 => Loss: 33.3360678981\n",
      "Iteration 1381 => Loss: 33.3249137100\n",
      "Iteration 1382 => Loss: 33.3137713785\n",
      "Iteration 1383 => Loss: 33.3026408911\n",
      "Iteration 1384 => Loss: 33.2915222352\n",
      "Iteration 1385 => Loss: 33.2804153981\n",
      "Iteration 1386 => Loss: 33.2693203674\n",
      "Iteration 1387 => Loss: 33.2582371305\n",
      "Iteration 1388 => Loss: 33.2471656748\n",
      "Iteration 1389 => Loss: 33.2361059879\n",
      "Iteration 1390 => Loss: 33.2250580571\n",
      "Iteration 1391 => Loss: 33.2140218701\n",
      "Iteration 1392 => Loss: 33.2029974143\n",
      "Iteration 1393 => Loss: 33.1919846773\n",
      "Iteration 1394 => Loss: 33.1809836465\n",
      "Iteration 1395 => Loss: 33.1699943097\n",
      "Iteration 1396 => Loss: 33.1590166542\n",
      "Iteration 1397 => Loss: 33.1480506678\n",
      "Iteration 1398 => Loss: 33.1370963380\n",
      "Iteration 1399 => Loss: 33.1261536524\n",
      "Iteration 1400 => Loss: 33.1152225987\n",
      "Iteration 1401 => Loss: 33.1043031644\n",
      "Iteration 1402 => Loss: 33.0933953373\n",
      "Iteration 1403 => Loss: 33.0824991049\n",
      "Iteration 1404 => Loss: 33.0716144550\n",
      "Iteration 1405 => Loss: 33.0607413753\n",
      "Iteration 1406 => Loss: 33.0498798534\n",
      "Iteration 1407 => Loss: 33.0390298771\n",
      "Iteration 1408 => Loss: 33.0281914341\n",
      "Iteration 1409 => Loss: 33.0173645121\n",
      "Iteration 1410 => Loss: 33.0065490989\n",
      "Iteration 1411 => Loss: 32.9957451822\n",
      "Iteration 1412 => Loss: 32.9849527499\n",
      "Iteration 1413 => Loss: 32.9741717897\n",
      "Iteration 1414 => Loss: 32.9634022895\n",
      "Iteration 1415 => Loss: 32.9526442370\n",
      "Iteration 1416 => Loss: 32.9418976200\n",
      "Iteration 1417 => Loss: 32.9311624265\n",
      "Iteration 1418 => Loss: 32.9204386443\n",
      "Iteration 1419 => Loss: 32.9097262613\n",
      "Iteration 1420 => Loss: 32.8990252652\n",
      "Iteration 1421 => Loss: 32.8883356441\n",
      "Iteration 1422 => Loss: 32.8776573859\n",
      "Iteration 1423 => Loss: 32.8669904784\n",
      "Iteration 1424 => Loss: 32.8563349096\n",
      "Iteration 1425 => Loss: 32.8456906674\n",
      "Iteration 1426 => Loss: 32.8350577399\n",
      "Iteration 1427 => Loss: 32.8244361149\n",
      "Iteration 1428 => Loss: 32.8138257805\n",
      "Iteration 1429 => Loss: 32.8032267247\n",
      "Iteration 1430 => Loss: 32.7926389354\n",
      "Iteration 1431 => Loss: 32.7820624007\n",
      "Iteration 1432 => Loss: 32.7714971086\n",
      "Iteration 1433 => Loss: 32.7609430473\n",
      "Iteration 1434 => Loss: 32.7504002046\n",
      "Iteration 1435 => Loss: 32.7398685688\n",
      "Iteration 1436 => Loss: 32.7293481279\n",
      "Iteration 1437 => Loss: 32.7188388700\n",
      "Iteration 1438 => Loss: 32.7083407832\n",
      "Iteration 1439 => Loss: 32.6978538557\n",
      "Iteration 1440 => Loss: 32.6873780755\n",
      "Iteration 1441 => Loss: 32.6769134309\n",
      "Iteration 1442 => Loss: 32.6664599100\n",
      "Iteration 1443 => Loss: 32.6560175009\n",
      "Iteration 1444 => Loss: 32.6455861919\n",
      "Iteration 1445 => Loss: 32.6351659712\n",
      "Iteration 1446 => Loss: 32.6247568269\n",
      "Iteration 1447 => Loss: 32.6143587473\n",
      "Iteration 1448 => Loss: 32.6039717207\n",
      "Iteration 1449 => Loss: 32.5935957352\n",
      "Iteration 1450 => Loss: 32.5832307792\n",
      "Iteration 1451 => Loss: 32.5728768410\n",
      "Iteration 1452 => Loss: 32.5625339087\n",
      "Iteration 1453 => Loss: 32.5522019708\n",
      "Iteration 1454 => Loss: 32.5418810155\n",
      "Iteration 1455 => Loss: 32.5315710312\n",
      "Iteration 1456 => Loss: 32.5212720061\n",
      "Iteration 1457 => Loss: 32.5109839287\n",
      "Iteration 1458 => Loss: 32.5007067873\n",
      "Iteration 1459 => Loss: 32.4904405703\n",
      "Iteration 1460 => Loss: 32.4801852660\n",
      "Iteration 1461 => Loss: 32.4699408630\n",
      "Iteration 1462 => Loss: 32.4597073495\n",
      "Iteration 1463 => Loss: 32.4494847140\n",
      "Iteration 1464 => Loss: 32.4392729450\n",
      "Iteration 1465 => Loss: 32.4290720308\n",
      "Iteration 1466 => Loss: 32.4188819600\n",
      "Iteration 1467 => Loss: 32.4087027211\n",
      "Iteration 1468 => Loss: 32.3985343024\n",
      "Iteration 1469 => Loss: 32.3883766926\n",
      "Iteration 1470 => Loss: 32.3782298801\n",
      "Iteration 1471 => Loss: 32.3680938534\n",
      "Iteration 1472 => Loss: 32.3579686011\n",
      "Iteration 1473 => Loss: 32.3478541118\n",
      "Iteration 1474 => Loss: 32.3377503739\n",
      "Iteration 1475 => Loss: 32.3276573761\n",
      "Iteration 1476 => Loss: 32.3175751069\n",
      "Iteration 1477 => Loss: 32.3075035550\n",
      "Iteration 1478 => Loss: 32.2974427089\n",
      "Iteration 1479 => Loss: 32.2873925573\n",
      "Iteration 1480 => Loss: 32.2773530888\n",
      "Iteration 1481 => Loss: 32.2673242920\n",
      "Iteration 1482 => Loss: 32.2573061556\n",
      "Iteration 1483 => Loss: 32.2472986683\n",
      "Iteration 1484 => Loss: 32.2373018188\n",
      "Iteration 1485 => Loss: 32.2273155956\n",
      "Iteration 1486 => Loss: 32.2173399876\n",
      "Iteration 1487 => Loss: 32.2073749835\n",
      "Iteration 1488 => Loss: 32.1974205720\n",
      "Iteration 1489 => Loss: 32.1874767418\n",
      "Iteration 1490 => Loss: 32.1775434816\n",
      "Iteration 1491 => Loss: 32.1676207804\n",
      "Iteration 1492 => Loss: 32.1577086267\n",
      "Iteration 1493 => Loss: 32.1478070094\n",
      "Iteration 1494 => Loss: 32.1379159174\n",
      "Iteration 1495 => Loss: 32.1280353394\n",
      "Iteration 1496 => Loss: 32.1181652642\n",
      "Iteration 1497 => Loss: 32.1083056807\n",
      "Iteration 1498 => Loss: 32.0984565777\n",
      "Iteration 1499 => Loss: 32.0886179441\n",
      "Iteration 1500 => Loss: 32.0787897688\n",
      "Iteration 1501 => Loss: 32.0689720406\n",
      "Iteration 1502 => Loss: 32.0591647485\n",
      "Iteration 1503 => Loss: 32.0493678813\n",
      "Iteration 1504 => Loss: 32.0395814279\n",
      "Iteration 1505 => Loss: 32.0298053774\n",
      "Iteration 1506 => Loss: 32.0200397185\n",
      "Iteration 1507 => Loss: 32.0102844404\n",
      "Iteration 1508 => Loss: 32.0005395319\n",
      "Iteration 1509 => Loss: 31.9908049821\n",
      "Iteration 1510 => Loss: 31.9810807799\n",
      "Iteration 1511 => Loss: 31.9713669143\n",
      "Iteration 1512 => Loss: 31.9616633743\n",
      "Iteration 1513 => Loss: 31.9519701490\n",
      "Iteration 1514 => Loss: 31.9422872274\n",
      "Iteration 1515 => Loss: 31.9326145985\n",
      "Iteration 1516 => Loss: 31.9229522514\n",
      "Iteration 1517 => Loss: 31.9133001752\n",
      "Iteration 1518 => Loss: 31.9036583589\n",
      "Iteration 1519 => Loss: 31.8940267917\n",
      "Iteration 1520 => Loss: 31.8844054626\n",
      "Iteration 1521 => Loss: 31.8747943608\n",
      "Iteration 1522 => Loss: 31.8651934754\n",
      "Iteration 1523 => Loss: 31.8556027956\n",
      "Iteration 1524 => Loss: 31.8460223104\n",
      "Iteration 1525 => Loss: 31.8364520091\n",
      "Iteration 1526 => Loss: 31.8268918808\n",
      "Iteration 1527 => Loss: 31.8173419147\n",
      "Iteration 1528 => Loss: 31.8078021000\n",
      "Iteration 1529 => Loss: 31.7982724260\n",
      "Iteration 1530 => Loss: 31.7887528818\n",
      "Iteration 1531 => Loss: 31.7792434566\n",
      "Iteration 1532 => Loss: 31.7697441398\n",
      "Iteration 1533 => Loss: 31.7602549206\n",
      "Iteration 1534 => Loss: 31.7507757882\n",
      "Iteration 1535 => Loss: 31.7413067319\n",
      "Iteration 1536 => Loss: 31.7318477410\n",
      "Iteration 1537 => Loss: 31.7223988048\n",
      "Iteration 1538 => Loss: 31.7129599126\n",
      "Iteration 1539 => Loss: 31.7035310538\n",
      "Iteration 1540 => Loss: 31.6941122177\n",
      "Iteration 1541 => Loss: 31.6847033936\n",
      "Iteration 1542 => Loss: 31.6753045708\n",
      "Iteration 1543 => Loss: 31.6659157388\n",
      "Iteration 1544 => Loss: 31.6565368870\n",
      "Iteration 1545 => Loss: 31.6471680046\n",
      "Iteration 1546 => Loss: 31.6378090812\n",
      "Iteration 1547 => Loss: 31.6284601061\n",
      "Iteration 1548 => Loss: 31.6191210688\n",
      "Iteration 1549 => Loss: 31.6097919587\n",
      "Iteration 1550 => Loss: 31.6004727652\n",
      "Iteration 1551 => Loss: 31.5911634778\n",
      "Iteration 1552 => Loss: 31.5818640860\n",
      "Iteration 1553 => Loss: 31.5725745793\n",
      "Iteration 1554 => Loss: 31.5632949471\n",
      "Iteration 1555 => Loss: 31.5540251790\n",
      "Iteration 1556 => Loss: 31.5447652644\n",
      "Iteration 1557 => Loss: 31.5355151929\n",
      "Iteration 1558 => Loss: 31.5262749541\n",
      "Iteration 1559 => Loss: 31.5170445374\n",
      "Iteration 1560 => Loss: 31.5078239324\n",
      "Iteration 1561 => Loss: 31.4986131288\n",
      "Iteration 1562 => Loss: 31.4894121161\n",
      "Iteration 1563 => Loss: 31.4802208838\n",
      "Iteration 1564 => Loss: 31.4710394216\n",
      "Iteration 1565 => Loss: 31.4618677192\n",
      "Iteration 1566 => Loss: 31.4527057660\n",
      "Iteration 1567 => Loss: 31.4435535518\n",
      "Iteration 1568 => Loss: 31.4344110662\n",
      "Iteration 1569 => Loss: 31.4252782989\n",
      "Iteration 1570 => Loss: 31.4161552396\n",
      "Iteration 1571 => Loss: 31.4070418778\n",
      "Iteration 1572 => Loss: 31.3979382034\n",
      "Iteration 1573 => Loss: 31.3888442059\n",
      "Iteration 1574 => Loss: 31.3797598752\n",
      "Iteration 1575 => Loss: 31.3706852010\n",
      "Iteration 1576 => Loss: 31.3616201729\n",
      "Iteration 1577 => Loss: 31.3525647807\n",
      "Iteration 1578 => Loss: 31.3435190143\n",
      "Iteration 1579 => Loss: 31.3344828633\n",
      "Iteration 1580 => Loss: 31.3254563175\n",
      "Iteration 1581 => Loss: 31.3164393668\n",
      "Iteration 1582 => Loss: 31.3074320009\n",
      "Iteration 1583 => Loss: 31.2984342097\n",
      "Iteration 1584 => Loss: 31.2894459829\n",
      "Iteration 1585 => Loss: 31.2804673103\n",
      "Iteration 1586 => Loss: 31.2714981820\n",
      "Iteration 1587 => Loss: 31.2625385876\n",
      "Iteration 1588 => Loss: 31.2535885171\n",
      "Iteration 1589 => Loss: 31.2446479603\n",
      "Iteration 1590 => Loss: 31.2357169071\n",
      "Iteration 1591 => Loss: 31.2267953475\n",
      "Iteration 1592 => Loss: 31.2178832713\n",
      "Iteration 1593 => Loss: 31.2089806684\n",
      "Iteration 1594 => Loss: 31.2000875288\n",
      "Iteration 1595 => Loss: 31.1912038425\n",
      "Iteration 1596 => Loss: 31.1823295993\n",
      "Iteration 1597 => Loss: 31.1734647892\n",
      "Iteration 1598 => Loss: 31.1646094022\n",
      "Iteration 1599 => Loss: 31.1557634284\n",
      "Iteration 1600 => Loss: 31.1469268576\n",
      "Iteration 1601 => Loss: 31.1380996799\n",
      "Iteration 1602 => Loss: 31.1292818853\n",
      "Iteration 1603 => Loss: 31.1204734638\n",
      "Iteration 1604 => Loss: 31.1116744055\n",
      "Iteration 1605 => Loss: 31.1028847004\n",
      "Iteration 1606 => Loss: 31.0941043385\n",
      "Iteration 1607 => Loss: 31.0853333101\n",
      "Iteration 1608 => Loss: 31.0765716050\n",
      "Iteration 1609 => Loss: 31.0678192134\n",
      "Iteration 1610 => Loss: 31.0590761255\n",
      "Iteration 1611 => Loss: 31.0503423312\n",
      "Iteration 1612 => Loss: 31.0416178208\n",
      "Iteration 1613 => Loss: 31.0329025844\n",
      "Iteration 1614 => Loss: 31.0241966120\n",
      "Iteration 1615 => Loss: 31.0154998940\n",
      "Iteration 1616 => Loss: 31.0068124203\n",
      "Iteration 1617 => Loss: 30.9981341813\n",
      "Iteration 1618 => Loss: 30.9894651671\n",
      "Iteration 1619 => Loss: 30.9808053678\n",
      "Iteration 1620 => Loss: 30.9721547737\n",
      "Iteration 1621 => Loss: 30.9635133750\n",
      "Iteration 1622 => Loss: 30.9548811619\n",
      "Iteration 1623 => Loss: 30.9462581247\n",
      "Iteration 1624 => Loss: 30.9376442536\n",
      "Iteration 1625 => Loss: 30.9290395389\n",
      "Iteration 1626 => Loss: 30.9204439708\n",
      "Iteration 1627 => Loss: 30.9118575396\n",
      "Iteration 1628 => Loss: 30.9032802355\n",
      "Iteration 1629 => Loss: 30.8947120490\n",
      "Iteration 1630 => Loss: 30.8861529703\n",
      "Iteration 1631 => Loss: 30.8776029897\n",
      "Iteration 1632 => Loss: 30.8690620975\n",
      "Iteration 1633 => Loss: 30.8605302842\n",
      "Iteration 1634 => Loss: 30.8520075399\n",
      "Iteration 1635 => Loss: 30.8434938552\n",
      "Iteration 1636 => Loss: 30.8349892203\n",
      "Iteration 1637 => Loss: 30.8264936257\n",
      "Iteration 1638 => Loss: 30.8180070617\n",
      "Iteration 1639 => Loss: 30.8095295188\n",
      "Iteration 1640 => Loss: 30.8010609873\n",
      "Iteration 1641 => Loss: 30.7926014577\n",
      "Iteration 1642 => Loss: 30.7841509203\n",
      "Iteration 1643 => Loss: 30.7757093657\n",
      "Iteration 1644 => Loss: 30.7672767843\n",
      "Iteration 1645 => Loss: 30.7588531666\n",
      "Iteration 1646 => Loss: 30.7504385030\n",
      "Iteration 1647 => Loss: 30.7420327840\n",
      "Iteration 1648 => Loss: 30.7336360001\n",
      "Iteration 1649 => Loss: 30.7252481418\n",
      "Iteration 1650 => Loss: 30.7168691996\n",
      "Iteration 1651 => Loss: 30.7084991640\n",
      "Iteration 1652 => Loss: 30.7001380256\n",
      "Iteration 1653 => Loss: 30.6917857750\n",
      "Iteration 1654 => Loss: 30.6834424026\n",
      "Iteration 1655 => Loss: 30.6751078990\n",
      "Iteration 1656 => Loss: 30.6667822548\n",
      "Iteration 1657 => Loss: 30.6584654606\n",
      "Iteration 1658 => Loss: 30.6501575070\n",
      "Iteration 1659 => Loss: 30.6418583846\n",
      "Iteration 1660 => Loss: 30.6335680839\n",
      "Iteration 1661 => Loss: 30.6252865957\n",
      "Iteration 1662 => Loss: 30.6170139105\n",
      "Iteration 1663 => Loss: 30.6087500190\n",
      "Iteration 1664 => Loss: 30.6004949119\n",
      "Iteration 1665 => Loss: 30.5922485797\n",
      "Iteration 1666 => Loss: 30.5840110132\n",
      "Iteration 1667 => Loss: 30.5757822031\n",
      "Iteration 1668 => Loss: 30.5675621400\n",
      "Iteration 1669 => Loss: 30.5593508147\n",
      "Iteration 1670 => Loss: 30.5511482179\n",
      "Iteration 1671 => Loss: 30.5429543402\n",
      "Iteration 1672 => Loss: 30.5347691725\n",
      "Iteration 1673 => Loss: 30.5265927054\n",
      "Iteration 1674 => Loss: 30.5184249297\n",
      "Iteration 1675 => Loss: 30.5102658362\n",
      "Iteration 1676 => Loss: 30.5021154156\n",
      "Iteration 1677 => Loss: 30.4939736588\n",
      "Iteration 1678 => Loss: 30.4858405564\n",
      "Iteration 1679 => Loss: 30.4777160994\n",
      "Iteration 1680 => Loss: 30.4696002786\n",
      "Iteration 1681 => Loss: 30.4614930846\n",
      "Iteration 1682 => Loss: 30.4533945085\n",
      "Iteration 1683 => Loss: 30.4453045409\n",
      "Iteration 1684 => Loss: 30.4372231728\n",
      "Iteration 1685 => Loss: 30.4291503951\n",
      "Iteration 1686 => Loss: 30.4210861985\n",
      "Iteration 1687 => Loss: 30.4130305740\n",
      "Iteration 1688 => Loss: 30.4049835124\n",
      "Iteration 1689 => Loss: 30.3969450047\n",
      "Iteration 1690 => Loss: 30.3889150418\n",
      "Iteration 1691 => Loss: 30.3808936146\n",
      "Iteration 1692 => Loss: 30.3728807139\n",
      "Iteration 1693 => Loss: 30.3648763308\n",
      "Iteration 1694 => Loss: 30.3568804562\n",
      "Iteration 1695 => Loss: 30.3488930811\n",
      "Iteration 1696 => Loss: 30.3409141963\n",
      "Iteration 1697 => Loss: 30.3329437929\n",
      "Iteration 1698 => Loss: 30.3249818619\n",
      "Iteration 1699 => Loss: 30.3170283943\n",
      "Iteration 1700 => Loss: 30.3090833810\n",
      "Iteration 1701 => Loss: 30.3011468132\n",
      "Iteration 1702 => Loss: 30.2932186817\n",
      "Iteration 1703 => Loss: 30.2852989776\n",
      "Iteration 1704 => Loss: 30.2773876921\n",
      "Iteration 1705 => Loss: 30.2694848160\n",
      "Iteration 1706 => Loss: 30.2615903406\n",
      "Iteration 1707 => Loss: 30.2537042568\n",
      "Iteration 1708 => Loss: 30.2458265557\n",
      "Iteration 1709 => Loss: 30.2379572285\n",
      "Iteration 1710 => Loss: 30.2300962662\n",
      "Iteration 1711 => Loss: 30.2222436599\n",
      "Iteration 1712 => Loss: 30.2143994008\n",
      "Iteration 1713 => Loss: 30.2065634800\n",
      "Iteration 1714 => Loss: 30.1987358886\n",
      "Iteration 1715 => Loss: 30.1909166177\n",
      "Iteration 1716 => Loss: 30.1831056586\n",
      "Iteration 1717 => Loss: 30.1753030024\n",
      "Iteration 1718 => Loss: 30.1675086402\n",
      "Iteration 1719 => Loss: 30.1597225632\n",
      "Iteration 1720 => Loss: 30.1519447627\n",
      "Iteration 1721 => Loss: 30.1441752298\n",
      "Iteration 1722 => Loss: 30.1364139558\n",
      "Iteration 1723 => Loss: 30.1286609319\n",
      "Iteration 1724 => Loss: 30.1209161492\n",
      "Iteration 1725 => Loss: 30.1131795991\n",
      "Iteration 1726 => Loss: 30.1054512728\n",
      "Iteration 1727 => Loss: 30.0977311615\n",
      "Iteration 1728 => Loss: 30.0900192565\n",
      "Iteration 1729 => Loss: 30.0823155491\n",
      "Iteration 1730 => Loss: 30.0746200306\n",
      "Iteration 1731 => Loss: 30.0669326923\n",
      "Iteration 1732 => Loss: 30.0592535255\n",
      "Iteration 1733 => Loss: 30.0515825214\n",
      "Iteration 1734 => Loss: 30.0439196715\n",
      "Iteration 1735 => Loss: 30.0362649670\n",
      "Iteration 1736 => Loss: 30.0286183993\n",
      "Iteration 1737 => Loss: 30.0209799597\n",
      "Iteration 1738 => Loss: 30.0133496396\n",
      "Iteration 1739 => Loss: 30.0057274304\n",
      "Iteration 1740 => Loss: 29.9981133235\n",
      "Iteration 1741 => Loss: 29.9905073102\n",
      "Iteration 1742 => Loss: 29.9829093819\n",
      "Iteration 1743 => Loss: 29.9753195300\n",
      "Iteration 1744 => Loss: 29.9677377460\n",
      "Iteration 1745 => Loss: 29.9601640213\n",
      "Iteration 1746 => Loss: 29.9525983473\n",
      "Iteration 1747 => Loss: 29.9450407154\n",
      "Iteration 1748 => Loss: 29.9374911171\n",
      "Iteration 1749 => Loss: 29.9299495439\n",
      "Iteration 1750 => Loss: 29.9224159872\n",
      "Iteration 1751 => Loss: 29.9148904386\n",
      "Iteration 1752 => Loss: 29.9073728894\n",
      "Iteration 1753 => Loss: 29.8998633313\n",
      "Iteration 1754 => Loss: 29.8923617556\n",
      "Iteration 1755 => Loss: 29.8848681539\n",
      "Iteration 1756 => Loss: 29.8773825178\n",
      "Iteration 1757 => Loss: 29.8699048388\n",
      "Iteration 1758 => Loss: 29.8624351084\n",
      "Iteration 1759 => Loss: 29.8549733181\n",
      "Iteration 1760 => Loss: 29.8475194596\n",
      "Iteration 1761 => Loss: 29.8400735243\n",
      "Iteration 1762 => Loss: 29.8326355040\n",
      "Iteration 1763 => Loss: 29.8252053900\n",
      "Iteration 1764 => Loss: 29.8177831742\n",
      "Iteration 1765 => Loss: 29.8103688480\n",
      "Iteration 1766 => Loss: 29.8029624030\n",
      "Iteration 1767 => Loss: 29.7955638310\n",
      "Iteration 1768 => Loss: 29.7881731235\n",
      "Iteration 1769 => Loss: 29.7807902721\n",
      "Iteration 1770 => Loss: 29.7734152686\n",
      "Iteration 1771 => Loss: 29.7660481045\n",
      "Iteration 1772 => Loss: 29.7586887716\n",
      "Iteration 1773 => Loss: 29.7513372615\n",
      "Iteration 1774 => Loss: 29.7439935659\n",
      "Iteration 1775 => Loss: 29.7366576765\n",
      "Iteration 1776 => Loss: 29.7293295850\n",
      "Iteration 1777 => Loss: 29.7220092831\n",
      "Iteration 1778 => Loss: 29.7146967625\n",
      "Iteration 1779 => Loss: 29.7073920149\n",
      "Iteration 1780 => Loss: 29.7000950322\n",
      "Iteration 1781 => Loss: 29.6928058060\n",
      "Iteration 1782 => Loss: 29.6855243281\n",
      "Iteration 1783 => Loss: 29.6782505902\n",
      "Iteration 1784 => Loss: 29.6709845842\n",
      "Iteration 1785 => Loss: 29.6637263017\n",
      "Iteration 1786 => Loss: 29.6564757347\n",
      "Iteration 1787 => Loss: 29.6492328749\n",
      "Iteration 1788 => Loss: 29.6419977141\n",
      "Iteration 1789 => Loss: 29.6347702441\n",
      "Iteration 1790 => Loss: 29.6275504568\n",
      "Iteration 1791 => Loss: 29.6203383439\n",
      "Iteration 1792 => Loss: 29.6131338973\n",
      "Iteration 1793 => Loss: 29.6059371090\n",
      "Iteration 1794 => Loss: 29.5987479706\n",
      "Iteration 1795 => Loss: 29.5915664742\n",
      "Iteration 1796 => Loss: 29.5843926115\n",
      "Iteration 1797 => Loss: 29.5772263746\n",
      "Iteration 1798 => Loss: 29.5700677551\n",
      "Iteration 1799 => Loss: 29.5629167451\n",
      "Iteration 1800 => Loss: 29.5557733365\n",
      "Iteration 1801 => Loss: 29.5486375212\n",
      "Iteration 1802 => Loss: 29.5415092911\n",
      "Iteration 1803 => Loss: 29.5343886382\n",
      "Iteration 1804 => Loss: 29.5272755544\n",
      "Iteration 1805 => Loss: 29.5201700316\n",
      "Iteration 1806 => Loss: 29.5130720618\n",
      "Iteration 1807 => Loss: 29.5059816371\n",
      "Iteration 1808 => Loss: 29.4988987493\n",
      "Iteration 1809 => Loss: 29.4918233905\n",
      "Iteration 1810 => Loss: 29.4847555526\n",
      "Iteration 1811 => Loss: 29.4776952277\n",
      "Iteration 1812 => Loss: 29.4706424077\n",
      "Iteration 1813 => Loss: 29.4635970848\n",
      "Iteration 1814 => Loss: 29.4565592509\n",
      "Iteration 1815 => Loss: 29.4495288980\n",
      "Iteration 1816 => Loss: 29.4425060183\n",
      "Iteration 1817 => Loss: 29.4354906037\n",
      "Iteration 1818 => Loss: 29.4284826464\n",
      "Iteration 1819 => Loss: 29.4214821384\n",
      "Iteration 1820 => Loss: 29.4144890718\n",
      "Iteration 1821 => Loss: 29.4075034386\n",
      "Iteration 1822 => Loss: 29.4005252311\n",
      "Iteration 1823 => Loss: 29.3935544412\n",
      "Iteration 1824 => Loss: 29.3865910611\n",
      "Iteration 1825 => Loss: 29.3796350830\n",
      "Iteration 1826 => Loss: 29.3726864989\n",
      "Iteration 1827 => Loss: 29.3657453010\n",
      "Iteration 1828 => Loss: 29.3588114815\n",
      "Iteration 1829 => Loss: 29.3518850324\n",
      "Iteration 1830 => Loss: 29.3449659461\n",
      "Iteration 1831 => Loss: 29.3380542145\n",
      "Iteration 1832 => Loss: 29.3311498300\n",
      "Iteration 1833 => Loss: 29.3242527847\n",
      "Iteration 1834 => Loss: 29.3173630708\n",
      "Iteration 1835 => Loss: 29.3104806806\n",
      "Iteration 1836 => Loss: 29.3036056061\n",
      "Iteration 1837 => Loss: 29.2967378398\n",
      "Iteration 1838 => Loss: 29.2898773737\n",
      "Iteration 1839 => Loss: 29.2830242001\n",
      "Iteration 1840 => Loss: 29.2761783114\n",
      "Iteration 1841 => Loss: 29.2693396996\n",
      "Iteration 1842 => Loss: 29.2625083572\n",
      "Iteration 1843 => Loss: 29.2556842763\n",
      "Iteration 1844 => Loss: 29.2488674493\n",
      "Iteration 1845 => Loss: 29.2420578684\n",
      "Iteration 1846 => Loss: 29.2352555260\n",
      "Iteration 1847 => Loss: 29.2284604143\n",
      "Iteration 1848 => Loss: 29.2216725257\n",
      "Iteration 1849 => Loss: 29.2148918524\n",
      "Iteration 1850 => Loss: 29.2081183869\n",
      "Iteration 1851 => Loss: 29.2013521214\n",
      "Iteration 1852 => Loss: 29.1945930483\n",
      "Iteration 1853 => Loss: 29.1878411600\n",
      "Iteration 1854 => Loss: 29.1810964488\n",
      "Iteration 1855 => Loss: 29.1743589070\n",
      "Iteration 1856 => Loss: 29.1676285272\n",
      "Iteration 1857 => Loss: 29.1609053015\n",
      "Iteration 1858 => Loss: 29.1541892226\n",
      "Iteration 1859 => Loss: 29.1474802826\n",
      "Iteration 1860 => Loss: 29.1407784742\n",
      "Iteration 1861 => Loss: 29.1340837896\n",
      "Iteration 1862 => Loss: 29.1273962213\n",
      "Iteration 1863 => Loss: 29.1207157618\n",
      "Iteration 1864 => Loss: 29.1140424034\n",
      "Iteration 1865 => Loss: 29.1073761387\n",
      "Iteration 1866 => Loss: 29.1007169601\n",
      "Iteration 1867 => Loss: 29.0940648600\n",
      "Iteration 1868 => Loss: 29.0874198310\n",
      "Iteration 1869 => Loss: 29.0807818655\n",
      "Iteration 1870 => Loss: 29.0741509561\n",
      "Iteration 1871 => Loss: 29.0675270951\n",
      "Iteration 1872 => Loss: 29.0609102752\n",
      "Iteration 1873 => Loss: 29.0543004888\n",
      "Iteration 1874 => Loss: 29.0476977285\n",
      "Iteration 1875 => Loss: 29.0411019868\n",
      "Iteration 1876 => Loss: 29.0345132562\n",
      "Iteration 1877 => Loss: 29.0279315292\n",
      "Iteration 1878 => Loss: 29.0213567986\n",
      "Iteration 1879 => Loss: 29.0147890567\n",
      "Iteration 1880 => Loss: 29.0082282962\n",
      "Iteration 1881 => Loss: 29.0016745096\n",
      "Iteration 1882 => Loss: 28.9951276896\n",
      "Iteration 1883 => Loss: 28.9885878287\n",
      "Iteration 1884 => Loss: 28.9820549195\n",
      "Iteration 1885 => Loss: 28.9755289547\n",
      "Iteration 1886 => Loss: 28.9690099268\n",
      "Iteration 1887 => Loss: 28.9624978286\n",
      "Iteration 1888 => Loss: 28.9559926525\n",
      "Iteration 1889 => Loss: 28.9494943913\n",
      "Iteration 1890 => Loss: 28.9430030377\n",
      "Iteration 1891 => Loss: 28.9365185842\n",
      "Iteration 1892 => Loss: 28.9300410235\n",
      "Iteration 1893 => Loss: 28.9235703483\n",
      "Iteration 1894 => Loss: 28.9171065514\n",
      "Iteration 1895 => Loss: 28.9106496253\n",
      "Iteration 1896 => Loss: 28.9041995628\n",
      "Iteration 1897 => Loss: 28.8977563565\n",
      "Iteration 1898 => Loss: 28.8913199993\n",
      "Iteration 1899 => Loss: 28.8848904838\n",
      "Iteration 1900 => Loss: 28.8784678027\n",
      "Iteration 1901 => Loss: 28.8720519488\n",
      "Iteration 1902 => Loss: 28.8656429148\n",
      "Iteration 1903 => Loss: 28.8592406934\n",
      "Iteration 1904 => Loss: 28.8528452775\n",
      "Iteration 1905 => Loss: 28.8464566598\n",
      "Iteration 1906 => Loss: 28.8400748331\n",
      "Iteration 1907 => Loss: 28.8336997901\n",
      "Iteration 1908 => Loss: 28.8273315236\n",
      "Iteration 1909 => Loss: 28.8209700265\n",
      "Iteration 1910 => Loss: 28.8146152915\n",
      "Iteration 1911 => Loss: 28.8082673114\n",
      "Iteration 1912 => Loss: 28.8019260791\n",
      "Iteration 1913 => Loss: 28.7955915874\n",
      "Iteration 1914 => Loss: 28.7892638292\n",
      "Iteration 1915 => Loss: 28.7829427972\n",
      "Iteration 1916 => Loss: 28.7766284843\n",
      "Iteration 1917 => Loss: 28.7703208834\n",
      "Iteration 1918 => Loss: 28.7640199874\n",
      "Iteration 1919 => Loss: 28.7577257891\n",
      "Iteration 1920 => Loss: 28.7514382814\n",
      "Iteration 1921 => Loss: 28.7451574571\n",
      "Iteration 1922 => Loss: 28.7388833093\n",
      "Iteration 1923 => Loss: 28.7326158307\n",
      "Iteration 1924 => Loss: 28.7263550143\n",
      "Iteration 1925 => Loss: 28.7201008531\n",
      "Iteration 1926 => Loss: 28.7138533399\n",
      "Iteration 1927 => Loss: 28.7076124676\n",
      "Iteration 1928 => Loss: 28.7013782293\n",
      "Iteration 1929 => Loss: 28.6951506179\n",
      "Iteration 1930 => Loss: 28.6889296262\n",
      "Iteration 1931 => Loss: 28.6827152474\n",
      "Iteration 1932 => Loss: 28.6765074742\n",
      "Iteration 1933 => Loss: 28.6703062999\n",
      "Iteration 1934 => Loss: 28.6641117172\n",
      "Iteration 1935 => Loss: 28.6579237193\n",
      "Iteration 1936 => Loss: 28.6517422990\n",
      "Iteration 1937 => Loss: 28.6455674495\n",
      "Iteration 1938 => Loss: 28.6393991637\n",
      "Iteration 1939 => Loss: 28.6332374347\n",
      "Iteration 1940 => Loss: 28.6270822554\n",
      "Iteration 1941 => Loss: 28.6209336190\n",
      "Iteration 1942 => Loss: 28.6147915185\n",
      "Iteration 1943 => Loss: 28.6086559468\n",
      "Iteration 1944 => Loss: 28.6025268972\n",
      "Iteration 1945 => Loss: 28.5964043626\n",
      "Iteration 1946 => Loss: 28.5902883361\n",
      "Iteration 1947 => Loss: 28.5841788109\n",
      "Iteration 1948 => Loss: 28.5780757799\n",
      "Iteration 1949 => Loss: 28.5719792363\n",
      "Iteration 1950 => Loss: 28.5658891732\n",
      "Iteration 1951 => Loss: 28.5598055838\n",
      "Iteration 1952 => Loss: 28.5537284610\n",
      "Iteration 1953 => Loss: 28.5476577981\n",
      "Iteration 1954 => Loss: 28.5415935882\n",
      "Iteration 1955 => Loss: 28.5355358244\n",
      "Iteration 1956 => Loss: 28.5294844999\n",
      "Iteration 1957 => Loss: 28.5234396079\n",
      "Iteration 1958 => Loss: 28.5174011414\n",
      "Iteration 1959 => Loss: 28.5113690936\n",
      "Iteration 1960 => Loss: 28.5053434579\n",
      "Iteration 1961 => Loss: 28.4993242272\n",
      "Iteration 1962 => Loss: 28.4933113949\n",
      "Iteration 1963 => Loss: 28.4873049540\n",
      "Iteration 1964 => Loss: 28.4813048979\n",
      "Iteration 1965 => Loss: 28.4753112197\n",
      "Iteration 1966 => Loss: 28.4693239127\n",
      "Iteration 1967 => Loss: 28.4633429700\n",
      "Iteration 1968 => Loss: 28.4573683850\n",
      "Iteration 1969 => Loss: 28.4514001508\n",
      "Iteration 1970 => Loss: 28.4454382607\n",
      "Iteration 1971 => Loss: 28.4394827080\n",
      "Iteration 1972 => Loss: 28.4335334859\n",
      "Iteration 1973 => Loss: 28.4275905878\n",
      "Iteration 1974 => Loss: 28.4216540067\n",
      "Iteration 1975 => Loss: 28.4157237362\n",
      "Iteration 1976 => Loss: 28.4097997694\n",
      "Iteration 1977 => Loss: 28.4038820996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1978 => Loss: 28.3979707202\n",
      "Iteration 1979 => Loss: 28.3920656245\n",
      "Iteration 1980 => Loss: 28.3861668058\n",
      "Iteration 1981 => Loss: 28.3802742574\n",
      "Iteration 1982 => Loss: 28.3743879726\n",
      "Iteration 1983 => Loss: 28.3685079448\n",
      "Iteration 1984 => Loss: 28.3626341674\n",
      "Iteration 1985 => Loss: 28.3567666337\n",
      "Iteration 1986 => Loss: 28.3509053371\n",
      "Iteration 1987 => Loss: 28.3450502708\n",
      "Iteration 1988 => Loss: 28.3392014284\n",
      "Iteration 1989 => Loss: 28.3333588032\n",
      "Iteration 1990 => Loss: 28.3275223886\n",
      "Iteration 1991 => Loss: 28.3216921779\n",
      "Iteration 1992 => Loss: 28.3158681647\n",
      "Iteration 1993 => Loss: 28.3100503422\n",
      "Iteration 1994 => Loss: 28.3042387040\n",
      "Iteration 1995 => Loss: 28.2984332434\n",
      "Iteration 1996 => Loss: 28.2926339539\n",
      "Iteration 1997 => Loss: 28.2868408289\n",
      "Iteration 1998 => Loss: 28.2810538619\n",
      "Iteration 1999 => Loss: 28.2752730463\n",
      "Iteration 2000 => Loss: 28.2694983756\n",
      "Iteration 2001 => Loss: 28.2637298433\n",
      "Iteration 2002 => Loss: 28.2579674428\n",
      "Iteration 2003 => Loss: 28.2522111676\n",
      "Iteration 2004 => Loss: 28.2464610111\n",
      "Iteration 2005 => Loss: 28.2407169670\n",
      "Iteration 2006 => Loss: 28.2349790287\n",
      "Iteration 2007 => Loss: 28.2292471897\n",
      "Iteration 2008 => Loss: 28.2235214435\n",
      "Iteration 2009 => Loss: 28.2178017836\n",
      "Iteration 2010 => Loss: 28.2120882037\n",
      "Iteration 2011 => Loss: 28.2063806971\n",
      "Iteration 2012 => Loss: 28.2006792575\n",
      "Iteration 2013 => Loss: 28.1949838784\n",
      "Iteration 2014 => Loss: 28.1892945534\n",
      "Iteration 2015 => Loss: 28.1836112760\n",
      "Iteration 2016 => Loss: 28.1779340398\n",
      "Iteration 2017 => Loss: 28.1722628384\n",
      "Iteration 2018 => Loss: 28.1665976654\n",
      "Iteration 2019 => Loss: 28.1609385143\n",
      "Iteration 2020 => Loss: 28.1552853788\n",
      "Iteration 2021 => Loss: 28.1496382524\n",
      "Iteration 2022 => Loss: 28.1439971288\n",
      "Iteration 2023 => Loss: 28.1383620016\n",
      "Iteration 2024 => Loss: 28.1327328645\n",
      "Iteration 2025 => Loss: 28.1271097109\n",
      "Iteration 2026 => Loss: 28.1214925347\n",
      "Iteration 2027 => Loss: 28.1158813294\n",
      "Iteration 2028 => Loss: 28.1102760887\n",
      "Iteration 2029 => Loss: 28.1046768063\n",
      "Iteration 2030 => Loss: 28.0990834758\n",
      "Iteration 2031 => Loss: 28.0934960908\n",
      "Iteration 2032 => Loss: 28.0879146452\n",
      "Iteration 2033 => Loss: 28.0823391325\n",
      "Iteration 2034 => Loss: 28.0767695464\n",
      "Iteration 2035 => Loss: 28.0712058807\n",
      "Iteration 2036 => Loss: 28.0656481291\n",
      "Iteration 2037 => Loss: 28.0600962852\n",
      "Iteration 2038 => Loss: 28.0545503429\n",
      "Iteration 2039 => Loss: 28.0490102957\n",
      "Iteration 2040 => Loss: 28.0434761375\n",
      "Iteration 2041 => Loss: 28.0379478620\n",
      "Iteration 2042 => Loss: 28.0324254629\n",
      "Iteration 2043 => Loss: 28.0269089340\n",
      "Iteration 2044 => Loss: 28.0213982691\n",
      "Iteration 2045 => Loss: 28.0158934619\n",
      "Iteration 2046 => Loss: 28.0103945062\n",
      "Iteration 2047 => Loss: 28.0049013957\n",
      "Iteration 2048 => Loss: 27.9994141244\n",
      "Iteration 2049 => Loss: 27.9939326858\n",
      "Iteration 2050 => Loss: 27.9884570739\n",
      "Iteration 2051 => Loss: 27.9829872825\n",
      "Iteration 2052 => Loss: 27.9775233054\n",
      "Iteration 2053 => Loss: 27.9720651363\n",
      "Iteration 2054 => Loss: 27.9666127692\n",
      "Iteration 2055 => Loss: 27.9611661978\n",
      "Iteration 2056 => Loss: 27.9557254160\n",
      "Iteration 2057 => Loss: 27.9502904177\n",
      "Iteration 2058 => Loss: 27.9448611966\n",
      "Iteration 2059 => Loss: 27.9394377467\n",
      "Iteration 2060 => Loss: 27.9340200618\n",
      "Iteration 2061 => Loss: 27.9286081357\n",
      "Iteration 2062 => Loss: 27.9232019625\n",
      "Iteration 2063 => Loss: 27.9178015358\n",
      "Iteration 2064 => Loss: 27.9124068498\n",
      "Iteration 2065 => Loss: 27.9070178981\n",
      "Iteration 2066 => Loss: 27.9016346748\n",
      "Iteration 2067 => Loss: 27.8962571738\n",
      "Iteration 2068 => Loss: 27.8908853889\n",
      "Iteration 2069 => Loss: 27.8855193141\n",
      "Iteration 2070 => Loss: 27.8801589433\n",
      "Iteration 2071 => Loss: 27.8748042705\n",
      "Iteration 2072 => Loss: 27.8694552896\n",
      "Iteration 2073 => Loss: 27.8641119946\n",
      "Iteration 2074 => Loss: 27.8587743793\n",
      "Iteration 2075 => Loss: 27.8534424379\n",
      "Iteration 2076 => Loss: 27.8481161641\n",
      "Iteration 2077 => Loss: 27.8427955521\n",
      "Iteration 2078 => Loss: 27.8374805958\n",
      "Iteration 2079 => Loss: 27.8321712892\n",
      "Iteration 2080 => Loss: 27.8268676262\n",
      "Iteration 2081 => Loss: 27.8215696010\n",
      "Iteration 2082 => Loss: 27.8162772074\n",
      "Iteration 2083 => Loss: 27.8109904395\n",
      "Iteration 2084 => Loss: 27.8057092914\n",
      "Iteration 2085 => Loss: 27.8004337570\n",
      "Iteration 2086 => Loss: 27.7951638303\n",
      "Iteration 2087 => Loss: 27.7898995055\n",
      "Iteration 2088 => Loss: 27.7846407766\n",
      "Iteration 2089 => Loss: 27.7793876376\n",
      "Iteration 2090 => Loss: 27.7741400825\n",
      "Iteration 2091 => Loss: 27.7688981055\n",
      "Iteration 2092 => Loss: 27.7636617006\n",
      "Iteration 2093 => Loss: 27.7584308619\n",
      "Iteration 2094 => Loss: 27.7532055835\n",
      "Iteration 2095 => Loss: 27.7479858594\n",
      "Iteration 2096 => Loss: 27.7427716838\n",
      "Iteration 2097 => Loss: 27.7375630507\n",
      "Iteration 2098 => Loss: 27.7323599543\n",
      "Iteration 2099 => Loss: 27.7271623887\n",
      "Iteration 2100 => Loss: 27.7219703480\n",
      "Iteration 2101 => Loss: 27.7167838263\n",
      "Iteration 2102 => Loss: 27.7116028178\n",
      "Iteration 2103 => Loss: 27.7064273165\n",
      "Iteration 2104 => Loss: 27.7012573168\n",
      "Iteration 2105 => Loss: 27.6960928126\n",
      "Iteration 2106 => Loss: 27.6909337982\n",
      "Iteration 2107 => Loss: 27.6857802677\n",
      "Iteration 2108 => Loss: 27.6806322153\n",
      "Iteration 2109 => Loss: 27.6754896352\n",
      "Iteration 2110 => Loss: 27.6703525215\n",
      "Iteration 2111 => Loss: 27.6652208684\n",
      "Iteration 2112 => Loss: 27.6600946702\n",
      "Iteration 2113 => Loss: 27.6549739211\n",
      "Iteration 2114 => Loss: 27.6498586152\n",
      "Iteration 2115 => Loss: 27.6447487467\n",
      "Iteration 2116 => Loss: 27.6396443100\n",
      "Iteration 2117 => Loss: 27.6345452991\n",
      "Iteration 2118 => Loss: 27.6294517084\n",
      "Iteration 2119 => Loss: 27.6243635321\n",
      "Iteration 2120 => Loss: 27.6192807643\n",
      "Iteration 2121 => Loss: 27.6142033995\n",
      "Iteration 2122 => Loss: 27.6091314318\n",
      "Iteration 2123 => Loss: 27.6040648555\n",
      "Iteration 2124 => Loss: 27.5990036648\n",
      "Iteration 2125 => Loss: 27.5939478541\n",
      "Iteration 2126 => Loss: 27.5888974176\n",
      "Iteration 2127 => Loss: 27.5838523496\n",
      "Iteration 2128 => Loss: 27.5788126444\n",
      "Iteration 2129 => Loss: 27.5737782963\n",
      "Iteration 2130 => Loss: 27.5687492997\n",
      "Iteration 2131 => Loss: 27.5637256487\n",
      "Iteration 2132 => Loss: 27.5587073378\n",
      "Iteration 2133 => Loss: 27.5536943612\n",
      "Iteration 2134 => Loss: 27.5486867133\n",
      "Iteration 2135 => Loss: 27.5436843884\n",
      "Iteration 2136 => Loss: 27.5386873809\n",
      "Iteration 2137 => Loss: 27.5336956851\n",
      "Iteration 2138 => Loss: 27.5287092954\n",
      "Iteration 2139 => Loss: 27.5237282061\n",
      "Iteration 2140 => Loss: 27.5187524116\n",
      "Iteration 2141 => Loss: 27.5137819063\n",
      "Iteration 2142 => Loss: 27.5088166845\n",
      "Iteration 2143 => Loss: 27.5038567406\n",
      "Iteration 2144 => Loss: 27.4989020691\n",
      "Iteration 2145 => Loss: 27.4939526642\n",
      "Iteration 2146 => Loss: 27.4890085205\n",
      "Iteration 2147 => Loss: 27.4840696323\n",
      "Iteration 2148 => Loss: 27.4791359940\n",
      "Iteration 2149 => Loss: 27.4742076001\n",
      "Iteration 2150 => Loss: 27.4692844449\n",
      "Iteration 2151 => Loss: 27.4643665230\n",
      "Iteration 2152 => Loss: 27.4594538287\n",
      "Iteration 2153 => Loss: 27.4545463565\n",
      "Iteration 2154 => Loss: 27.4496441008\n",
      "Iteration 2155 => Loss: 27.4447470561\n",
      "Iteration 2156 => Loss: 27.4398552169\n",
      "Iteration 2157 => Loss: 27.4349685776\n",
      "Iteration 2158 => Loss: 27.4300871327\n",
      "Iteration 2159 => Loss: 27.4252108767\n",
      "Iteration 2160 => Loss: 27.4203398040\n",
      "Iteration 2161 => Loss: 27.4154739092\n",
      "Iteration 2162 => Loss: 27.4106131867\n",
      "Iteration 2163 => Loss: 27.4057576311\n",
      "Iteration 2164 => Loss: 27.4009072368\n",
      "Iteration 2165 => Loss: 27.3960619984\n",
      "Iteration 2166 => Loss: 27.3912219103\n",
      "Iteration 2167 => Loss: 27.3863869672\n",
      "Iteration 2168 => Loss: 27.3815571635\n",
      "Iteration 2169 => Loss: 27.3767324938\n",
      "Iteration 2170 => Loss: 27.3719129527\n",
      "Iteration 2171 => Loss: 27.3670985345\n",
      "Iteration 2172 => Loss: 27.3622892341\n",
      "Iteration 2173 => Loss: 27.3574850457\n",
      "Iteration 2174 => Loss: 27.3526859642\n",
      "Iteration 2175 => Loss: 27.3478919840\n",
      "Iteration 2176 => Loss: 27.3431030996\n",
      "Iteration 2177 => Loss: 27.3383193058\n",
      "Iteration 2178 => Loss: 27.3335405970\n",
      "Iteration 2179 => Loss: 27.3287669679\n",
      "Iteration 2180 => Loss: 27.3239984130\n",
      "Iteration 2181 => Loss: 27.3192349271\n",
      "Iteration 2182 => Loss: 27.3144765046\n",
      "Iteration 2183 => Loss: 27.3097231402\n",
      "Iteration 2184 => Loss: 27.3049748285\n",
      "Iteration 2185 => Loss: 27.3002315642\n",
      "Iteration 2186 => Loss: 27.2954933419\n",
      "Iteration 2187 => Loss: 27.2907601562\n",
      "Iteration 2188 => Loss: 27.2860320018\n",
      "Iteration 2189 => Loss: 27.2813088733\n",
      "Iteration 2190 => Loss: 27.2765907654\n",
      "Iteration 2191 => Loss: 27.2718776728\n",
      "Iteration 2192 => Loss: 27.2671695900\n",
      "Iteration 2193 => Loss: 27.2624665119\n",
      "Iteration 2194 => Loss: 27.2577684330\n",
      "Iteration 2195 => Loss: 27.2530753481\n",
      "Iteration 2196 => Loss: 27.2483872518\n",
      "Iteration 2197 => Loss: 27.2437041389\n",
      "Iteration 2198 => Loss: 27.2390260041\n",
      "Iteration 2199 => Loss: 27.2343528420\n",
      "Iteration 2200 => Loss: 27.2296846473\n",
      "Iteration 2201 => Loss: 27.2250214149\n",
      "Iteration 2202 => Loss: 27.2203631393\n",
      "Iteration 2203 => Loss: 27.2157098155\n",
      "Iteration 2204 => Loss: 27.2110614380\n",
      "Iteration 2205 => Loss: 27.2064180016\n",
      "Iteration 2206 => Loss: 27.2017795011\n",
      "Iteration 2207 => Loss: 27.1971459312\n",
      "Iteration 2208 => Loss: 27.1925172868\n",
      "Iteration 2209 => Loss: 27.1878935624\n",
      "Iteration 2210 => Loss: 27.1832747530\n",
      "Iteration 2211 => Loss: 27.1786608533\n",
      "Iteration 2212 => Loss: 27.1740518581\n",
      "Iteration 2213 => Loss: 27.1694477621\n",
      "Iteration 2214 => Loss: 27.1648485602\n",
      "Iteration 2215 => Loss: 27.1602542471\n",
      "Iteration 2216 => Loss: 27.1556648177\n",
      "Iteration 2217 => Loss: 27.1510802668\n",
      "Iteration 2218 => Loss: 27.1465005891\n",
      "Iteration 2219 => Loss: 27.1419257796\n",
      "Iteration 2220 => Loss: 27.1373558329\n",
      "Iteration 2221 => Loss: 27.1327907441\n",
      "Iteration 2222 => Loss: 27.1282305078\n",
      "Iteration 2223 => Loss: 27.1236751189\n",
      "Iteration 2224 => Loss: 27.1191245724\n",
      "Iteration 2225 => Loss: 27.1145788629\n",
      "Iteration 2226 => Loss: 27.1100379855\n",
      "Iteration 2227 => Loss: 27.1055019349\n",
      "Iteration 2228 => Loss: 27.1009707060\n",
      "Iteration 2229 => Loss: 27.0964442938\n",
      "Iteration 2230 => Loss: 27.0919226930\n",
      "Iteration 2231 => Loss: 27.0874058986\n",
      "Iteration 2232 => Loss: 27.0828939054\n",
      "Iteration 2233 => Loss: 27.0783867084\n",
      "Iteration 2234 => Loss: 27.0738843025\n",
      "Iteration 2235 => Loss: 27.0693866825\n",
      "Iteration 2236 => Loss: 27.0648938434\n",
      "Iteration 2237 => Loss: 27.0604057801\n",
      "Iteration 2238 => Loss: 27.0559224875\n",
      "Iteration 2239 => Loss: 27.0514439605\n",
      "Iteration 2240 => Loss: 27.0469701941\n",
      "Iteration 2241 => Loss: 27.0425011833\n",
      "Iteration 2242 => Loss: 27.0380369229\n",
      "Iteration 2243 => Loss: 27.0335774079\n",
      "Iteration 2244 => Loss: 27.0291226333\n",
      "Iteration 2245 => Loss: 27.0246725940\n",
      "Iteration 2246 => Loss: 27.0202272850\n",
      "Iteration 2247 => Loss: 27.0157867013\n",
      "Iteration 2248 => Loss: 27.0113508378\n",
      "Iteration 2249 => Loss: 27.0069196896\n",
      "Iteration 2250 => Loss: 27.0024932515\n",
      "Iteration 2251 => Loss: 26.9980715187\n",
      "Iteration 2252 => Loss: 26.9936544861\n",
      "Iteration 2253 => Loss: 26.9892421487\n",
      "Iteration 2254 => Loss: 26.9848345015\n",
      "Iteration 2255 => Loss: 26.9804315396\n",
      "Iteration 2256 => Loss: 26.9760332579\n",
      "Iteration 2257 => Loss: 26.9716396515\n",
      "Iteration 2258 => Loss: 26.9672507154\n",
      "Iteration 2259 => Loss: 26.9628664447\n",
      "Iteration 2260 => Loss: 26.9584868343\n",
      "Iteration 2261 => Loss: 26.9541118794\n",
      "Iteration 2262 => Loss: 26.9497415749\n",
      "Iteration 2263 => Loss: 26.9453759160\n",
      "Iteration 2264 => Loss: 26.9410148977\n",
      "Iteration 2265 => Loss: 26.9366585151\n",
      "Iteration 2266 => Loss: 26.9323067632\n",
      "Iteration 2267 => Loss: 26.9279596371\n",
      "Iteration 2268 => Loss: 26.9236171319\n",
      "Iteration 2269 => Loss: 26.9192792428\n",
      "Iteration 2270 => Loss: 26.9149459647\n",
      "Iteration 2271 => Loss: 26.9106172928\n",
      "Iteration 2272 => Loss: 26.9062932221\n",
      "Iteration 2273 => Loss: 26.9019737479\n",
      "Iteration 2274 => Loss: 26.8976588652\n",
      "Iteration 2275 => Loss: 26.8933485691\n",
      "Iteration 2276 => Loss: 26.8890428548\n",
      "Iteration 2277 => Loss: 26.8847417173\n",
      "Iteration 2278 => Loss: 26.8804451519\n",
      "Iteration 2279 => Loss: 26.8761531536\n",
      "Iteration 2280 => Loss: 26.8718657176\n",
      "Iteration 2281 => Loss: 26.8675828391\n",
      "Iteration 2282 => Loss: 26.8633045132\n",
      "Iteration 2283 => Loss: 26.8590307350\n",
      "Iteration 2284 => Loss: 26.8547614998\n",
      "Iteration 2285 => Loss: 26.8504968027\n",
      "Iteration 2286 => Loss: 26.8462366389\n",
      "Iteration 2287 => Loss: 26.8419810035\n",
      "Iteration 2288 => Loss: 26.8377298918\n",
      "Iteration 2289 => Loss: 26.8334832990\n",
      "Iteration 2290 => Loss: 26.8292412202\n",
      "Iteration 2291 => Loss: 26.8250036506\n",
      "Iteration 2292 => Loss: 26.8207705854\n",
      "Iteration 2293 => Loss: 26.8165420199\n",
      "Iteration 2294 => Loss: 26.8123179493\n",
      "Iteration 2295 => Loss: 26.8080983688\n",
      "Iteration 2296 => Loss: 26.8038832736\n",
      "Iteration 2297 => Loss: 26.7996726590\n",
      "Iteration 2298 => Loss: 26.7954665202\n",
      "Iteration 2299 => Loss: 26.7912648524\n",
      "Iteration 2300 => Loss: 26.7870676509\n",
      "Iteration 2301 => Loss: 26.7828749109\n",
      "Iteration 2302 => Loss: 26.7786866277\n",
      "Iteration 2303 => Loss: 26.7745027966\n",
      "Iteration 2304 => Loss: 26.7703234128\n",
      "Iteration 2305 => Loss: 26.7661484715\n",
      "Iteration 2306 => Loss: 26.7619779682\n",
      "Iteration 2307 => Loss: 26.7578118980\n",
      "Iteration 2308 => Loss: 26.7536502563\n",
      "Iteration 2309 => Loss: 26.7494930383\n",
      "Iteration 2310 => Loss: 26.7453402393\n",
      "Iteration 2311 => Loss: 26.7411918547\n",
      "Iteration 2312 => Loss: 26.7370478797\n",
      "Iteration 2313 => Loss: 26.7329083097\n",
      "Iteration 2314 => Loss: 26.7287731400\n",
      "Iteration 2315 => Loss: 26.7246423658\n",
      "Iteration 2316 => Loss: 26.7205159826\n",
      "Iteration 2317 => Loss: 26.7163939856\n",
      "Iteration 2318 => Loss: 26.7122763702\n",
      "Iteration 2319 => Loss: 26.7081631318\n",
      "Iteration 2320 => Loss: 26.7040542656\n",
      "Iteration 2321 => Loss: 26.6999497671\n",
      "Iteration 2322 => Loss: 26.6958496316\n",
      "Iteration 2323 => Loss: 26.6917538544\n",
      "Iteration 2324 => Loss: 26.6876624310\n",
      "Iteration 2325 => Loss: 26.6835753567\n",
      "Iteration 2326 => Loss: 26.6794926268\n",
      "Iteration 2327 => Loss: 26.6754142368\n",
      "Iteration 2328 => Loss: 26.6713401820\n",
      "Iteration 2329 => Loss: 26.6672704579\n",
      "Iteration 2330 => Loss: 26.6632050598\n",
      "Iteration 2331 => Loss: 26.6591439831\n",
      "Iteration 2332 => Loss: 26.6550872233\n",
      "Iteration 2333 => Loss: 26.6510347757\n",
      "Iteration 2334 => Loss: 26.6469866357\n",
      "Iteration 2335 => Loss: 26.6429427989\n",
      "Iteration 2336 => Loss: 26.6389032606\n",
      "Iteration 2337 => Loss: 26.6348680162\n",
      "Iteration 2338 => Loss: 26.6308370612\n",
      "Iteration 2339 => Loss: 26.6268103910\n",
      "Iteration 2340 => Loss: 26.6227880011\n",
      "Iteration 2341 => Loss: 26.6187698869\n",
      "Iteration 2342 => Loss: 26.6147560439\n",
      "Iteration 2343 => Loss: 26.6107464675\n",
      "Iteration 2344 => Loss: 26.6067411532\n",
      "Iteration 2345 => Loss: 26.6027400964\n",
      "Iteration 2346 => Loss: 26.5987432927\n",
      "Iteration 2347 => Loss: 26.5947507375\n",
      "Iteration 2348 => Loss: 26.5907624263\n",
      "Iteration 2349 => Loss: 26.5867783546\n",
      "Iteration 2350 => Loss: 26.5827985179\n",
      "Iteration 2351 => Loss: 26.5788229117\n",
      "Iteration 2352 => Loss: 26.5748515315\n",
      "Iteration 2353 => Loss: 26.5708843727\n",
      "Iteration 2354 => Loss: 26.5669214310\n",
      "Iteration 2355 => Loss: 26.5629627017\n",
      "Iteration 2356 => Loss: 26.5590081806\n",
      "Iteration 2357 => Loss: 26.5550578630\n",
      "Iteration 2358 => Loss: 26.5511117445\n",
      "Iteration 2359 => Loss: 26.5471698206\n",
      "Iteration 2360 => Loss: 26.5432320869\n",
      "Iteration 2361 => Loss: 26.5392985390\n",
      "Iteration 2362 => Loss: 26.5353691723\n",
      "Iteration 2363 => Loss: 26.5314439824\n",
      "Iteration 2364 => Loss: 26.5275229650\n",
      "Iteration 2365 => Loss: 26.5236061155\n",
      "Iteration 2366 => Loss: 26.5196934295\n",
      "Iteration 2367 => Loss: 26.5157849027\n",
      "Iteration 2368 => Loss: 26.5118805305\n",
      "Iteration 2369 => Loss: 26.5079803086\n",
      "Iteration 2370 => Loss: 26.5040842325\n",
      "Iteration 2371 => Loss: 26.5001922979\n",
      "Iteration 2372 => Loss: 26.4963045003\n",
      "Iteration 2373 => Loss: 26.4924208354\n",
      "Iteration 2374 => Loss: 26.4885412987\n",
      "Iteration 2375 => Loss: 26.4846658859\n",
      "Iteration 2376 => Loss: 26.4807945926\n",
      "Iteration 2377 => Loss: 26.4769274144\n",
      "Iteration 2378 => Loss: 26.4730643469\n",
      "Iteration 2379 => Loss: 26.4692053857\n",
      "Iteration 2380 => Loss: 26.4653505266\n",
      "Iteration 2381 => Loss: 26.4614997651\n",
      "Iteration 2382 => Loss: 26.4576530968\n",
      "Iteration 2383 => Loss: 26.4538105175\n",
      "Iteration 2384 => Loss: 26.4499720228\n",
      "Iteration 2385 => Loss: 26.4461376083\n",
      "Iteration 2386 => Loss: 26.4423072697\n",
      "Iteration 2387 => Loss: 26.4384810027\n",
      "Iteration 2388 => Loss: 26.4346588029\n",
      "Iteration 2389 => Loss: 26.4308406661\n",
      "Iteration 2390 => Loss: 26.4270265878\n",
      "Iteration 2391 => Loss: 26.4232165639\n",
      "Iteration 2392 => Loss: 26.4194105898\n",
      "Iteration 2393 => Loss: 26.4156086615\n",
      "Iteration 2394 => Loss: 26.4118107746\n",
      "Iteration 2395 => Loss: 26.4080169247\n",
      "Iteration 2396 => Loss: 26.4042271076\n",
      "Iteration 2397 => Loss: 26.4004413189\n",
      "Iteration 2398 => Loss: 26.3966595545\n",
      "Iteration 2399 => Loss: 26.3928818101\n",
      "Iteration 2400 => Loss: 26.3891080813\n",
      "Iteration 2401 => Loss: 26.3853383639\n",
      "Iteration 2402 => Loss: 26.3815726536\n",
      "Iteration 2403 => Loss: 26.3778109462\n",
      "Iteration 2404 => Loss: 26.3740532374\n",
      "Iteration 2405 => Loss: 26.3702995229\n",
      "Iteration 2406 => Loss: 26.3665497986\n",
      "Iteration 2407 => Loss: 26.3628040602\n",
      "Iteration 2408 => Loss: 26.3590623034\n",
      "Iteration 2409 => Loss: 26.3553245240\n",
      "Iteration 2410 => Loss: 26.3515907178\n",
      "Iteration 2411 => Loss: 26.3478608806\n",
      "Iteration 2412 => Loss: 26.3441350080\n",
      "Iteration 2413 => Loss: 26.3404130961\n",
      "Iteration 2414 => Loss: 26.3366951404\n",
      "Iteration 2415 => Loss: 26.3329811368\n",
      "Iteration 2416 => Loss: 26.3292710812\n",
      "Iteration 2417 => Loss: 26.3255649692\n",
      "Iteration 2418 => Loss: 26.3218627968\n",
      "Iteration 2419 => Loss: 26.3181645597\n",
      "Iteration 2420 => Loss: 26.3144702537\n",
      "Iteration 2421 => Loss: 26.3107798747\n",
      "Iteration 2422 => Loss: 26.3070934185\n",
      "Iteration 2423 => Loss: 26.3034108810\n",
      "Iteration 2424 => Loss: 26.2997322579\n",
      "Iteration 2425 => Loss: 26.2960575451\n",
      "Iteration 2426 => Loss: 26.2923867384\n",
      "Iteration 2427 => Loss: 26.2887198337\n",
      "Iteration 2428 => Loss: 26.2850568269\n",
      "Iteration 2429 => Loss: 26.2813977137\n",
      "Iteration 2430 => Loss: 26.2777424902\n",
      "Iteration 2431 => Loss: 26.2740911520\n",
      "Iteration 2432 => Loss: 26.2704436952\n",
      "Iteration 2433 => Loss: 26.2668001155\n",
      "Iteration 2434 => Loss: 26.2631604088\n",
      "Iteration 2435 => Loss: 26.2595245711\n",
      "Iteration 2436 => Loss: 26.2558925982\n",
      "Iteration 2437 => Loss: 26.2522644860\n",
      "Iteration 2438 => Loss: 26.2486402305\n",
      "Iteration 2439 => Loss: 26.2450198274\n",
      "Iteration 2440 => Loss: 26.2414032727\n",
      "Iteration 2441 => Loss: 26.2377905624\n",
      "Iteration 2442 => Loss: 26.2341816923\n",
      "Iteration 2443 => Loss: 26.2305766584\n",
      "Iteration 2444 => Loss: 26.2269754565\n",
      "Iteration 2445 => Loss: 26.2233780826\n",
      "Iteration 2446 => Loss: 26.2197845327\n",
      "Iteration 2447 => Loss: 26.2161948026\n",
      "Iteration 2448 => Loss: 26.2126088883\n",
      "Iteration 2449 => Loss: 26.2090267858\n",
      "Iteration 2450 => Loss: 26.2054484910\n",
      "Iteration 2451 => Loss: 26.2018739998\n",
      "Iteration 2452 => Loss: 26.1983033083\n",
      "Iteration 2453 => Loss: 26.1947364123\n",
      "Iteration 2454 => Loss: 26.1911733078\n",
      "Iteration 2455 => Loss: 26.1876139909\n",
      "Iteration 2456 => Loss: 26.1840584574\n",
      "Iteration 2457 => Loss: 26.1805067034\n",
      "Iteration 2458 => Loss: 26.1769587248\n",
      "Iteration 2459 => Loss: 26.1734145177\n",
      "Iteration 2460 => Loss: 26.1698740779\n",
      "Iteration 2461 => Loss: 26.1663374016\n",
      "Iteration 2462 => Loss: 26.1628044847\n",
      "Iteration 2463 => Loss: 26.1592753232\n",
      "Iteration 2464 => Loss: 26.1557499131\n",
      "Iteration 2465 => Loss: 26.1522282505\n",
      "Iteration 2466 => Loss: 26.1487103313\n",
      "Iteration 2467 => Loss: 26.1451961516\n",
      "Iteration 2468 => Loss: 26.1416857074\n",
      "Iteration 2469 => Loss: 26.1381789947\n",
      "Iteration 2470 => Loss: 26.1346760096\n",
      "Iteration 2471 => Loss: 26.1311767481\n",
      "Iteration 2472 => Loss: 26.1276812062\n",
      "Iteration 2473 => Loss: 26.1241893800\n",
      "Iteration 2474 => Loss: 26.1207012655\n",
      "Iteration 2475 => Loss: 26.1172168589\n",
      "Iteration 2476 => Loss: 26.1137361561\n",
      "Iteration 2477 => Loss: 26.1102591532\n",
      "Iteration 2478 => Loss: 26.1067858462\n",
      "Iteration 2479 => Loss: 26.1033162314\n",
      "Iteration 2480 => Loss: 26.0998503046\n",
      "Iteration 2481 => Loss: 26.0963880621\n",
      "Iteration 2482 => Loss: 26.0929294998\n",
      "Iteration 2483 => Loss: 26.0894746140\n",
      "Iteration 2484 => Loss: 26.0860234006\n",
      "Iteration 2485 => Loss: 26.0825758557\n",
      "Iteration 2486 => Loss: 26.0791319756\n",
      "Iteration 2487 => Loss: 26.0756917562\n",
      "Iteration 2488 => Loss: 26.0722551937\n",
      "Iteration 2489 => Loss: 26.0688222841\n",
      "Iteration 2490 => Loss: 26.0653930237\n",
      "Iteration 2491 => Loss: 26.0619674085\n",
      "Iteration 2492 => Loss: 26.0585454347\n",
      "Iteration 2493 => Loss: 26.0551270984\n",
      "Iteration 2494 => Loss: 26.0517123957\n",
      "Iteration 2495 => Loss: 26.0483013227\n",
      "Iteration 2496 => Loss: 26.0448938756\n",
      "Iteration 2497 => Loss: 26.0414900506\n",
      "Iteration 2498 => Loss: 26.0380898438\n",
      "Iteration 2499 => Loss: 26.0346932513\n",
      "Iteration 2500 => Loss: 26.0313002693\n",
      "Iteration 2501 => Loss: 26.0279108940\n",
      "Iteration 2502 => Loss: 26.0245251216\n",
      "Iteration 2503 => Loss: 26.0211429481\n",
      "Iteration 2504 => Loss: 26.0177643698\n",
      "Iteration 2505 => Loss: 26.0143893829\n",
      "Iteration 2506 => Loss: 26.0110179835\n",
      "Iteration 2507 => Loss: 26.0076501678\n",
      "Iteration 2508 => Loss: 26.0042859320\n",
      "Iteration 2509 => Loss: 26.0009252724\n",
      "Iteration 2510 => Loss: 25.9975681851\n",
      "Iteration 2511 => Loss: 25.9942146663\n",
      "Iteration 2512 => Loss: 25.9908647122\n",
      "Iteration 2513 => Loss: 25.9875183190\n",
      "Iteration 2514 => Loss: 25.9841754830\n",
      "Iteration 2515 => Loss: 25.9808362003\n",
      "Iteration 2516 => Loss: 25.9775004672\n",
      "Iteration 2517 => Loss: 25.9741682800\n",
      "Iteration 2518 => Loss: 25.9708396348\n",
      "Iteration 2519 => Loss: 25.9675145278\n",
      "Iteration 2520 => Loss: 25.9641929554\n",
      "Iteration 2521 => Loss: 25.9608749138\n",
      "Iteration 2522 => Loss: 25.9575603991\n",
      "Iteration 2523 => Loss: 25.9542494077\n",
      "Iteration 2524 => Loss: 25.9509419358\n",
      "Iteration 2525 => Loss: 25.9476379797\n",
      "Iteration 2526 => Loss: 25.9443375357\n",
      "Iteration 2527 => Loss: 25.9410405999\n",
      "Iteration 2528 => Loss: 25.9377471687\n",
      "Iteration 2529 => Loss: 25.9344572384\n",
      "Iteration 2530 => Loss: 25.9311708051\n",
      "Iteration 2531 => Loss: 25.9278878653\n",
      "Iteration 2532 => Loss: 25.9246084152\n",
      "Iteration 2533 => Loss: 25.9213324511\n",
      "Iteration 2534 => Loss: 25.9180599692\n",
      "Iteration 2535 => Loss: 25.9147909659\n",
      "Iteration 2536 => Loss: 25.9115254376\n",
      "Iteration 2537 => Loss: 25.9082633803\n",
      "Iteration 2538 => Loss: 25.9050047906\n",
      "Iteration 2539 => Loss: 25.9017496647\n",
      "Iteration 2540 => Loss: 25.8984979990\n",
      "Iteration 2541 => Loss: 25.8952497897\n",
      "Iteration 2542 => Loss: 25.8920050331\n",
      "Iteration 2543 => Loss: 25.8887637257\n",
      "Iteration 2544 => Loss: 25.8855258637\n",
      "Iteration 2545 => Loss: 25.8822914435\n",
      "Iteration 2546 => Loss: 25.8790604614\n",
      "Iteration 2547 => Loss: 25.8758329138\n",
      "Iteration 2548 => Loss: 25.8726087970\n",
      "Iteration 2549 => Loss: 25.8693881073\n",
      "Iteration 2550 => Loss: 25.8661708412\n",
      "Iteration 2551 => Loss: 25.8629569950\n",
      "Iteration 2552 => Loss: 25.8597465650\n",
      "Iteration 2553 => Loss: 25.8565395476\n",
      "Iteration 2554 => Loss: 25.8533359393\n",
      "Iteration 2555 => Loss: 25.8501357363\n",
      "Iteration 2556 => Loss: 25.8469389350\n",
      "Iteration 2557 => Loss: 25.8437455319\n",
      "Iteration 2558 => Loss: 25.8405555233\n",
      "Iteration 2559 => Loss: 25.8373689056\n",
      "Iteration 2560 => Loss: 25.8341856752\n",
      "Iteration 2561 => Loss: 25.8310058285\n",
      "Iteration 2562 => Loss: 25.8278293620\n",
      "Iteration 2563 => Loss: 25.8246562719\n",
      "Iteration 2564 => Loss: 25.8214865548\n",
      "Iteration 2565 => Loss: 25.8183202070\n",
      "Iteration 2566 => Loss: 25.8151572250\n",
      "Iteration 2567 => Loss: 25.8119976051\n",
      "Iteration 2568 => Loss: 25.8088413439\n",
      "Iteration 2569 => Loss: 25.8056884377\n",
      "Iteration 2570 => Loss: 25.8025388830\n",
      "Iteration 2571 => Loss: 25.7993926762\n",
      "Iteration 2572 => Loss: 25.7962498137\n",
      "Iteration 2573 => Loss: 25.7931102920\n",
      "Iteration 2574 => Loss: 25.7899741076\n",
      "Iteration 2575 => Loss: 25.7868412569\n",
      "Iteration 2576 => Loss: 25.7837117363\n",
      "Iteration 2577 => Loss: 25.7805855424\n",
      "Iteration 2578 => Loss: 25.7774626715\n",
      "Iteration 2579 => Loss: 25.7743431202\n",
      "Iteration 2580 => Loss: 25.7712268848\n",
      "Iteration 2581 => Loss: 25.7681139620\n",
      "Iteration 2582 => Loss: 25.7650043482\n",
      "Iteration 2583 => Loss: 25.7618980398\n",
      "Iteration 2584 => Loss: 25.7587950333\n",
      "Iteration 2585 => Loss: 25.7556953253\n",
      "Iteration 2586 => Loss: 25.7525989122\n",
      "Iteration 2587 => Loss: 25.7495057905\n",
      "Iteration 2588 => Loss: 25.7464159567\n",
      "Iteration 2589 => Loss: 25.7433294074\n",
      "Iteration 2590 => Loss: 25.7402461390\n",
      "Iteration 2591 => Loss: 25.7371661481\n",
      "Iteration 2592 => Loss: 25.7340894311\n",
      "Iteration 2593 => Loss: 25.7310159846\n",
      "Iteration 2594 => Loss: 25.7279458051\n",
      "Iteration 2595 => Loss: 25.7248788891\n",
      "Iteration 2596 => Loss: 25.7218152332\n",
      "Iteration 2597 => Loss: 25.7187548340\n",
      "Iteration 2598 => Loss: 25.7156976878\n",
      "Iteration 2599 => Loss: 25.7126437913\n",
      "Iteration 2600 => Loss: 25.7095931411\n",
      "Iteration 2601 => Loss: 25.7065457336\n",
      "Iteration 2602 => Loss: 25.7035015655\n",
      "Iteration 2603 => Loss: 25.7004606333\n",
      "Iteration 2604 => Loss: 25.6974229335\n",
      "Iteration 2605 => Loss: 25.6943884627\n",
      "Iteration 2606 => Loss: 25.6913572175\n",
      "Iteration 2607 => Loss: 25.6883291944\n",
      "Iteration 2608 => Loss: 25.6853043901\n",
      "Iteration 2609 => Loss: 25.6822828010\n",
      "Iteration 2610 => Loss: 25.6792644239\n",
      "Iteration 2611 => Loss: 25.6762492552\n",
      "Iteration 2612 => Loss: 25.6732372916\n",
      "Iteration 2613 => Loss: 25.6702285296\n",
      "Iteration 2614 => Loss: 25.6672229659\n",
      "Iteration 2615 => Loss: 25.6642205970\n",
      "Iteration 2616 => Loss: 25.6612214196\n",
      "Iteration 2617 => Loss: 25.6582254303\n",
      "Iteration 2618 => Loss: 25.6552326256\n",
      "Iteration 2619 => Loss: 25.6522430022\n",
      "Iteration 2620 => Loss: 25.6492565567\n",
      "Iteration 2621 => Loss: 25.6462732857\n",
      "Iteration 2622 => Loss: 25.6432931859\n",
      "Iteration 2623 => Loss: 25.6403162539\n",
      "Iteration 2624 => Loss: 25.6373424863\n",
      "Iteration 2625 => Loss: 25.6343718798\n",
      "Iteration 2626 => Loss: 25.6314044309\n",
      "Iteration 2627 => Loss: 25.6284401364\n",
      "Iteration 2628 => Loss: 25.6254789928\n",
      "Iteration 2629 => Loss: 25.6225209969\n",
      "Iteration 2630 => Loss: 25.6195661453\n",
      "Iteration 2631 => Loss: 25.6166144346\n",
      "Iteration 2632 => Loss: 25.6136658616\n",
      "Iteration 2633 => Loss: 25.6107204228\n",
      "Iteration 2634 => Loss: 25.6077781149\n",
      "Iteration 2635 => Loss: 25.6048389346\n",
      "Iteration 2636 => Loss: 25.6019028787\n",
      "Iteration 2637 => Loss: 25.5989699437\n",
      "Iteration 2638 => Loss: 25.5960401263\n",
      "Iteration 2639 => Loss: 25.5931134233\n",
      "Iteration 2640 => Loss: 25.5901898313\n",
      "Iteration 2641 => Loss: 25.5872693470\n",
      "Iteration 2642 => Loss: 25.5843519672\n",
      "Iteration 2643 => Loss: 25.5814376884\n",
      "Iteration 2644 => Loss: 25.5785265075\n",
      "Iteration 2645 => Loss: 25.5756184211\n",
      "Iteration 2646 => Loss: 25.5727134259\n",
      "Iteration 2647 => Loss: 25.5698115186\n",
      "Iteration 2648 => Loss: 25.5669126961\n",
      "Iteration 2649 => Loss: 25.5640169549\n",
      "Iteration 2650 => Loss: 25.5611242918\n",
      "Iteration 2651 => Loss: 25.5582347036\n",
      "Iteration 2652 => Loss: 25.5553481869\n",
      "Iteration 2653 => Loss: 25.5524647386\n",
      "Iteration 2654 => Loss: 25.5495843553\n",
      "Iteration 2655 => Loss: 25.5467070337\n",
      "Iteration 2656 => Loss: 25.5438327708\n",
      "Iteration 2657 => Loss: 25.5409615630\n",
      "Iteration 2658 => Loss: 25.5380934074\n",
      "Iteration 2659 => Loss: 25.5352283005\n",
      "Iteration 2660 => Loss: 25.5323662391\n",
      "Iteration 2661 => Loss: 25.5295072201\n",
      "Iteration 2662 => Loss: 25.5266512402\n",
      "Iteration 2663 => Loss: 25.5237982960\n",
      "Iteration 2664 => Loss: 25.5209483846\n",
      "Iteration 2665 => Loss: 25.5181015025\n",
      "Iteration 2666 => Loss: 25.5152576465\n",
      "Iteration 2667 => Loss: 25.5124168136\n",
      "Iteration 2668 => Loss: 25.5095790004\n",
      "Iteration 2669 => Loss: 25.5067442037\n",
      "Iteration 2670 => Loss: 25.5039124203\n",
      "Iteration 2671 => Loss: 25.5010836471\n",
      "Iteration 2672 => Loss: 25.4982578808\n",
      "Iteration 2673 => Loss: 25.4954351182\n",
      "Iteration 2674 => Loss: 25.4926153562\n",
      "Iteration 2675 => Loss: 25.4897985915\n",
      "Iteration 2676 => Loss: 25.4869848210\n",
      "Iteration 2677 => Loss: 25.4841740415\n",
      "Iteration 2678 => Loss: 25.4813662497\n",
      "Iteration 2679 => Loss: 25.4785614426\n",
      "Iteration 2680 => Loss: 25.4757596169\n",
      "Iteration 2681 => Loss: 25.4729607695\n",
      "Iteration 2682 => Loss: 25.4701648972\n",
      "Iteration 2683 => Loss: 25.4673719969\n",
      "Iteration 2684 => Loss: 25.4645820654\n",
      "Iteration 2685 => Loss: 25.4617950995\n",
      "Iteration 2686 => Loss: 25.4590110961\n",
      "Iteration 2687 => Loss: 25.4562300520\n",
      "Iteration 2688 => Loss: 25.4534519641\n",
      "Iteration 2689 => Loss: 25.4506768293\n",
      "Iteration 2690 => Loss: 25.4479046444\n",
      "Iteration 2691 => Loss: 25.4451354062\n",
      "Iteration 2692 => Loss: 25.4423691117\n",
      "Iteration 2693 => Loss: 25.4396057577\n",
      "Iteration 2694 => Loss: 25.4368453411\n",
      "Iteration 2695 => Loss: 25.4340878588\n",
      "Iteration 2696 => Loss: 25.4313333076\n",
      "Iteration 2697 => Loss: 25.4285816844\n",
      "Iteration 2698 => Loss: 25.4258329861\n",
      "Iteration 2699 => Loss: 25.4230872097\n",
      "Iteration 2700 => Loss: 25.4203443520\n",
      "Iteration 2701 => Loss: 25.4176044098\n",
      "Iteration 2702 => Loss: 25.4148673802\n",
      "Iteration 2703 => Loss: 25.4121332599\n",
      "Iteration 2704 => Loss: 25.4094020460\n",
      "Iteration 2705 => Loss: 25.4066737353\n",
      "Iteration 2706 => Loss: 25.4039483247\n",
      "Iteration 2707 => Loss: 25.4012258112\n",
      "Iteration 2708 => Loss: 25.3985061917\n",
      "Iteration 2709 => Loss: 25.3957894630\n",
      "Iteration 2710 => Loss: 25.3930756222\n",
      "Iteration 2711 => Loss: 25.3903646661\n",
      "Iteration 2712 => Loss: 25.3876565918\n",
      "Iteration 2713 => Loss: 25.3849513960\n",
      "Iteration 2714 => Loss: 25.3822490758\n",
      "Iteration 2715 => Loss: 25.3795496282\n",
      "Iteration 2716 => Loss: 25.3768530499\n",
      "Iteration 2717 => Loss: 25.3741593381\n",
      "Iteration 2718 => Loss: 25.3714684897\n",
      "Iteration 2719 => Loss: 25.3687805015\n",
      "Iteration 2720 => Loss: 25.3660953707\n",
      "Iteration 2721 => Loss: 25.3634130940\n",
      "Iteration 2722 => Loss: 25.3607336686\n",
      "Iteration 2723 => Loss: 25.3580570914\n",
      "Iteration 2724 => Loss: 25.3553833592\n",
      "Iteration 2725 => Loss: 25.3527124693\n",
      "Iteration 2726 => Loss: 25.3500444184\n",
      "Iteration 2727 => Loss: 25.3473792036\n",
      "Iteration 2728 => Loss: 25.3447168218\n",
      "Iteration 2729 => Loss: 25.3420572701\n",
      "Iteration 2730 => Loss: 25.3394005455\n",
      "Iteration 2731 => Loss: 25.3367466449\n",
      "Iteration 2732 => Loss: 25.3340955653\n",
      "Iteration 2733 => Loss: 25.3314473038\n",
      "Iteration 2734 => Loss: 25.3288018574\n",
      "Iteration 2735 => Loss: 25.3261592229\n",
      "Iteration 2736 => Loss: 25.3235193976\n",
      "Iteration 2737 => Loss: 25.3208823783\n",
      "Iteration 2738 => Loss: 25.3182481621\n",
      "Iteration 2739 => Loss: 25.3156167461\n",
      "Iteration 2740 => Loss: 25.3129881271\n",
      "Iteration 2741 => Loss: 25.3103623024\n",
      "Iteration 2742 => Loss: 25.3077392688\n",
      "Iteration 2743 => Loss: 25.3051190235\n",
      "Iteration 2744 => Loss: 25.3025015634\n",
      "Iteration 2745 => Loss: 25.2998868857\n",
      "Iteration 2746 => Loss: 25.2972749872\n",
      "Iteration 2747 => Loss: 25.2946658652\n",
      "Iteration 2748 => Loss: 25.2920595166\n",
      "Iteration 2749 => Loss: 25.2894559386\n",
      "Iteration 2750 => Loss: 25.2868551280\n",
      "Iteration 2751 => Loss: 25.2842570821\n",
      "Iteration 2752 => Loss: 25.2816617978\n",
      "Iteration 2753 => Loss: 25.2790692723\n",
      "Iteration 2754 => Loss: 25.2764795025\n",
      "Iteration 2755 => Loss: 25.2738924857\n",
      "Iteration 2756 => Loss: 25.2713082188\n",
      "Iteration 2757 => Loss: 25.2687266989\n",
      "Iteration 2758 => Loss: 25.2661479231\n",
      "Iteration 2759 => Loss: 25.2635718884\n",
      "Iteration 2760 => Loss: 25.2609985921\n",
      "Iteration 2761 => Loss: 25.2584280311\n",
      "Iteration 2762 => Loss: 25.2558602026\n",
      "Iteration 2763 => Loss: 25.2532951036\n",
      "Iteration 2764 => Loss: 25.2507327312\n",
      "Iteration 2765 => Loss: 25.2481730827\n",
      "Iteration 2766 => Loss: 25.2456161549\n",
      "Iteration 2767 => Loss: 25.2430619451\n",
      "Iteration 2768 => Loss: 25.2405104504\n",
      "Iteration 2769 => Loss: 25.2379616679\n",
      "Iteration 2770 => Loss: 25.2354155947\n",
      "Iteration 2771 => Loss: 25.2328722279\n",
      "Iteration 2772 => Loss: 25.2303315646\n",
      "Iteration 2773 => Loss: 25.2277936020\n",
      "Iteration 2774 => Loss: 25.2252583372\n",
      "Iteration 2775 => Loss: 25.2227257674\n",
      "Iteration 2776 => Loss: 25.2201958896\n",
      "Iteration 2777 => Loss: 25.2176687010\n",
      "Iteration 2778 => Loss: 25.2151441988\n",
      "Iteration 2779 => Loss: 25.2126223800\n",
      "Iteration 2780 => Loss: 25.2101032419\n",
      "Iteration 2781 => Loss: 25.2075867816\n",
      "Iteration 2782 => Loss: 25.2050729963\n",
      "Iteration 2783 => Loss: 25.2025618830\n",
      "Iteration 2784 => Loss: 25.2000534390\n",
      "Iteration 2785 => Loss: 25.1975476614\n",
      "Iteration 2786 => Loss: 25.1950445474\n",
      "Iteration 2787 => Loss: 25.1925440942\n",
      "Iteration 2788 => Loss: 25.1900462989\n",
      "Iteration 2789 => Loss: 25.1875511587\n",
      "Iteration 2790 => Loss: 25.1850586707\n",
      "Iteration 2791 => Loss: 25.1825688323\n",
      "Iteration 2792 => Loss: 25.1800816405\n",
      "Iteration 2793 => Loss: 25.1775970925\n",
      "Iteration 2794 => Loss: 25.1751151855\n",
      "Iteration 2795 => Loss: 25.1726359168\n",
      "Iteration 2796 => Loss: 25.1701592834\n",
      "Iteration 2797 => Loss: 25.1676852827\n",
      "Iteration 2798 => Loss: 25.1652139118\n",
      "Iteration 2799 => Loss: 25.1627451679\n",
      "Iteration 2800 => Loss: 25.1602790482\n",
      "Iteration 2801 => Loss: 25.1578155499\n",
      "Iteration 2802 => Loss: 25.1553546703\n",
      "Iteration 2803 => Loss: 25.1528964066\n",
      "Iteration 2804 => Loss: 25.1504407559\n",
      "Iteration 2805 => Loss: 25.1479877156\n",
      "Iteration 2806 => Loss: 25.1455372828\n",
      "Iteration 2807 => Loss: 25.1430894547\n",
      "Iteration 2808 => Loss: 25.1406442286\n",
      "Iteration 2809 => Loss: 25.1382016018\n",
      "Iteration 2810 => Loss: 25.1357615714\n",
      "Iteration 2811 => Loss: 25.1333241347\n",
      "Iteration 2812 => Loss: 25.1308892889\n",
      "Iteration 2813 => Loss: 25.1284570314\n",
      "Iteration 2814 => Loss: 25.1260273592\n",
      "Iteration 2815 => Loss: 25.1236002698\n",
      "Iteration 2816 => Loss: 25.1211757603\n",
      "Iteration 2817 => Loss: 25.1187538280\n",
      "Iteration 2818 => Loss: 25.1163344702\n",
      "Iteration 2819 => Loss: 25.1139176841\n",
      "Iteration 2820 => Loss: 25.1115034670\n",
      "Iteration 2821 => Loss: 25.1090918162\n",
      "Iteration 2822 => Loss: 25.1066827288\n",
      "Iteration 2823 => Loss: 25.1042762023\n",
      "Iteration 2824 => Loss: 25.1018722339\n",
      "Iteration 2825 => Loss: 25.0994708209\n",
      "Iteration 2826 => Loss: 25.0970719605\n",
      "Iteration 2827 => Loss: 25.0946756500\n",
      "Iteration 2828 => Loss: 25.0922818868\n",
      "Iteration 2829 => Loss: 25.0898906681\n",
      "Iteration 2830 => Loss: 25.0875019912\n",
      "Iteration 2831 => Loss: 25.0851158534\n",
      "Iteration 2832 => Loss: 25.0827322520\n",
      "Iteration 2833 => Loss: 25.0803511844\n",
      "Iteration 2834 => Loss: 25.0779726478\n",
      "Iteration 2835 => Loss: 25.0755966395\n",
      "Iteration 2836 => Loss: 25.0732231568\n",
      "Iteration 2837 => Loss: 25.0708521971\n",
      "Iteration 2838 => Loss: 25.0684837577\n",
      "Iteration 2839 => Loss: 25.0661178359\n",
      "Iteration 2840 => Loss: 25.0637544290\n",
      "Iteration 2841 => Loss: 25.0613935344\n",
      "Iteration 2842 => Loss: 25.0590351493\n",
      "Iteration 2843 => Loss: 25.0566792712\n",
      "Iteration 2844 => Loss: 25.0543258973\n",
      "Iteration 2845 => Loss: 25.0519750250\n",
      "Iteration 2846 => Loss: 25.0496266516\n",
      "Iteration 2847 => Loss: 25.0472807745\n",
      "Iteration 2848 => Loss: 25.0449373911\n",
      "Iteration 2849 => Loss: 25.0425964985\n",
      "Iteration 2850 => Loss: 25.0402580943\n",
      "Iteration 2851 => Loss: 25.0379221758\n",
      "Iteration 2852 => Loss: 25.0355887403\n",
      "Iteration 2853 => Loss: 25.0332577852\n",
      "Iteration 2854 => Loss: 25.0309293079\n",
      "Iteration 2855 => Loss: 25.0286033056\n",
      "Iteration 2856 => Loss: 25.0262797759\n",
      "Iteration 2857 => Loss: 25.0239587160\n",
      "Iteration 2858 => Loss: 25.0216401234\n",
      "Iteration 2859 => Loss: 25.0193239954\n",
      "Iteration 2860 => Loss: 25.0170103294\n",
      "Iteration 2861 => Loss: 25.0146991227\n",
      "Iteration 2862 => Loss: 25.0123903728\n",
      "Iteration 2863 => Loss: 25.0100840771\n",
      "Iteration 2864 => Loss: 25.0077802329\n",
      "Iteration 2865 => Loss: 25.0054788377\n",
      "Iteration 2866 => Loss: 25.0031798888\n",
      "Iteration 2867 => Loss: 25.0008833836\n",
      "Iteration 2868 => Loss: 24.9985893195\n",
      "Iteration 2869 => Loss: 24.9962976940\n",
      "Iteration 2870 => Loss: 24.9940085045\n",
      "Iteration 2871 => Loss: 24.9917217483\n",
      "Iteration 2872 => Loss: 24.9894374229\n",
      "Iteration 2873 => Loss: 24.9871555256\n",
      "Iteration 2874 => Loss: 24.9848760540\n",
      "Iteration 2875 => Loss: 24.9825990054\n",
      "Iteration 2876 => Loss: 24.9803243773\n",
      "Iteration 2877 => Loss: 24.9780521670\n",
      "Iteration 2878 => Loss: 24.9757823721\n",
      "Iteration 2879 => Loss: 24.9735149899\n",
      "Iteration 2880 => Loss: 24.9712500179\n",
      "Iteration 2881 => Loss: 24.9689874534\n",
      "Iteration 2882 => Loss: 24.9667272941\n",
      "Iteration 2883 => Loss: 24.9644695372\n",
      "Iteration 2884 => Loss: 24.9622141803\n",
      "Iteration 2885 => Loss: 24.9599612208\n",
      "Iteration 2886 => Loss: 24.9577106562\n",
      "Iteration 2887 => Loss: 24.9554624838\n",
      "Iteration 2888 => Loss: 24.9532167012\n",
      "Iteration 2889 => Loss: 24.9509733059\n",
      "Iteration 2890 => Loss: 24.9487322952\n",
      "Iteration 2891 => Loss: 24.9464936666\n",
      "Iteration 2892 => Loss: 24.9442574177\n",
      "Iteration 2893 => Loss: 24.9420235459\n",
      "Iteration 2894 => Loss: 24.9397920486\n",
      "Iteration 2895 => Loss: 24.9375629233\n",
      "Iteration 2896 => Loss: 24.9353361676\n",
      "Iteration 2897 => Loss: 24.9331117788\n",
      "Iteration 2898 => Loss: 24.9308897546\n",
      "Iteration 2899 => Loss: 24.9286700923\n",
      "Iteration 2900 => Loss: 24.9264527894\n",
      "Iteration 2901 => Loss: 24.9242378435\n",
      "Iteration 2902 => Loss: 24.9220252520\n",
      "Iteration 2903 => Loss: 24.9198150125\n",
      "Iteration 2904 => Loss: 24.9176071224\n",
      "Iteration 2905 => Loss: 24.9154015793\n",
      "Iteration 2906 => Loss: 24.9131983806\n",
      "Iteration 2907 => Loss: 24.9109975238\n",
      "Iteration 2908 => Loss: 24.9087990065\n",
      "Iteration 2909 => Loss: 24.9066028262\n",
      "Iteration 2910 => Loss: 24.9044089804\n",
      "Iteration 2911 => Loss: 24.9022174666\n",
      "Iteration 2912 => Loss: 24.9000282823\n",
      "Iteration 2913 => Loss: 24.8978414251\n",
      "Iteration 2914 => Loss: 24.8956568925\n",
      "Iteration 2915 => Loss: 24.8934746820\n",
      "Iteration 2916 => Loss: 24.8912947911\n",
      "Iteration 2917 => Loss: 24.8891172174\n",
      "Iteration 2918 => Loss: 24.8869419584\n",
      "Iteration 2919 => Loss: 24.8847690117\n",
      "Iteration 2920 => Loss: 24.8825983748\n",
      "Iteration 2921 => Loss: 24.8804300452\n",
      "Iteration 2922 => Loss: 24.8782640205\n",
      "Iteration 2923 => Loss: 24.8761002982\n",
      "Iteration 2924 => Loss: 24.8739388759\n",
      "Iteration 2925 => Loss: 24.8717797512\n",
      "Iteration 2926 => Loss: 24.8696229216\n",
      "Iteration 2927 => Loss: 24.8674683846\n",
      "Iteration 2928 => Loss: 24.8653161379\n",
      "Iteration 2929 => Loss: 24.8631661789\n",
      "Iteration 2930 => Loss: 24.8610185053\n",
      "Iteration 2931 => Loss: 24.8588731147\n",
      "Iteration 2932 => Loss: 24.8567300045\n",
      "Iteration 2933 => Loss: 24.8545891725\n",
      "Iteration 2934 => Loss: 24.8524506161\n",
      "Iteration 2935 => Loss: 24.8503143329\n",
      "Iteration 2936 => Loss: 24.8481803206\n",
      "Iteration 2937 => Loss: 24.8460485766\n",
      "Iteration 2938 => Loss: 24.8439190987\n",
      "Iteration 2939 => Loss: 24.8417918844\n",
      "Iteration 2940 => Loss: 24.8396669312\n",
      "Iteration 2941 => Loss: 24.8375442368\n",
      "Iteration 2942 => Loss: 24.8354237988\n",
      "Iteration 2943 => Loss: 24.8333056148\n",
      "Iteration 2944 => Loss: 24.8311896824\n",
      "Iteration 2945 => Loss: 24.8290759991\n",
      "Iteration 2946 => Loss: 24.8269645627\n",
      "Iteration 2947 => Loss: 24.8248553706\n",
      "Iteration 2948 => Loss: 24.8227484206\n",
      "Iteration 2949 => Loss: 24.8206437103\n",
      "Iteration 2950 => Loss: 24.8185412372\n",
      "Iteration 2951 => Loss: 24.8164409990\n",
      "Iteration 2952 => Loss: 24.8143429932\n",
      "Iteration 2953 => Loss: 24.8122472177\n",
      "Iteration 2954 => Loss: 24.8101536699\n",
      "Iteration 2955 => Loss: 24.8080623475\n",
      "Iteration 2956 => Loss: 24.8059732481\n",
      "Iteration 2957 => Loss: 24.8038863694\n",
      "Iteration 2958 => Loss: 24.8018017090\n",
      "Iteration 2959 => Loss: 24.7997192645\n",
      "Iteration 2960 => Loss: 24.7976390337\n",
      "Iteration 2961 => Loss: 24.7955610140\n",
      "Iteration 2962 => Loss: 24.7934852033\n",
      "Iteration 2963 => Loss: 24.7914115991\n",
      "Iteration 2964 => Loss: 24.7893401991\n",
      "Iteration 2965 => Loss: 24.7872710010\n",
      "Iteration 2966 => Loss: 24.7852040024\n",
      "Iteration 2967 => Loss: 24.7831392009\n",
      "Iteration 2968 => Loss: 24.7810765943\n",
      "Iteration 2969 => Loss: 24.7790161802\n",
      "Iteration 2970 => Loss: 24.7769579563\n",
      "Iteration 2971 => Loss: 24.7749019202\n",
      "Iteration 2972 => Loss: 24.7728480697\n",
      "Iteration 2973 => Loss: 24.7707964023\n",
      "Iteration 2974 => Loss: 24.7687469159\n",
      "Iteration 2975 => Loss: 24.7666996080\n",
      "Iteration 2976 => Loss: 24.7646544763\n",
      "Iteration 2977 => Loss: 24.7626115186\n",
      "Iteration 2978 => Loss: 24.7605707325\n",
      "Iteration 2979 => Loss: 24.7585321157\n",
      "Iteration 2980 => Loss: 24.7564956659\n",
      "Iteration 2981 => Loss: 24.7544613808\n",
      "Iteration 2982 => Loss: 24.7524292581\n",
      "Iteration 2983 => Loss: 24.7503992955\n",
      "Iteration 2984 => Loss: 24.7483714907\n",
      "Iteration 2985 => Loss: 24.7463458414\n",
      "Iteration 2986 => Loss: 24.7443223454\n",
      "Iteration 2987 => Loss: 24.7423010003\n",
      "Iteration 2988 => Loss: 24.7402818038\n",
      "Iteration 2989 => Loss: 24.7382647537\n",
      "Iteration 2990 => Loss: 24.7362498477\n",
      "Iteration 2991 => Loss: 24.7342370835\n",
      "Iteration 2992 => Loss: 24.7322264588\n",
      "Iteration 2993 => Loss: 24.7302179714\n",
      "Iteration 2994 => Loss: 24.7282116189\n",
      "Iteration 2995 => Loss: 24.7262073991\n",
      "Iteration 2996 => Loss: 24.7242053098\n",
      "Iteration 2997 => Loss: 24.7222053487\n",
      "Iteration 2998 => Loss: 24.7202075135\n",
      "Iteration 2999 => Loss: 24.7182118019\n",
      "Iteration 3000 => Loss: 24.7162182118\n",
      "Iteration 3001 => Loss: 24.7142267408\n",
      "Iteration 3002 => Loss: 24.7122373866\n",
      "Iteration 3003 => Loss: 24.7102501472\n",
      "Iteration 3004 => Loss: 24.7082650201\n",
      "Iteration 3005 => Loss: 24.7062820031\n",
      "Iteration 3006 => Loss: 24.7043010941\n",
      "Iteration 3007 => Loss: 24.7023222907\n",
      "Iteration 3008 => Loss: 24.7003455908\n",
      "Iteration 3009 => Loss: 24.6983709920\n",
      "Iteration 3010 => Loss: 24.6963984922\n",
      "Iteration 3011 => Loss: 24.6944280892\n",
      "Iteration 3012 => Loss: 24.6924597806\n",
      "Iteration 3013 => Loss: 24.6904935643\n",
      "Iteration 3014 => Loss: 24.6885294380\n",
      "Iteration 3015 => Loss: 24.6865673996\n",
      "Iteration 3016 => Loss: 24.6846074468\n",
      "Iteration 3017 => Loss: 24.6826495773\n",
      "Iteration 3018 => Loss: 24.6806937890\n",
      "Iteration 3019 => Loss: 24.6787400797\n",
      "Iteration 3020 => Loss: 24.6767884472\n",
      "Iteration 3021 => Loss: 24.6748388892\n",
      "Iteration 3022 => Loss: 24.6728914035\n",
      "Iteration 3023 => Loss: 24.6709459880\n",
      "Iteration 3024 => Loss: 24.6690026404\n",
      "Iteration 3025 => Loss: 24.6670613585\n",
      "Iteration 3026 => Loss: 24.6651221402\n",
      "Iteration 3027 => Loss: 24.6631849832\n",
      "Iteration 3028 => Loss: 24.6612498854\n",
      "Iteration 3029 => Loss: 24.6593168445\n",
      "Iteration 3030 => Loss: 24.6573858585\n",
      "Iteration 3031 => Loss: 24.6554569250\n",
      "Iteration 3032 => Loss: 24.6535300419\n",
      "Iteration 3033 => Loss: 24.6516052071\n",
      "Iteration 3034 => Loss: 24.6496824183\n",
      "Iteration 3035 => Loss: 24.6477616735\n",
      "Iteration 3036 => Loss: 24.6458429703\n",
      "Iteration 3037 => Loss: 24.6439263067\n",
      "Iteration 3038 => Loss: 24.6420116804\n",
      "Iteration 3039 => Loss: 24.6400990894\n",
      "Iteration 3040 => Loss: 24.6381885314\n",
      "Iteration 3041 => Loss: 24.6362800042\n",
      "Iteration 3042 => Loss: 24.6343735058\n",
      "Iteration 3043 => Loss: 24.6324690340\n",
      "Iteration 3044 => Loss: 24.6305665866\n",
      "Iteration 3045 => Loss: 24.6286661614\n",
      "Iteration 3046 => Loss: 24.6267677564\n",
      "Iteration 3047 => Loss: 24.6248713693\n",
      "Iteration 3048 => Loss: 24.6229769981\n",
      "Iteration 3049 => Loss: 24.6210846405\n",
      "Iteration 3050 => Loss: 24.6191942944\n",
      "Iteration 3051 => Loss: 24.6173059578\n",
      "Iteration 3052 => Loss: 24.6154196284\n",
      "Iteration 3053 => Loss: 24.6135353041\n",
      "Iteration 3054 => Loss: 24.6116529829\n",
      "Iteration 3055 => Loss: 24.6097726625\n",
      "Iteration 3056 => Loss: 24.6078943408\n",
      "Iteration 3057 => Loss: 24.6060180158\n",
      "Iteration 3058 => Loss: 24.6041436852\n",
      "Iteration 3059 => Loss: 24.6022713471\n",
      "Iteration 3060 => Loss: 24.6004009991\n",
      "Iteration 3061 => Loss: 24.5985326394\n",
      "Iteration 3062 => Loss: 24.5966662656\n",
      "Iteration 3063 => Loss: 24.5948018758\n",
      "Iteration 3064 => Loss: 24.5929394677\n",
      "Iteration 3065 => Loss: 24.5910790394\n",
      "Iteration 3066 => Loss: 24.5892205887\n",
      "Iteration 3067 => Loss: 24.5873641135\n",
      "Iteration 3068 => Loss: 24.5855096116\n",
      "Iteration 3069 => Loss: 24.5836570811\n",
      "Iteration 3070 => Loss: 24.5818065197\n",
      "Iteration 3071 => Loss: 24.5799579255\n",
      "Iteration 3072 => Loss: 24.5781112962\n",
      "Iteration 3073 => Loss: 24.5762666300\n",
      "Iteration 3074 => Loss: 24.5744239245\n",
      "Iteration 3075 => Loss: 24.5725831778\n",
      "Iteration 3076 => Loss: 24.5707443878\n",
      "Iteration 3077 => Loss: 24.5689075523\n",
      "Iteration 3078 => Loss: 24.5670726694\n",
      "Iteration 3079 => Loss: 24.5652397370\n",
      "Iteration 3080 => Loss: 24.5634087529\n",
      "Iteration 3081 => Loss: 24.5615797151\n",
      "Iteration 3082 => Loss: 24.5597526215\n",
      "Iteration 3083 => Loss: 24.5579274701\n",
      "Iteration 3084 => Loss: 24.5561042587\n",
      "Iteration 3085 => Loss: 24.5542829855\n",
      "Iteration 3086 => Loss: 24.5524636482\n",
      "Iteration 3087 => Loss: 24.5506462448\n",
      "Iteration 3088 => Loss: 24.5488307732\n",
      "Iteration 3089 => Loss: 24.5470172315\n",
      "Iteration 3090 => Loss: 24.5452056175\n",
      "Iteration 3091 => Loss: 24.5433959293\n",
      "Iteration 3092 => Loss: 24.5415881647\n",
      "Iteration 3093 => Loss: 24.5397823217\n",
      "Iteration 3094 => Loss: 24.5379783983\n",
      "Iteration 3095 => Loss: 24.5361763924\n",
      "Iteration 3096 => Loss: 24.5343763020\n",
      "Iteration 3097 => Loss: 24.5325781251\n",
      "Iteration 3098 => Loss: 24.5307818596\n",
      "Iteration 3099 => Loss: 24.5289875035\n",
      "Iteration 3100 => Loss: 24.5271950547\n",
      "Iteration 3101 => Loss: 24.5254045113\n",
      "Iteration 3102 => Loss: 24.5236158712\n",
      "Iteration 3103 => Loss: 24.5218291324\n",
      "Iteration 3104 => Loss: 24.5200442929\n",
      "Iteration 3105 => Loss: 24.5182613506\n",
      "Iteration 3106 => Loss: 24.5164803035\n",
      "Iteration 3107 => Loss: 24.5147011496\n",
      "Iteration 3108 => Loss: 24.5129238870\n",
      "Iteration 3109 => Loss: 24.5111485135\n",
      "Iteration 3110 => Loss: 24.5093750272\n",
      "Iteration 3111 => Loss: 24.5076034261\n",
      "Iteration 3112 => Loss: 24.5058337082\n",
      "Iteration 3113 => Loss: 24.5040658714\n",
      "Iteration 3114 => Loss: 24.5022999139\n",
      "Iteration 3115 => Loss: 24.5005358334\n",
      "Iteration 3116 => Loss: 24.4987736282\n",
      "Iteration 3117 => Loss: 24.4970132962\n",
      "Iteration 3118 => Loss: 24.4952548353\n",
      "Iteration 3119 => Loss: 24.4934982437\n",
      "Iteration 3120 => Loss: 24.4917435193\n",
      "Iteration 3121 => Loss: 24.4899906601\n",
      "Iteration 3122 => Loss: 24.4882396642\n",
      "Iteration 3123 => Loss: 24.4864905295\n",
      "Iteration 3124 => Loss: 24.4847432541\n",
      "Iteration 3125 => Loss: 24.4829978361\n",
      "Iteration 3126 => Loss: 24.4812542734\n",
      "Iteration 3127 => Loss: 24.4795125640\n",
      "Iteration 3128 => Loss: 24.4777727061\n",
      "Iteration 3129 => Loss: 24.4760346976\n",
      "Iteration 3130 => Loss: 24.4742985366\n",
      "Iteration 3131 => Loss: 24.4725642210\n",
      "Iteration 3132 => Loss: 24.4708317490\n",
      "Iteration 3133 => Loss: 24.4691011186\n",
      "Iteration 3134 => Loss: 24.4673723278\n",
      "Iteration 3135 => Loss: 24.4656453747\n",
      "Iteration 3136 => Loss: 24.4639202573\n",
      "Iteration 3137 => Loss: 24.4621969736\n",
      "Iteration 3138 => Loss: 24.4604755218\n",
      "Iteration 3139 => Loss: 24.4587558998\n",
      "Iteration 3140 => Loss: 24.4570381058\n",
      "Iteration 3141 => Loss: 24.4553221377\n",
      "Iteration 3142 => Loss: 24.4536079937\n",
      "Iteration 3143 => Loss: 24.4518956718\n",
      "Iteration 3144 => Loss: 24.4501851700\n",
      "Iteration 3145 => Loss: 24.4484764864\n",
      "Iteration 3146 => Loss: 24.4467696192\n",
      "Iteration 3147 => Loss: 24.4450645663\n",
      "Iteration 3148 => Loss: 24.4433613259\n",
      "Iteration 3149 => Loss: 24.4416598959\n",
      "Iteration 3150 => Loss: 24.4399602746\n",
      "Iteration 3151 => Loss: 24.4382624599\n",
      "Iteration 3152 => Loss: 24.4365664499\n",
      "Iteration 3153 => Loss: 24.4348722428\n",
      "Iteration 3154 => Loss: 24.4331798366\n",
      "Iteration 3155 => Loss: 24.4314892293\n",
      "Iteration 3156 => Loss: 24.4298004192\n",
      "Iteration 3157 => Loss: 24.4281134042\n",
      "Iteration 3158 => Loss: 24.4264281825\n",
      "Iteration 3159 => Loss: 24.4247447521\n",
      "Iteration 3160 => Loss: 24.4230631112\n",
      "Iteration 3161 => Loss: 24.4213832578\n",
      "Iteration 3162 => Loss: 24.4197051901\n",
      "Iteration 3163 => Loss: 24.4180289061\n",
      "Iteration 3164 => Loss: 24.4163544040\n",
      "Iteration 3165 => Loss: 24.4146816819\n",
      "Iteration 3166 => Loss: 24.4130107378\n",
      "Iteration 3167 => Loss: 24.4113415699\n",
      "Iteration 3168 => Loss: 24.4096741762\n",
      "Iteration 3169 => Loss: 24.4080085550\n",
      "Iteration 3170 => Loss: 24.4063447043\n",
      "Iteration 3171 => Loss: 24.4046826223\n",
      "Iteration 3172 => Loss: 24.4030223070\n",
      "Iteration 3173 => Loss: 24.4013637566\n",
      "Iteration 3174 => Loss: 24.3997069691\n",
      "Iteration 3175 => Loss: 24.3980519429\n",
      "Iteration 3176 => Loss: 24.3963986758\n",
      "Iteration 3177 => Loss: 24.3947471662\n",
      "Iteration 3178 => Loss: 24.3930974121\n",
      "Iteration 3179 => Loss: 24.3914494116\n",
      "Iteration 3180 => Loss: 24.3898031629\n",
      "Iteration 3181 => Loss: 24.3881586642\n",
      "Iteration 3182 => Loss: 24.3865159135\n",
      "Iteration 3183 => Loss: 24.3848749090\n",
      "Iteration 3184 => Loss: 24.3832356489\n",
      "Iteration 3185 => Loss: 24.3815981313\n",
      "Iteration 3186 => Loss: 24.3799623543\n",
      "Iteration 3187 => Loss: 24.3783283161\n",
      "Iteration 3188 => Loss: 24.3766960149\n",
      "Iteration 3189 => Loss: 24.3750654487\n",
      "Iteration 3190 => Loss: 24.3734366159\n",
      "Iteration 3191 => Loss: 24.3718095144\n",
      "Iteration 3192 => Loss: 24.3701841425\n",
      "Iteration 3193 => Loss: 24.3685604984\n",
      "Iteration 3194 => Loss: 24.3669385801\n",
      "Iteration 3195 => Loss: 24.3653183859\n",
      "Iteration 3196 => Loss: 24.3636999140\n",
      "Iteration 3197 => Loss: 24.3620831624\n",
      "Iteration 3198 => Loss: 24.3604681295\n",
      "Iteration 3199 => Loss: 24.3588548132\n",
      "Iteration 3200 => Loss: 24.3572432119\n",
      "Iteration 3201 => Loss: 24.3556333237\n",
      "Iteration 3202 => Loss: 24.3540251468\n",
      "Iteration 3203 => Loss: 24.3524186793\n",
      "Iteration 3204 => Loss: 24.3508139195\n",
      "Iteration 3205 => Loss: 24.3492108654\n",
      "Iteration 3206 => Loss: 24.3476095154\n",
      "Iteration 3207 => Loss: 24.3460098676\n",
      "Iteration 3208 => Loss: 24.3444119202\n",
      "Iteration 3209 => Loss: 24.3428156714\n",
      "Iteration 3210 => Loss: 24.3412211194\n",
      "Iteration 3211 => Loss: 24.3396282623\n",
      "Iteration 3212 => Loss: 24.3380370984\n",
      "Iteration 3213 => Loss: 24.3364476259\n",
      "Iteration 3214 => Loss: 24.3348598429\n",
      "Iteration 3215 => Loss: 24.3332737478\n",
      "Iteration 3216 => Loss: 24.3316893386\n",
      "Iteration 3217 => Loss: 24.3301066136\n",
      "Iteration 3218 => Loss: 24.3285255710\n",
      "Iteration 3219 => Loss: 24.3269462090\n",
      "Iteration 3220 => Loss: 24.3253685259\n",
      "Iteration 3221 => Loss: 24.3237925198\n",
      "Iteration 3222 => Loss: 24.3222181889\n",
      "Iteration 3223 => Loss: 24.3206455316\n",
      "Iteration 3224 => Loss: 24.3190745459\n",
      "Iteration 3225 => Loss: 24.3175052302\n",
      "Iteration 3226 => Loss: 24.3159375826\n",
      "Iteration 3227 => Loss: 24.3143716014\n",
      "Iteration 3228 => Loss: 24.3128072848\n",
      "Iteration 3229 => Loss: 24.3112446310\n",
      "Iteration 3230 => Loss: 24.3096836383\n",
      "Iteration 3231 => Loss: 24.3081243049\n",
      "Iteration 3232 => Loss: 24.3065666291\n",
      "Iteration 3233 => Loss: 24.3050106090\n",
      "Iteration 3234 => Loss: 24.3034562429\n",
      "Iteration 3235 => Loss: 24.3019035291\n",
      "Iteration 3236 => Loss: 24.3003524658\n",
      "Iteration 3237 => Loss: 24.2988030513\n",
      "Iteration 3238 => Loss: 24.2972552837\n",
      "Iteration 3239 => Loss: 24.2957091614\n",
      "Iteration 3240 => Loss: 24.2941646825\n",
      "Iteration 3241 => Loss: 24.2926218455\n",
      "Iteration 3242 => Loss: 24.2910806484\n",
      "Iteration 3243 => Loss: 24.2895410896\n",
      "Iteration 3244 => Loss: 24.2880031673\n",
      "Iteration 3245 => Loss: 24.2864668798\n",
      "Iteration 3246 => Loss: 24.2849322253\n",
      "Iteration 3247 => Loss: 24.2833992021\n",
      "Iteration 3248 => Loss: 24.2818678085\n",
      "Iteration 3249 => Loss: 24.2803380428\n",
      "Iteration 3250 => Loss: 24.2788099031\n",
      "Iteration 3251 => Loss: 24.2772833878\n",
      "Iteration 3252 => Loss: 24.2757584952\n",
      "Iteration 3253 => Loss: 24.2742352235\n",
      "Iteration 3254 => Loss: 24.2727135710\n",
      "Iteration 3255 => Loss: 24.2711935360\n",
      "Iteration 3256 => Loss: 24.2696751168\n",
      "Iteration 3257 => Loss: 24.2681583116\n",
      "Iteration 3258 => Loss: 24.2666431187\n",
      "Iteration 3259 => Loss: 24.2651295365\n",
      "Iteration 3260 => Loss: 24.2636175632\n",
      "Iteration 3261 => Loss: 24.2621071970\n",
      "Iteration 3262 => Loss: 24.2605984364\n",
      "Iteration 3263 => Loss: 24.2590912795\n",
      "Iteration 3264 => Loss: 24.2575857247\n",
      "Iteration 3265 => Loss: 24.2560817703\n",
      "Iteration 3266 => Loss: 24.2545794145\n",
      "Iteration 3267 => Loss: 24.2530786558\n",
      "Iteration 3268 => Loss: 24.2515794923\n",
      "Iteration 3269 => Loss: 24.2500819223\n",
      "Iteration 3270 => Loss: 24.2485859443\n",
      "Iteration 3271 => Loss: 24.2470915565\n",
      "Iteration 3272 => Loss: 24.2455987571\n",
      "Iteration 3273 => Loss: 24.2441075446\n",
      "Iteration 3274 => Loss: 24.2426179172\n",
      "Iteration 3275 => Loss: 24.2411298732\n",
      "Iteration 3276 => Loss: 24.2396434110\n",
      "Iteration 3277 => Loss: 24.2381585289\n",
      "Iteration 3278 => Loss: 24.2366752252\n",
      "Iteration 3279 => Loss: 24.2351934982\n",
      "Iteration 3280 => Loss: 24.2337133462\n",
      "Iteration 3281 => Loss: 24.2322347676\n",
      "Iteration 3282 => Loss: 24.2307577607\n",
      "Iteration 3283 => Loss: 24.2292823238\n",
      "Iteration 3284 => Loss: 24.2278084553\n",
      "Iteration 3285 => Loss: 24.2263361535\n",
      "Iteration 3286 => Loss: 24.2248654167\n",
      "Iteration 3287 => Loss: 24.2233962433\n",
      "Iteration 3288 => Loss: 24.2219286316\n",
      "Iteration 3289 => Loss: 24.2204625799\n",
      "Iteration 3290 => Loss: 24.2189980866\n",
      "Iteration 3291 => Loss: 24.2175351500\n",
      "Iteration 3292 => Loss: 24.2160737685\n",
      "Iteration 3293 => Loss: 24.2146139404\n",
      "Iteration 3294 => Loss: 24.2131556641\n",
      "Iteration 3295 => Loss: 24.2116989378\n",
      "Iteration 3296 => Loss: 24.2102437601\n",
      "Iteration 3297 => Loss: 24.2087901292\n",
      "Iteration 3298 => Loss: 24.2073380434\n",
      "Iteration 3299 => Loss: 24.2058875012\n",
      "Iteration 3300 => Loss: 24.2044385009\n",
      "Iteration 3301 => Loss: 24.2029910409\n",
      "Iteration 3302 => Loss: 24.2015451194\n",
      "Iteration 3303 => Loss: 24.2001007350\n",
      "Iteration 3304 => Loss: 24.1986578859\n",
      "Iteration 3305 => Loss: 24.1972165705\n",
      "Iteration 3306 => Loss: 24.1957767872\n",
      "Iteration 3307 => Loss: 24.1943385344\n",
      "Iteration 3308 => Loss: 24.1929018104\n",
      "Iteration 3309 => Loss: 24.1914666136\n",
      "Iteration 3310 => Loss: 24.1900329424\n",
      "Iteration 3311 => Loss: 24.1886007951\n",
      "Iteration 3312 => Loss: 24.1871701702\n",
      "Iteration 3313 => Loss: 24.1857410660\n",
      "Iteration 3314 => Loss: 24.1843134810\n",
      "Iteration 3315 => Loss: 24.1828874134\n",
      "Iteration 3316 => Loss: 24.1814628617\n",
      "Iteration 3317 => Loss: 24.1800398242\n",
      "Iteration 3318 => Loss: 24.1786182995\n",
      "Iteration 3319 => Loss: 24.1771982857\n",
      "Iteration 3320 => Loss: 24.1757797815\n",
      "Iteration 3321 => Loss: 24.1743627850\n",
      "Iteration 3322 => Loss: 24.1729472948\n",
      "Iteration 3323 => Loss: 24.1715333092\n",
      "Iteration 3324 => Loss: 24.1701208267\n",
      "Iteration 3325 => Loss: 24.1687098456\n",
      "Iteration 3326 => Loss: 24.1673003644\n",
      "Iteration 3327 => Loss: 24.1658923814\n",
      "Iteration 3328 => Loss: 24.1644858950\n",
      "Iteration 3329 => Loss: 24.1630809037\n",
      "Iteration 3330 => Loss: 24.1616774059\n",
      "Iteration 3331 => Loss: 24.1602754000\n",
      "Iteration 3332 => Loss: 24.1588748844\n",
      "Iteration 3333 => Loss: 24.1574758575\n",
      "Iteration 3334 => Loss: 24.1560783177\n",
      "Iteration 3335 => Loss: 24.1546822635\n",
      "Iteration 3336 => Loss: 24.1532876933\n",
      "Iteration 3337 => Loss: 24.1518946055\n",
      "Iteration 3338 => Loss: 24.1505029985\n",
      "Iteration 3339 => Loss: 24.1491128707\n",
      "Iteration 3340 => Loss: 24.1477242206\n",
      "Iteration 3341 => Loss: 24.1463370467\n",
      "Iteration 3342 => Loss: 24.1449513472\n",
      "Iteration 3343 => Loss: 24.1435671207\n",
      "Iteration 3344 => Loss: 24.1421843657\n",
      "Iteration 3345 => Loss: 24.1408030804\n",
      "Iteration 3346 => Loss: 24.1394232635\n",
      "Iteration 3347 => Loss: 24.1380449133\n",
      "Iteration 3348 => Loss: 24.1366680282\n",
      "Iteration 3349 => Loss: 24.1352926067\n",
      "Iteration 3350 => Loss: 24.1339186473\n",
      "Iteration 3351 => Loss: 24.1325461483\n",
      "Iteration 3352 => Loss: 24.1311751083\n",
      "Iteration 3353 => Loss: 24.1298055257\n",
      "Iteration 3354 => Loss: 24.1284373989\n",
      "Iteration 3355 => Loss: 24.1270707264\n",
      "Iteration 3356 => Loss: 24.1257055067\n",
      "Iteration 3357 => Loss: 24.1243417381\n",
      "Iteration 3358 => Loss: 24.1229794192\n",
      "Iteration 3359 => Loss: 24.1216185484\n",
      "Iteration 3360 => Loss: 24.1202591242\n",
      "Iteration 3361 => Loss: 24.1189011451\n",
      "Iteration 3362 => Loss: 24.1175446094\n",
      "Iteration 3363 => Loss: 24.1161895157\n",
      "Iteration 3364 => Loss: 24.1148358625\n",
      "Iteration 3365 => Loss: 24.1134836481\n",
      "Iteration 3366 => Loss: 24.1121328711\n",
      "Iteration 3367 => Loss: 24.1107835300\n",
      "Iteration 3368 => Loss: 24.1094356232\n",
      "Iteration 3369 => Loss: 24.1080891492\n",
      "Iteration 3370 => Loss: 24.1067441065\n",
      "Iteration 3371 => Loss: 24.1054004935\n",
      "Iteration 3372 => Loss: 24.1040583087\n",
      "Iteration 3373 => Loss: 24.1027175507\n",
      "Iteration 3374 => Loss: 24.1013782178\n",
      "Iteration 3375 => Loss: 24.1000403087\n",
      "Iteration 3376 => Loss: 24.0987038217\n",
      "Iteration 3377 => Loss: 24.0973687553\n",
      "Iteration 3378 => Loss: 24.0960351082\n",
      "Iteration 3379 => Loss: 24.0947028786\n",
      "Iteration 3380 => Loss: 24.0933720652\n",
      "Iteration 3381 => Loss: 24.0920426664\n",
      "Iteration 3382 => Loss: 24.0907146807\n",
      "Iteration 3383 => Loss: 24.0893881067\n",
      "Iteration 3384 => Loss: 24.0880629428\n",
      "Iteration 3385 => Loss: 24.0867391875\n",
      "Iteration 3386 => Loss: 24.0854168393\n",
      "Iteration 3387 => Loss: 24.0840958967\n",
      "Iteration 3388 => Loss: 24.0827763583\n",
      "Iteration 3389 => Loss: 24.0814582225\n",
      "Iteration 3390 => Loss: 24.0801414879\n",
      "Iteration 3391 => Loss: 24.0788261529\n",
      "Iteration 3392 => Loss: 24.0775122161\n",
      "Iteration 3393 => Loss: 24.0761996760\n",
      "Iteration 3394 => Loss: 24.0748885311\n",
      "Iteration 3395 => Loss: 24.0735787799\n",
      "Iteration 3396 => Loss: 24.0722704210\n",
      "Iteration 3397 => Loss: 24.0709634528\n",
      "Iteration 3398 => Loss: 24.0696578739\n",
      "Iteration 3399 => Loss: 24.0683536828\n",
      "Iteration 3400 => Loss: 24.0670508780\n",
      "Iteration 3401 => Loss: 24.0657494581\n",
      "Iteration 3402 => Loss: 24.0644494215\n",
      "Iteration 3403 => Loss: 24.0631507669\n",
      "Iteration 3404 => Loss: 24.0618534927\n",
      "Iteration 3405 => Loss: 24.0605575975\n",
      "Iteration 3406 => Loss: 24.0592630798\n",
      "Iteration 3407 => Loss: 24.0579699381\n",
      "Iteration 3408 => Loss: 24.0566781710\n",
      "Iteration 3409 => Loss: 24.0553877771\n",
      "Iteration 3410 => Loss: 24.0540987548\n",
      "Iteration 3411 => Loss: 24.0528111027\n",
      "Iteration 3412 => Loss: 24.0515248193\n",
      "Iteration 3413 => Loss: 24.0502399033\n",
      "Iteration 3414 => Loss: 24.0489563530\n",
      "Iteration 3415 => Loss: 24.0476741672\n",
      "Iteration 3416 => Loss: 24.0463933443\n",
      "Iteration 3417 => Loss: 24.0451138829\n",
      "Iteration 3418 => Loss: 24.0438357815\n",
      "Iteration 3419 => Loss: 24.0425590388\n",
      "Iteration 3420 => Loss: 24.0412836531\n",
      "Iteration 3421 => Loss: 24.0400096232\n",
      "Iteration 3422 => Loss: 24.0387369476\n",
      "Iteration 3423 => Loss: 24.0374656248\n",
      "Iteration 3424 => Loss: 24.0361956533\n",
      "Iteration 3425 => Loss: 24.0349270319\n",
      "Iteration 3426 => Loss: 24.0336597589\n",
      "Iteration 3427 => Loss: 24.0323938330\n",
      "Iteration 3428 => Loss: 24.0311292528\n",
      "Iteration 3429 => Loss: 24.0298660168\n",
      "Iteration 3430 => Loss: 24.0286041236\n",
      "Iteration 3431 => Loss: 24.0273435717\n",
      "Iteration 3432 => Loss: 24.0260843598\n",
      "Iteration 3433 => Loss: 24.0248264864\n",
      "Iteration 3434 => Loss: 24.0235699501\n",
      "Iteration 3435 => Loss: 24.0223147495\n",
      "Iteration 3436 => Loss: 24.0210608831\n",
      "Iteration 3437 => Loss: 24.0198083496\n",
      "Iteration 3438 => Loss: 24.0185571475\n",
      "Iteration 3439 => Loss: 24.0173072754\n",
      "Iteration 3440 => Loss: 24.0160587318\n",
      "Iteration 3441 => Loss: 24.0148115155\n",
      "Iteration 3442 => Loss: 24.0135656249\n",
      "Iteration 3443 => Loss: 24.0123210586\n",
      "Iteration 3444 => Loss: 24.0110778153\n",
      "Iteration 3445 => Loss: 24.0098358936\n",
      "Iteration 3446 => Loss: 24.0085952920\n",
      "Iteration 3447 => Loss: 24.0073560091\n",
      "Iteration 3448 => Loss: 24.0061180435\n",
      "Iteration 3449 => Loss: 24.0048813939\n",
      "Iteration 3450 => Loss: 24.0036460588\n",
      "Iteration 3451 => Loss: 24.0024120369\n",
      "Iteration 3452 => Loss: 24.0011793267\n",
      "Iteration 3453 => Loss: 23.9999479268\n",
      "Iteration 3454 => Loss: 23.9987178359\n",
      "Iteration 3455 => Loss: 23.9974890525\n",
      "Iteration 3456 => Loss: 23.9962615754\n",
      "Iteration 3457 => Loss: 23.9950354030\n",
      "Iteration 3458 => Loss: 23.9938105339\n",
      "Iteration 3459 => Loss: 23.9925869669\n",
      "Iteration 3460 => Loss: 23.9913647006\n",
      "Iteration 3461 => Loss: 23.9901437334\n",
      "Iteration 3462 => Loss: 23.9889240642\n",
      "Iteration 3463 => Loss: 23.9877056914\n",
      "Iteration 3464 => Loss: 23.9864886137\n",
      "Iteration 3465 => Loss: 23.9852728298\n",
      "Iteration 3466 => Loss: 23.9840583382\n",
      "Iteration 3467 => Loss: 23.9828451375\n",
      "Iteration 3468 => Loss: 23.9816332265\n",
      "Iteration 3469 => Loss: 23.9804226038\n",
      "Iteration 3470 => Loss: 23.9792132678\n",
      "Iteration 3471 => Loss: 23.9780052174\n",
      "Iteration 3472 => Loss: 23.9767984511\n",
      "Iteration 3473 => Loss: 23.9755929676\n",
      "Iteration 3474 => Loss: 23.9743887655\n",
      "Iteration 3475 => Loss: 23.9731858435\n",
      "Iteration 3476 => Loss: 23.9719842001\n",
      "Iteration 3477 => Loss: 23.9707838340\n",
      "Iteration 3478 => Loss: 23.9695847439\n",
      "Iteration 3479 => Loss: 23.9683869284\n",
      "Iteration 3480 => Loss: 23.9671903861\n",
      "Iteration 3481 => Loss: 23.9659951158\n",
      "Iteration 3482 => Loss: 23.9648011160\n",
      "Iteration 3483 => Loss: 23.9636083854\n",
      "Iteration 3484 => Loss: 23.9624169226\n",
      "Iteration 3485 => Loss: 23.9612267264\n",
      "Iteration 3486 => Loss: 23.9600377953\n",
      "Iteration 3487 => Loss: 23.9588501280\n",
      "Iteration 3488 => Loss: 23.9576637232\n",
      "Iteration 3489 => Loss: 23.9564785795\n",
      "Iteration 3490 => Loss: 23.9552946955\n",
      "Iteration 3491 => Loss: 23.9541120701\n",
      "Iteration 3492 => Loss: 23.9529307017\n",
      "Iteration 3493 => Loss: 23.9517505891\n",
      "Iteration 3494 => Loss: 23.9505717309\n",
      "Iteration 3495 => Loss: 23.9493941258\n",
      "Iteration 3496 => Loss: 23.9482177725\n",
      "Iteration 3497 => Loss: 23.9470426697\n",
      "Iteration 3498 => Loss: 23.9458688159\n",
      "Iteration 3499 => Loss: 23.9446962100\n",
      "Iteration 3500 => Loss: 23.9435248505\n",
      "Iteration 3501 => Loss: 23.9423547361\n",
      "Iteration 3502 => Loss: 23.9411858655\n",
      "Iteration 3503 => Loss: 23.9400182374\n",
      "Iteration 3504 => Loss: 23.9388518505\n",
      "Iteration 3505 => Loss: 23.9376867034\n",
      "Iteration 3506 => Loss: 23.9365227948\n",
      "Iteration 3507 => Loss: 23.9353601235\n",
      "Iteration 3508 => Loss: 23.9341986880\n",
      "Iteration 3509 => Loss: 23.9330384872\n",
      "Iteration 3510 => Loss: 23.9318795196\n",
      "Iteration 3511 => Loss: 23.9307217839\n",
      "Iteration 3512 => Loss: 23.9295652789\n",
      "Iteration 3513 => Loss: 23.9284100033\n",
      "Iteration 3514 => Loss: 23.9272559556\n",
      "Iteration 3515 => Loss: 23.9261031347\n",
      "Iteration 3516 => Loss: 23.9249515393\n",
      "Iteration 3517 => Loss: 23.9238011679\n",
      "Iteration 3518 => Loss: 23.9226520194\n",
      "Iteration 3519 => Loss: 23.9215040924\n",
      "Iteration 3520 => Loss: 23.9203573856\n",
      "Iteration 3521 => Loss: 23.9192118977\n",
      "Iteration 3522 => Loss: 23.9180676275\n",
      "Iteration 3523 => Loss: 23.9169245736\n",
      "Iteration 3524 => Loss: 23.9157827348\n",
      "Iteration 3525 => Loss: 23.9146421097\n",
      "Iteration 3526 => Loss: 23.9135026970\n",
      "Iteration 3527 => Loss: 23.9123644955\n",
      "Iteration 3528 => Loss: 23.9112275039\n",
      "Iteration 3529 => Loss: 23.9100917210\n",
      "Iteration 3530 => Loss: 23.9089571453\n",
      "Iteration 3531 => Loss: 23.9078237756\n",
      "Iteration 3532 => Loss: 23.9066916107\n",
      "Iteration 3533 => Loss: 23.9055606493\n",
      "Iteration 3534 => Loss: 23.9044308901\n",
      "Iteration 3535 => Loss: 23.9033023317\n",
      "Iteration 3536 => Loss: 23.9021749730\n",
      "Iteration 3537 => Loss: 23.9010488127\n",
      "Iteration 3538 => Loss: 23.8999238494\n",
      "Iteration 3539 => Loss: 23.8988000820\n",
      "Iteration 3540 => Loss: 23.8976775091\n",
      "Iteration 3541 => Loss: 23.8965561294\n",
      "Iteration 3542 => Loss: 23.8954359418\n",
      "Iteration 3543 => Loss: 23.8943169449\n",
      "Iteration 3544 => Loss: 23.8931991375\n",
      "Iteration 3545 => Loss: 23.8920825183\n",
      "Iteration 3546 => Loss: 23.8909670860\n",
      "Iteration 3547 => Loss: 23.8898528394\n",
      "Iteration 3548 => Loss: 23.8887397772\n",
      "Iteration 3549 => Loss: 23.8876278982\n",
      "Iteration 3550 => Loss: 23.8865172011\n",
      "Iteration 3551 => Loss: 23.8854076846\n",
      "Iteration 3552 => Loss: 23.8842993476\n",
      "Iteration 3553 => Loss: 23.8831921886\n",
      "Iteration 3554 => Loss: 23.8820862066\n",
      "Iteration 3555 => Loss: 23.8809814002\n",
      "Iteration 3556 => Loss: 23.8798777681\n",
      "Iteration 3557 => Loss: 23.8787753092\n",
      "Iteration 3558 => Loss: 23.8776740223\n",
      "Iteration 3559 => Loss: 23.8765739059\n",
      "Iteration 3560 => Loss: 23.8754749589\n",
      "Iteration 3561 => Loss: 23.8743771802\n",
      "Iteration 3562 => Loss: 23.8732805683\n",
      "Iteration 3563 => Loss: 23.8721851221\n",
      "Iteration 3564 => Loss: 23.8710908403\n",
      "Iteration 3565 => Loss: 23.8699977217\n",
      "Iteration 3566 => Loss: 23.8689057651\n",
      "Iteration 3567 => Loss: 23.8678149692\n",
      "Iteration 3568 => Loss: 23.8667253329\n",
      "Iteration 3569 => Loss: 23.8656368547\n",
      "Iteration 3570 => Loss: 23.8645495336\n",
      "Iteration 3571 => Loss: 23.8634633683\n",
      "Iteration 3572 => Loss: 23.8623783576\n",
      "Iteration 3573 => Loss: 23.8612945002\n",
      "Iteration 3574 => Loss: 23.8602117949\n",
      "Iteration 3575 => Loss: 23.8591302406\n",
      "Iteration 3576 => Loss: 23.8580498359\n",
      "Iteration 3577 => Loss: 23.8569705796\n",
      "Iteration 3578 => Loss: 23.8558924706\n",
      "Iteration 3579 => Loss: 23.8548155075\n",
      "Iteration 3580 => Loss: 23.8537396893\n",
      "Iteration 3581 => Loss: 23.8526650146\n",
      "Iteration 3582 => Loss: 23.8515914823\n",
      "Iteration 3583 => Loss: 23.8505190912\n",
      "Iteration 3584 => Loss: 23.8494478399\n",
      "Iteration 3585 => Loss: 23.8483777274\n",
      "Iteration 3586 => Loss: 23.8473087524\n",
      "Iteration 3587 => Loss: 23.8462409137\n",
      "Iteration 3588 => Loss: 23.8451742101\n",
      "Iteration 3589 => Loss: 23.8441086403\n",
      "Iteration 3590 => Loss: 23.8430442033\n",
      "Iteration 3591 => Loss: 23.8419808977\n",
      "Iteration 3592 => Loss: 23.8409187223\n",
      "Iteration 3593 => Loss: 23.8398576761\n",
      "Iteration 3594 => Loss: 23.8387977577\n",
      "Iteration 3595 => Loss: 23.8377389660\n",
      "Iteration 3596 => Loss: 23.8366812998\n",
      "Iteration 3597 => Loss: 23.8356247578\n",
      "Iteration 3598 => Loss: 23.8345693389\n",
      "Iteration 3599 => Loss: 23.8335150419\n",
      "Iteration 3600 => Loss: 23.8324618656\n",
      "Iteration 3601 => Loss: 23.8314098089\n",
      "Iteration 3602 => Loss: 23.8303588704\n",
      "Iteration 3603 => Loss: 23.8293090490\n",
      "Iteration 3604 => Loss: 23.8282603436\n",
      "Iteration 3605 => Loss: 23.8272127530\n",
      "Iteration 3606 => Loss: 23.8261662759\n",
      "Iteration 3607 => Loss: 23.8251209111\n",
      "Iteration 3608 => Loss: 23.8240766576\n",
      "Iteration 3609 => Loss: 23.8230335141\n",
      "Iteration 3610 => Loss: 23.8219914795\n",
      "Iteration 3611 => Loss: 23.8209505525\n",
      "Iteration 3612 => Loss: 23.8199107320\n",
      "Iteration 3613 => Loss: 23.8188720168\n",
      "Iteration 3614 => Loss: 23.8178344057\n",
      "Iteration 3615 => Loss: 23.8167978976\n",
      "Iteration 3616 => Loss: 23.8157624913\n",
      "Iteration 3617 => Loss: 23.8147281856\n",
      "Iteration 3618 => Loss: 23.8136949793\n",
      "Iteration 3619 => Loss: 23.8126628713\n",
      "Iteration 3620 => Loss: 23.8116318604\n",
      "Iteration 3621 => Loss: 23.8106019455\n",
      "Iteration 3622 => Loss: 23.8095731253\n",
      "Iteration 3623 => Loss: 23.8085453988\n",
      "Iteration 3624 => Loss: 23.8075187647\n",
      "Iteration 3625 => Loss: 23.8064932219\n",
      "Iteration 3626 => Loss: 23.8054687692\n",
      "Iteration 3627 => Loss: 23.8044454055\n",
      "Iteration 3628 => Loss: 23.8034231296\n",
      "Iteration 3629 => Loss: 23.8024019404\n",
      "Iteration 3630 => Loss: 23.8013818367\n",
      "Iteration 3631 => Loss: 23.8003628173\n",
      "Iteration 3632 => Loss: 23.7993448811\n",
      "Iteration 3633 => Loss: 23.7983280270\n",
      "Iteration 3634 => Loss: 23.7973122537\n",
      "Iteration 3635 => Loss: 23.7962975602\n",
      "Iteration 3636 => Loss: 23.7952839453\n",
      "Iteration 3637 => Loss: 23.7942714079\n",
      "Iteration 3638 => Loss: 23.7932599467\n",
      "Iteration 3639 => Loss: 23.7922495607\n",
      "Iteration 3640 => Loss: 23.7912402488\n",
      "Iteration 3641 => Loss: 23.7902320097\n",
      "Iteration 3642 => Loss: 23.7892248423\n",
      "Iteration 3643 => Loss: 23.7882187456\n",
      "Iteration 3644 => Loss: 23.7872137183\n",
      "Iteration 3645 => Loss: 23.7862097593\n",
      "Iteration 3646 => Loss: 23.7852068675\n",
      "Iteration 3647 => Loss: 23.7842050418\n",
      "Iteration 3648 => Loss: 23.7832042810\n",
      "Iteration 3649 => Loss: 23.7822045840\n",
      "Iteration 3650 => Loss: 23.7812059496\n",
      "Iteration 3651 => Loss: 23.7802083768\n",
      "Iteration 3652 => Loss: 23.7792118643\n",
      "Iteration 3653 => Loss: 23.7782164112\n",
      "Iteration 3654 => Loss: 23.7772220161\n",
      "Iteration 3655 => Loss: 23.7762286781\n",
      "Iteration 3656 => Loss: 23.7752363960\n",
      "Iteration 3657 => Loss: 23.7742451687\n",
      "Iteration 3658 => Loss: 23.7732549950\n",
      "Iteration 3659 => Loss: 23.7722658739\n",
      "Iteration 3660 => Loss: 23.7712778041\n",
      "Iteration 3661 => Loss: 23.7702907847\n",
      "Iteration 3662 => Loss: 23.7693048145\n",
      "Iteration 3663 => Loss: 23.7683198923\n",
      "Iteration 3664 => Loss: 23.7673360170\n",
      "Iteration 3665 => Loss: 23.7663531876\n",
      "Iteration 3666 => Loss: 23.7653714030\n",
      "Iteration 3667 => Loss: 23.7643906619\n",
      "Iteration 3668 => Loss: 23.7634109634\n",
      "Iteration 3669 => Loss: 23.7624323062\n",
      "Iteration 3670 => Loss: 23.7614546894\n",
      "Iteration 3671 => Loss: 23.7604781117\n",
      "Iteration 3672 => Loss: 23.7595025721\n",
      "Iteration 3673 => Loss: 23.7585280695\n",
      "Iteration 3674 => Loss: 23.7575546028\n",
      "Iteration 3675 => Loss: 23.7565821708\n",
      "Iteration 3676 => Loss: 23.7556107725\n",
      "Iteration 3677 => Loss: 23.7546404068\n",
      "Iteration 3678 => Loss: 23.7536710726\n",
      "Iteration 3679 => Loss: 23.7527027687\n",
      "Iteration 3680 => Loss: 23.7517354942\n",
      "Iteration 3681 => Loss: 23.7507692478\n",
      "Iteration 3682 => Loss: 23.7498040285\n",
      "Iteration 3683 => Loss: 23.7488398352\n",
      "Iteration 3684 => Loss: 23.7478766669\n",
      "Iteration 3685 => Loss: 23.7469145224\n",
      "Iteration 3686 => Loss: 23.7459534006\n",
      "Iteration 3687 => Loss: 23.7449933005\n",
      "Iteration 3688 => Loss: 23.7440342209\n",
      "Iteration 3689 => Loss: 23.7430761608\n",
      "Iteration 3690 => Loss: 23.7421191191\n",
      "Iteration 3691 => Loss: 23.7411630948\n",
      "Iteration 3692 => Loss: 23.7402080866\n",
      "Iteration 3693 => Loss: 23.7392540936\n",
      "Iteration 3694 => Loss: 23.7383011147\n",
      "Iteration 3695 => Loss: 23.7373491488\n",
      "Iteration 3696 => Loss: 23.7363981948\n",
      "Iteration 3697 => Loss: 23.7354482517\n",
      "Iteration 3698 => Loss: 23.7344993183\n",
      "Iteration 3699 => Loss: 23.7335513936\n",
      "Iteration 3700 => Loss: 23.7326044766\n",
      "Iteration 3701 => Loss: 23.7316585661\n",
      "Iteration 3702 => Loss: 23.7307136610\n",
      "Iteration 3703 => Loss: 23.7297697604\n",
      "Iteration 3704 => Loss: 23.7288268632\n",
      "Iteration 3705 => Loss: 23.7278849682\n",
      "Iteration 3706 => Loss: 23.7269440744\n",
      "Iteration 3707 => Loss: 23.7260041808\n",
      "Iteration 3708 => Loss: 23.7250652863\n",
      "Iteration 3709 => Loss: 23.7241273897\n",
      "Iteration 3710 => Loss: 23.7231904902\n",
      "Iteration 3711 => Loss: 23.7222545866\n",
      "Iteration 3712 => Loss: 23.7213196778\n",
      "Iteration 3713 => Loss: 23.7203857628\n",
      "Iteration 3714 => Loss: 23.7194528405\n",
      "Iteration 3715 => Loss: 23.7185209099\n",
      "Iteration 3716 => Loss: 23.7175899699\n",
      "Iteration 3717 => Loss: 23.7166600195\n",
      "Iteration 3718 => Loss: 23.7157310576\n",
      "Iteration 3719 => Loss: 23.7148030832\n",
      "Iteration 3720 => Loss: 23.7138760952\n",
      "Iteration 3721 => Loss: 23.7129500926\n",
      "Iteration 3722 => Loss: 23.7120250743\n",
      "Iteration 3723 => Loss: 23.7111010392\n",
      "Iteration 3724 => Loss: 23.7101779864\n",
      "Iteration 3725 => Loss: 23.7092559148\n",
      "Iteration 3726 => Loss: 23.7083348233\n",
      "Iteration 3727 => Loss: 23.7074147109\n",
      "Iteration 3728 => Loss: 23.7064955766\n",
      "Iteration 3729 => Loss: 23.7055774193\n",
      "Iteration 3730 => Loss: 23.7046602380\n",
      "Iteration 3731 => Loss: 23.7037440316\n",
      "Iteration 3732 => Loss: 23.7028287991\n",
      "Iteration 3733 => Loss: 23.7019145395\n",
      "Iteration 3734 => Loss: 23.7010012518\n",
      "Iteration 3735 => Loss: 23.7000889348\n",
      "Iteration 3736 => Loss: 23.6991775877\n",
      "Iteration 3737 => Loss: 23.6982672092\n",
      "Iteration 3738 => Loss: 23.6973577985\n",
      "Iteration 3739 => Loss: 23.6964493545\n",
      "Iteration 3740 => Loss: 23.6955418761\n",
      "Iteration 3741 => Loss: 23.6946353623\n",
      "Iteration 3742 => Loss: 23.6937298122\n",
      "Iteration 3743 => Loss: 23.6928252246\n",
      "Iteration 3744 => Loss: 23.6919215986\n",
      "Iteration 3745 => Loss: 23.6910189331\n",
      "Iteration 3746 => Loss: 23.6901172272\n",
      "Iteration 3747 => Loss: 23.6892164797\n",
      "Iteration 3748 => Loss: 23.6883166897\n",
      "Iteration 3749 => Loss: 23.6874178562\n",
      "Iteration 3750 => Loss: 23.6865199781\n",
      "Iteration 3751 => Loss: 23.6856230545\n",
      "Iteration 3752 => Loss: 23.6847270842\n",
      "Iteration 3753 => Loss: 23.6838320663\n",
      "Iteration 3754 => Loss: 23.6829379999\n",
      "Iteration 3755 => Loss: 23.6820448838\n",
      "Iteration 3756 => Loss: 23.6811527170\n",
      "Iteration 3757 => Loss: 23.6802614987\n",
      "Iteration 3758 => Loss: 23.6793712276\n",
      "Iteration 3759 => Loss: 23.6784819029\n",
      "Iteration 3760 => Loss: 23.6775935236\n",
      "Iteration 3761 => Loss: 23.6767060885\n",
      "Iteration 3762 => Loss: 23.6758195968\n",
      "Iteration 3763 => Loss: 23.6749340475\n",
      "Iteration 3764 => Loss: 23.6740494394\n",
      "Iteration 3765 => Loss: 23.6731657716\n",
      "Iteration 3766 => Loss: 23.6722830432\n",
      "Iteration 3767 => Loss: 23.6714012531\n",
      "Iteration 3768 => Loss: 23.6705204003\n",
      "Iteration 3769 => Loss: 23.6696404839\n",
      "Iteration 3770 => Loss: 23.6687615028\n",
      "Iteration 3771 => Loss: 23.6678834560\n",
      "Iteration 3772 => Loss: 23.6670063425\n",
      "Iteration 3773 => Loss: 23.6661301615\n",
      "Iteration 3774 => Loss: 23.6652549117\n",
      "Iteration 3775 => Loss: 23.6643805924\n",
      "Iteration 3776 => Loss: 23.6635072024\n",
      "Iteration 3777 => Loss: 23.6626347408\n",
      "Iteration 3778 => Loss: 23.6617632067\n",
      "Iteration 3779 => Loss: 23.6608925989\n",
      "Iteration 3780 => Loss: 23.6600229166\n",
      "Iteration 3781 => Loss: 23.6591541588\n",
      "Iteration 3782 => Loss: 23.6582863244\n",
      "Iteration 3783 => Loss: 23.6574194125\n",
      "Iteration 3784 => Loss: 23.6565534221\n",
      "Iteration 3785 => Loss: 23.6556883523\n",
      "Iteration 3786 => Loss: 23.6548242020\n",
      "Iteration 3787 => Loss: 23.6539609703\n",
      "Iteration 3788 => Loss: 23.6530986561\n",
      "Iteration 3789 => Loss: 23.6522372586\n",
      "Iteration 3790 => Loss: 23.6513767768\n",
      "Iteration 3791 => Loss: 23.6505172096\n",
      "Iteration 3792 => Loss: 23.6496585561\n",
      "Iteration 3793 => Loss: 23.6488008153\n",
      "Iteration 3794 => Loss: 23.6479439863\n",
      "Iteration 3795 => Loss: 23.6470880681\n",
      "Iteration 3796 => Loss: 23.6462330597\n",
      "Iteration 3797 => Loss: 23.6453789602\n",
      "Iteration 3798 => Loss: 23.6445257686\n",
      "Iteration 3799 => Loss: 23.6436734839\n",
      "Iteration 3800 => Loss: 23.6428221051\n",
      "Iteration 3801 => Loss: 23.6419716314\n",
      "Iteration 3802 => Loss: 23.6411220617\n",
      "Iteration 3803 => Loss: 23.6402733950\n",
      "Iteration 3804 => Loss: 23.6394256305\n",
      "Iteration 3805 => Loss: 23.6385787671\n",
      "Iteration 3806 => Loss: 23.6377328039\n",
      "Iteration 3807 => Loss: 23.6368877400\n",
      "Iteration 3808 => Loss: 23.6360435744\n",
      "Iteration 3809 => Loss: 23.6352003060\n",
      "Iteration 3810 => Loss: 23.6343579341\n",
      "Iteration 3811 => Loss: 23.6335164576\n",
      "Iteration 3812 => Loss: 23.6326758755\n",
      "Iteration 3813 => Loss: 23.6318361870\n",
      "Iteration 3814 => Loss: 23.6309973910\n",
      "Iteration 3815 => Loss: 23.6301594867\n",
      "Iteration 3816 => Loss: 23.6293224731\n",
      "Iteration 3817 => Loss: 23.6284863491\n",
      "Iteration 3818 => Loss: 23.6276511140\n",
      "Iteration 3819 => Loss: 23.6268167667\n",
      "Iteration 3820 => Loss: 23.6259833062\n",
      "Iteration 3821 => Loss: 23.6251507318\n",
      "Iteration 3822 => Loss: 23.6243190423\n",
      "Iteration 3823 => Loss: 23.6234882369\n",
      "Iteration 3824 => Loss: 23.6226583147\n",
      "Iteration 3825 => Loss: 23.6218292746\n",
      "Iteration 3826 => Loss: 23.6210011158\n",
      "Iteration 3827 => Loss: 23.6201738373\n",
      "Iteration 3828 => Loss: 23.6193474381\n",
      "Iteration 3829 => Loss: 23.6185219175\n",
      "Iteration 3830 => Loss: 23.6176972743\n",
      "Iteration 3831 => Loss: 23.6168735077\n",
      "Iteration 3832 => Loss: 23.6160506168\n",
      "Iteration 3833 => Loss: 23.6152286005\n",
      "Iteration 3834 => Loss: 23.6144074581\n",
      "Iteration 3835 => Loss: 23.6135871885\n",
      "Iteration 3836 => Loss: 23.6127677908\n",
      "Iteration 3837 => Loss: 23.6119492642\n",
      "Iteration 3838 => Loss: 23.6111316076\n",
      "Iteration 3839 => Loss: 23.6103148202\n",
      "Iteration 3840 => Loss: 23.6094989010\n",
      "Iteration 3841 => Loss: 23.6086838491\n",
      "Iteration 3842 => Loss: 23.6078696636\n",
      "Iteration 3843 => Loss: 23.6070563435\n",
      "Iteration 3844 => Loss: 23.6062438880\n",
      "Iteration 3845 => Loss: 23.6054322961\n",
      "Iteration 3846 => Loss: 23.6046215669\n",
      "Iteration 3847 => Loss: 23.6038116996\n",
      "Iteration 3848 => Loss: 23.6030026930\n",
      "Iteration 3849 => Loss: 23.6021945465\n",
      "Iteration 3850 => Loss: 23.6013872589\n",
      "Iteration 3851 => Loss: 23.6005808296\n",
      "Iteration 3852 => Loss: 23.5997752574\n",
      "Iteration 3853 => Loss: 23.5989705415\n",
      "Iteration 3854 => Loss: 23.5981666810\n",
      "Iteration 3855 => Loss: 23.5973636751\n",
      "Iteration 3856 => Loss: 23.5965615226\n",
      "Iteration 3857 => Loss: 23.5957602229\n",
      "Iteration 3858 => Loss: 23.5949597749\n",
      "Iteration 3859 => Loss: 23.5941601778\n",
      "Iteration 3860 => Loss: 23.5933614307\n",
      "Iteration 3861 => Loss: 23.5925635326\n",
      "Iteration 3862 => Loss: 23.5917664826\n",
      "Iteration 3863 => Loss: 23.5909702799\n",
      "Iteration 3864 => Loss: 23.5901749235\n",
      "Iteration 3865 => Loss: 23.5893804126\n",
      "Iteration 3866 => Loss: 23.5885867462\n",
      "Iteration 3867 => Loss: 23.5877939235\n",
      "Iteration 3868 => Loss: 23.5870019436\n",
      "Iteration 3869 => Loss: 23.5862108054\n",
      "Iteration 3870 => Loss: 23.5854205083\n",
      "Iteration 3871 => Loss: 23.5846310512\n",
      "Iteration 3872 => Loss: 23.5838424333\n",
      "Iteration 3873 => Loss: 23.5830546537\n",
      "Iteration 3874 => Loss: 23.5822677115\n",
      "Iteration 3875 => Loss: 23.5814816058\n",
      "Iteration 3876 => Loss: 23.5806963357\n",
      "Iteration 3877 => Loss: 23.5799119003\n",
      "Iteration 3878 => Loss: 23.5791282987\n",
      "Iteration 3879 => Loss: 23.5783455302\n",
      "Iteration 3880 => Loss: 23.5775635936\n",
      "Iteration 3881 => Loss: 23.5767824883\n",
      "Iteration 3882 => Loss: 23.5760022133\n",
      "Iteration 3883 => Loss: 23.5752227676\n",
      "Iteration 3884 => Loss: 23.5744441505\n",
      "Iteration 3885 => Loss: 23.5736663611\n",
      "Iteration 3886 => Loss: 23.5728893984\n",
      "Iteration 3887 => Loss: 23.5721132617\n",
      "Iteration 3888 => Loss: 23.5713379499\n",
      "Iteration 3889 => Loss: 23.5705634623\n",
      "Iteration 3890 => Loss: 23.5697897979\n",
      "Iteration 3891 => Loss: 23.5690169560\n",
      "Iteration 3892 => Loss: 23.5682449355\n",
      "Iteration 3893 => Loss: 23.5674737357\n",
      "Iteration 3894 => Loss: 23.5667033557\n",
      "Iteration 3895 => Loss: 23.5659337945\n",
      "Iteration 3896 => Loss: 23.5651650514\n",
      "Iteration 3897 => Loss: 23.5643971255\n",
      "Iteration 3898 => Loss: 23.5636300158\n",
      "Iteration 3899 => Loss: 23.5628637216\n",
      "Iteration 3900 => Loss: 23.5620982419\n",
      "Iteration 3901 => Loss: 23.5613335759\n",
      "Iteration 3902 => Loss: 23.5605697227\n",
      "Iteration 3903 => Loss: 23.5598066815\n",
      "Iteration 3904 => Loss: 23.5590444514\n",
      "Iteration 3905 => Loss: 23.5582830315\n",
      "Iteration 3906 => Loss: 23.5575224210\n",
      "Iteration 3907 => Loss: 23.5567626190\n",
      "Iteration 3908 => Loss: 23.5560036246\n",
      "Iteration 3909 => Loss: 23.5552454371\n",
      "Iteration 3910 => Loss: 23.5544880554\n",
      "Iteration 3911 => Loss: 23.5537314789\n",
      "Iteration 3912 => Loss: 23.5529757066\n",
      "Iteration 3913 => Loss: 23.5522207377\n",
      "Iteration 3914 => Loss: 23.5514665712\n",
      "Iteration 3915 => Loss: 23.5507132065\n",
      "Iteration 3916 => Loss: 23.5499606425\n",
      "Iteration 3917 => Loss: 23.5492088785\n",
      "Iteration 3918 => Loss: 23.5484579136\n",
      "Iteration 3919 => Loss: 23.5477077470\n",
      "Iteration 3920 => Loss: 23.5469583778\n",
      "Iteration 3921 => Loss: 23.5462098052\n",
      "Iteration 3922 => Loss: 23.5454620282\n",
      "Iteration 3923 => Loss: 23.5447150462\n",
      "Iteration 3924 => Loss: 23.5439688581\n",
      "Iteration 3925 => Loss: 23.5432234633\n",
      "Iteration 3926 => Loss: 23.5424788608\n",
      "Iteration 3927 => Loss: 23.5417350498\n",
      "Iteration 3928 => Loss: 23.5409920294\n",
      "Iteration 3929 => Loss: 23.5402497989\n",
      "Iteration 3930 => Loss: 23.5395083573\n",
      "Iteration 3931 => Loss: 23.5387677039\n",
      "Iteration 3932 => Loss: 23.5380278377\n",
      "Iteration 3933 => Loss: 23.5372887580\n",
      "Iteration 3934 => Loss: 23.5365504640\n",
      "Iteration 3935 => Loss: 23.5358129547\n",
      "Iteration 3936 => Loss: 23.5350762294\n",
      "Iteration 3937 => Loss: 23.5343402873\n",
      "Iteration 3938 => Loss: 23.5336051274\n",
      "Iteration 3939 => Loss: 23.5328707490\n",
      "Iteration 3940 => Loss: 23.5321371512\n",
      "Iteration 3941 => Loss: 23.5314043332\n",
      "Iteration 3942 => Loss: 23.5306722941\n",
      "Iteration 3943 => Loss: 23.5299410333\n",
      "Iteration 3944 => Loss: 23.5292105497\n",
      "Iteration 3945 => Loss: 23.5284808426\n",
      "Iteration 3946 => Loss: 23.5277519112\n",
      "Iteration 3947 => Loss: 23.5270237546\n",
      "Iteration 3948 => Loss: 23.5262963720\n",
      "Iteration 3949 => Loss: 23.5255697627\n",
      "Iteration 3950 => Loss: 23.5248439257\n",
      "Iteration 3951 => Loss: 23.5241188602\n",
      "Iteration 3952 => Loss: 23.5233945655\n",
      "Iteration 3953 => Loss: 23.5226710407\n",
      "Iteration 3954 => Loss: 23.5219482849\n",
      "Iteration 3955 => Loss: 23.5212262975\n",
      "Iteration 3956 => Loss: 23.5205050775\n",
      "Iteration 3957 => Loss: 23.5197846241\n",
      "Iteration 3958 => Loss: 23.5190649366\n",
      "Iteration 3959 => Loss: 23.5183460141\n",
      "Iteration 3960 => Loss: 23.5176278558\n",
      "Iteration 3961 => Loss: 23.5169104609\n",
      "Iteration 3962 => Loss: 23.5161938285\n",
      "Iteration 3963 => Loss: 23.5154779579\n",
      "Iteration 3964 => Loss: 23.5147628483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3965 => Loss: 23.5140484988\n",
      "Iteration 3966 => Loss: 23.5133349087\n",
      "Iteration 3967 => Loss: 23.5126220771\n",
      "Iteration 3968 => Loss: 23.5119100032\n",
      "Iteration 3969 => Loss: 23.5111986862\n",
      "Iteration 3970 => Loss: 23.5104881253\n",
      "Iteration 3971 => Loss: 23.5097783198\n",
      "Iteration 3972 => Loss: 23.5090692688\n",
      "Iteration 3973 => Loss: 23.5083609714\n",
      "Iteration 3974 => Loss: 23.5076534270\n",
      "Iteration 3975 => Loss: 23.5069466347\n",
      "Iteration 3976 => Loss: 23.5062405937\n",
      "Iteration 3977 => Loss: 23.5055353032\n",
      "Iteration 3978 => Loss: 23.5048307624\n",
      "Iteration 3979 => Loss: 23.5041269705\n",
      "Iteration 3980 => Loss: 23.5034239267\n",
      "Iteration 3981 => Loss: 23.5027216303\n",
      "Iteration 3982 => Loss: 23.5020200803\n",
      "Iteration 3983 => Loss: 23.5013192762\n",
      "Iteration 3984 => Loss: 23.5006192169\n",
      "Iteration 3985 => Loss: 23.4999199018\n",
      "Iteration 3986 => Loss: 23.4992213300\n",
      "Iteration 3987 => Loss: 23.4985235009\n",
      "Iteration 3988 => Loss: 23.4978264135\n",
      "Iteration 3989 => Loss: 23.4971300671\n",
      "Iteration 3990 => Loss: 23.4964344608\n",
      "Iteration 3991 => Loss: 23.4957395940\n",
      "Iteration 3992 => Loss: 23.4950454659\n",
      "Iteration 3993 => Loss: 23.4943520756\n",
      "Iteration 3994 => Loss: 23.4936594223\n",
      "Iteration 3995 => Loss: 23.4929675053\n",
      "Iteration 3996 => Loss: 23.4922763238\n",
      "Iteration 3997 => Loss: 23.4915858770\n",
      "Iteration 3998 => Loss: 23.4908961642\n",
      "Iteration 3999 => Loss: 23.4902071845\n",
      "Iteration 4000 => Loss: 23.4895189371\n",
      "Iteration 4001 => Loss: 23.4888314214\n",
      "Iteration 4002 => Loss: 23.4881446365\n",
      "Iteration 4003 => Loss: 23.4874585816\n",
      "Iteration 4004 => Loss: 23.4867732559\n",
      "Iteration 4005 => Loss: 23.4860886588\n",
      "Iteration 4006 => Loss: 23.4854047894\n",
      "Iteration 4007 => Loss: 23.4847216469\n",
      "Iteration 4008 => Loss: 23.4840392306\n",
      "Iteration 4009 => Loss: 23.4833575396\n",
      "Iteration 4010 => Loss: 23.4826765733\n",
      "Iteration 4011 => Loss: 23.4819963309\n",
      "Iteration 4012 => Loss: 23.4813168115\n",
      "Iteration 4013 => Loss: 23.4806380144\n",
      "Iteration 4014 => Loss: 23.4799599389\n",
      "Iteration 4015 => Loss: 23.4792825842\n",
      "Iteration 4016 => Loss: 23.4786059495\n",
      "Iteration 4017 => Loss: 23.4779300340\n",
      "Iteration 4018 => Loss: 23.4772548370\n",
      "Iteration 4019 => Loss: 23.4765803578\n",
      "Iteration 4020 => Loss: 23.4759065955\n",
      "Iteration 4021 => Loss: 23.4752335493\n",
      "Iteration 4022 => Loss: 23.4745612187\n",
      "Iteration 4023 => Loss: 23.4738896027\n",
      "Iteration 4024 => Loss: 23.4732187006\n",
      "Iteration 4025 => Loss: 23.4725485116\n",
      "Iteration 4026 => Loss: 23.4718790351\n",
      "Iteration 4027 => Loss: 23.4712102702\n",
      "Iteration 4028 => Loss: 23.4705422162\n",
      "Iteration 4029 => Loss: 23.4698748723\n",
      "Iteration 4030 => Loss: 23.4692082378\n",
      "Iteration 4031 => Loss: 23.4685423119\n",
      "Iteration 4032 => Loss: 23.4678770938\n",
      "Iteration 4033 => Loss: 23.4672125829\n",
      "Iteration 4034 => Loss: 23.4665487783\n",
      "Iteration 4035 => Loss: 23.4658856794\n",
      "Iteration 4036 => Loss: 23.4652232853\n",
      "Iteration 4037 => Loss: 23.4645615953\n",
      "Iteration 4038 => Loss: 23.4639006087\n",
      "Iteration 4039 => Loss: 23.4632403247\n",
      "Iteration 4040 => Loss: 23.4625807426\n",
      "Iteration 4041 => Loss: 23.4619218616\n",
      "Iteration 4042 => Loss: 23.4612636809\n",
      "Iteration 4043 => Loss: 23.4606061999\n",
      "Iteration 4044 => Loss: 23.4599494178\n",
      "Iteration 4045 => Loss: 23.4592933338\n",
      "Iteration 4046 => Loss: 23.4586379473\n",
      "Iteration 4047 => Loss: 23.4579832574\n",
      "Iteration 4048 => Loss: 23.4573292634\n",
      "Iteration 4049 => Loss: 23.4566759646\n",
      "Iteration 4050 => Loss: 23.4560233602\n",
      "Iteration 4051 => Loss: 23.4553714496\n",
      "Iteration 4052 => Loss: 23.4547202319\n",
      "Iteration 4053 => Loss: 23.4540697064\n",
      "Iteration 4054 => Loss: 23.4534198724\n",
      "Iteration 4055 => Loss: 23.4527707292\n",
      "Iteration 4056 => Loss: 23.4521222761\n",
      "Iteration 4057 => Loss: 23.4514745122\n",
      "Iteration 4058 => Loss: 23.4508274369\n",
      "Iteration 4059 => Loss: 23.4501810494\n",
      "Iteration 4060 => Loss: 23.4495353489\n",
      "Iteration 4061 => Loss: 23.4488903349\n",
      "Iteration 4062 => Loss: 23.4482460065\n",
      "Iteration 4063 => Loss: 23.4476023630\n",
      "Iteration 4064 => Loss: 23.4469594037\n",
      "Iteration 4065 => Loss: 23.4463171278\n",
      "Iteration 4066 => Loss: 23.4456755347\n",
      "Iteration 4067 => Loss: 23.4450346236\n",
      "Iteration 4068 => Loss: 23.4443943937\n",
      "Iteration 4069 => Loss: 23.4437548444\n",
      "Iteration 4070 => Loss: 23.4431159749\n",
      "Iteration 4071 => Loss: 23.4424777845\n",
      "Iteration 4072 => Loss: 23.4418402725\n",
      "Iteration 4073 => Loss: 23.4412034382\n",
      "Iteration 4074 => Loss: 23.4405672808\n",
      "Iteration 4075 => Loss: 23.4399317996\n",
      "Iteration 4076 => Loss: 23.4392969940\n",
      "Iteration 4077 => Loss: 23.4386628631\n",
      "Iteration 4078 => Loss: 23.4380294063\n",
      "Iteration 4079 => Loss: 23.4373966228\n",
      "Iteration 4080 => Loss: 23.4367645120\n",
      "Iteration 4081 => Loss: 23.4361330731\n",
      "Iteration 4082 => Loss: 23.4355023054\n",
      "Iteration 4083 => Loss: 23.4348722082\n",
      "Iteration 4084 => Loss: 23.4342427807\n",
      "Iteration 4085 => Loss: 23.4336140224\n",
      "Iteration 4086 => Loss: 23.4329859324\n",
      "Iteration 4087 => Loss: 23.4323585100\n",
      "Iteration 4088 => Loss: 23.4317317546\n",
      "Iteration 4089 => Loss: 23.4311056654\n",
      "Iteration 4090 => Loss: 23.4304802417\n",
      "Iteration 4091 => Loss: 23.4298554829\n",
      "Iteration 4092 => Loss: 23.4292313881\n",
      "Iteration 4093 => Loss: 23.4286079567\n",
      "Iteration 4094 => Loss: 23.4279851881\n",
      "Iteration 4095 => Loss: 23.4273630814\n",
      "Iteration 4096 => Loss: 23.4267416360\n",
      "Iteration 4097 => Loss: 23.4261208512\n",
      "Iteration 4098 => Loss: 23.4255007263\n",
      "Iteration 4099 => Loss: 23.4248812605\n",
      "Iteration 4100 => Loss: 23.4242624533\n",
      "Iteration 4101 => Loss: 23.4236443038\n",
      "Iteration 4102 => Loss: 23.4230268114\n",
      "Iteration 4103 => Loss: 23.4224099754\n",
      "Iteration 4104 => Loss: 23.4217937950\n",
      "Iteration 4105 => Loss: 23.4211782697\n",
      "Iteration 4106 => Loss: 23.4205633986\n",
      "Iteration 4107 => Loss: 23.4199491811\n",
      "Iteration 4108 => Loss: 23.4193356166\n",
      "Iteration 4109 => Loss: 23.4187227042\n",
      "Iteration 4110 => Loss: 23.4181104433\n",
      "Iteration 4111 => Loss: 23.4174988333\n",
      "Iteration 4112 => Loss: 23.4168878734\n",
      "Iteration 4113 => Loss: 23.4162775630\n",
      "Iteration 4114 => Loss: 23.4156679012\n",
      "Iteration 4115 => Loss: 23.4150588876\n",
      "Iteration 4116 => Loss: 23.4144505213\n",
      "Iteration 4117 => Loss: 23.4138428017\n",
      "Iteration 4118 => Loss: 23.4132357281\n",
      "Iteration 4119 => Loss: 23.4126292997\n",
      "Iteration 4120 => Loss: 23.4120235161\n",
      "Iteration 4121 => Loss: 23.4114183763\n",
      "Iteration 4122 => Loss: 23.4108138798\n",
      "Iteration 4123 => Loss: 23.4102100259\n",
      "Iteration 4124 => Loss: 23.4096068138\n",
      "Iteration 4125 => Loss: 23.4090042430\n",
      "Iteration 4126 => Loss: 23.4084023126\n",
      "Iteration 4127 => Loss: 23.4078010221\n",
      "Iteration 4128 => Loss: 23.4072003708\n",
      "Iteration 4129 => Loss: 23.4066003579\n",
      "Iteration 4130 => Loss: 23.4060009829\n",
      "Iteration 4131 => Loss: 23.4054022450\n",
      "Iteration 4132 => Loss: 23.4048041435\n",
      "Iteration 4133 => Loss: 23.4042066778\n",
      "Iteration 4134 => Loss: 23.4036098471\n",
      "Iteration 4135 => Loss: 23.4030136509\n",
      "Iteration 4136 => Loss: 23.4024180885\n",
      "Iteration 4137 => Loss: 23.4018231591\n",
      "Iteration 4138 => Loss: 23.4012288621\n",
      "Iteration 4139 => Loss: 23.4006351968\n",
      "Iteration 4140 => Loss: 23.4000421626\n",
      "Iteration 4141 => Loss: 23.3994497588\n",
      "Iteration 4142 => Loss: 23.3988579847\n",
      "Iteration 4143 => Loss: 23.3982668396\n",
      "Iteration 4144 => Loss: 23.3976763229\n",
      "Iteration 4145 => Loss: 23.3970864339\n",
      "Iteration 4146 => Loss: 23.3964971719\n",
      "Iteration 4147 => Loss: 23.3959085363\n",
      "Iteration 4148 => Loss: 23.3953205265\n",
      "Iteration 4149 => Loss: 23.3947331416\n",
      "Iteration 4150 => Loss: 23.3941463812\n",
      "Iteration 4151 => Loss: 23.3935602444\n",
      "Iteration 4152 => Loss: 23.3929747308\n",
      "Iteration 4153 => Loss: 23.3923898395\n",
      "Iteration 4154 => Loss: 23.3918055699\n",
      "Iteration 4155 => Loss: 23.3912219214\n",
      "Iteration 4156 => Loss: 23.3906388933\n",
      "Iteration 4157 => Loss: 23.3900564849\n",
      "Iteration 4158 => Loss: 23.3894746956\n",
      "Iteration 4159 => Loss: 23.3888935248\n",
      "Iteration 4160 => Loss: 23.3883129717\n",
      "Iteration 4161 => Loss: 23.3877330358\n",
      "Iteration 4162 => Loss: 23.3871537163\n",
      "Iteration 4163 => Loss: 23.3865750126\n",
      "Iteration 4164 => Loss: 23.3859969241\n",
      "Iteration 4165 => Loss: 23.3854194500\n",
      "Iteration 4166 => Loss: 23.3848425898\n",
      "Iteration 4167 => Loss: 23.3842663428\n",
      "Iteration 4168 => Loss: 23.3836907084\n",
      "Iteration 4169 => Loss: 23.3831156858\n",
      "Iteration 4170 => Loss: 23.3825412744\n",
      "Iteration 4171 => Loss: 23.3819674737\n",
      "Iteration 4172 => Loss: 23.3813942828\n",
      "Iteration 4173 => Loss: 23.3808217013\n",
      "Iteration 4174 => Loss: 23.3802497284\n",
      "Iteration 4175 => Loss: 23.3796783635\n",
      "Iteration 4176 => Loss: 23.3791076060\n",
      "Iteration 4177 => Loss: 23.3785374551\n",
      "Iteration 4178 => Loss: 23.3779679104\n",
      "Iteration 4179 => Loss: 23.3773989710\n",
      "Iteration 4180 => Loss: 23.3768306364\n",
      "Iteration 4181 => Loss: 23.3762629059\n",
      "Iteration 4182 => Loss: 23.3756957789\n",
      "Iteration 4183 => Loss: 23.3751292548\n",
      "Iteration 4184 => Loss: 23.3745633329\n",
      "Iteration 4185 => Loss: 23.3739980125\n",
      "Iteration 4186 => Loss: 23.3734332930\n",
      "Iteration 4187 => Loss: 23.3728691739\n",
      "Iteration 4188 => Loss: 23.3723056543\n",
      "Iteration 4189 => Loss: 23.3717427338\n",
      "Iteration 4190 => Loss: 23.3711804117\n",
      "Iteration 4191 => Loss: 23.3706186873\n",
      "Iteration 4192 => Loss: 23.3700575600\n",
      "Iteration 4193 => Loss: 23.3694970291\n",
      "Iteration 4194 => Loss: 23.3689370941\n",
      "Iteration 4195 => Loss: 23.3683777543\n",
      "Iteration 4196 => Loss: 23.3678190091\n",
      "Iteration 4197 => Loss: 23.3672608578\n",
      "Iteration 4198 => Loss: 23.3667032998\n",
      "Iteration 4199 => Loss: 23.3661463345\n",
      "Iteration 4200 => Loss: 23.3655899612\n",
      "Iteration 4201 => Loss: 23.3650341793\n",
      "Iteration 4202 => Loss: 23.3644789882\n",
      "Iteration 4203 => Loss: 23.3639243873\n",
      "Iteration 4204 => Loss: 23.3633703759\n",
      "Iteration 4205 => Loss: 23.3628169534\n",
      "Iteration 4206 => Loss: 23.3622641192\n",
      "Iteration 4207 => Loss: 23.3617118726\n",
      "Iteration 4208 => Loss: 23.3611602130\n",
      "Iteration 4209 => Loss: 23.3606091399\n",
      "Iteration 4210 => Loss: 23.3600586525\n",
      "Iteration 4211 => Loss: 23.3595087503\n",
      "Iteration 4212 => Loss: 23.3589594326\n",
      "Iteration 4213 => Loss: 23.3584106989\n",
      "Iteration 4214 => Loss: 23.3578625484\n",
      "Iteration 4215 => Loss: 23.3573149806\n",
      "Iteration 4216 => Loss: 23.3567679949\n",
      "Iteration 4217 => Loss: 23.3562215906\n",
      "Iteration 4218 => Loss: 23.3556757671\n",
      "Iteration 4219 => Loss: 23.3551305238\n",
      "Iteration 4220 => Loss: 23.3545858601\n",
      "Iteration 4221 => Loss: 23.3540417753\n",
      "Iteration 4222 => Loss: 23.3534982689\n",
      "Iteration 4223 => Loss: 23.3529553403\n",
      "Iteration 4224 => Loss: 23.3524129887\n",
      "Iteration 4225 => Loss: 23.3518712137\n",
      "Iteration 4226 => Loss: 23.3513300145\n",
      "Iteration 4227 => Loss: 23.3507893907\n",
      "Iteration 4228 => Loss: 23.3502493415\n",
      "Iteration 4229 => Loss: 23.3497098664\n",
      "Iteration 4230 => Loss: 23.3491709647\n",
      "Iteration 4231 => Loss: 23.3486326359\n",
      "Iteration 4232 => Loss: 23.3480948793\n",
      "Iteration 4233 => Loss: 23.3475576943\n",
      "Iteration 4234 => Loss: 23.3470210804\n",
      "Iteration 4235 => Loss: 23.3464850368\n",
      "Iteration 4236 => Loss: 23.3459495631\n",
      "Iteration 4237 => Loss: 23.3454146585\n",
      "Iteration 4238 => Loss: 23.3448803226\n",
      "Iteration 4239 => Loss: 23.3443465546\n",
      "Iteration 4240 => Loss: 23.3438133540\n",
      "Iteration 4241 => Loss: 23.3432807202\n",
      "Iteration 4242 => Loss: 23.3427486526\n",
      "Iteration 4243 => Loss: 23.3422171506\n",
      "Iteration 4244 => Loss: 23.3416862135\n",
      "Iteration 4245 => Loss: 23.3411558408\n",
      "Iteration 4246 => Loss: 23.3406260319\n",
      "Iteration 4247 => Loss: 23.3400967861\n",
      "Iteration 4248 => Loss: 23.3395681029\n",
      "Iteration 4249 => Loss: 23.3390399818\n",
      "Iteration 4250 => Loss: 23.3385124219\n",
      "Iteration 4251 => Loss: 23.3379854229\n",
      "Iteration 4252 => Loss: 23.3374589841\n",
      "Iteration 4253 => Loss: 23.3369331048\n",
      "Iteration 4254 => Loss: 23.3364077846\n",
      "Iteration 4255 => Loss: 23.3358830228\n",
      "Iteration 4256 => Loss: 23.3353588187\n",
      "Iteration 4257 => Loss: 23.3348351719\n",
      "Iteration 4258 => Loss: 23.3343120817\n",
      "Iteration 4259 => Loss: 23.3337895476\n",
      "Iteration 4260 => Loss: 23.3332675689\n",
      "Iteration 4261 => Loss: 23.3327461450\n",
      "Iteration 4262 => Loss: 23.3322252754\n",
      "Iteration 4263 => Loss: 23.3317049595\n",
      "Iteration 4264 => Loss: 23.3311851967\n",
      "Iteration 4265 => Loss: 23.3306659863\n",
      "Iteration 4266 => Loss: 23.3301473279\n",
      "Iteration 4267 => Loss: 23.3296292208\n",
      "Iteration 4268 => Loss: 23.3291116644\n",
      "Iteration 4269 => Loss: 23.3285946582\n",
      "Iteration 4270 => Loss: 23.3280782016\n",
      "Iteration 4271 => Loss: 23.3275622939\n",
      "Iteration 4272 => Loss: 23.3270469346\n",
      "Iteration 4273 => Loss: 23.3265321232\n",
      "Iteration 4274 => Loss: 23.3260178589\n",
      "Iteration 4275 => Loss: 23.3255041414\n",
      "Iteration 4276 => Loss: 23.3249909699\n",
      "Iteration 4277 => Loss: 23.3244783439\n",
      "Iteration 4278 => Loss: 23.3239662628\n",
      "Iteration 4279 => Loss: 23.3234547260\n",
      "Iteration 4280 => Loss: 23.3229437330\n",
      "Iteration 4281 => Loss: 23.3224332832\n",
      "Iteration 4282 => Loss: 23.3219233759\n",
      "Iteration 4283 => Loss: 23.3214140107\n",
      "Iteration 4284 => Loss: 23.3209051869\n",
      "Iteration 4285 => Loss: 23.3203969040\n",
      "Iteration 4286 => Loss: 23.3198891614\n",
      "Iteration 4287 => Loss: 23.3193819585\n",
      "Iteration 4288 => Loss: 23.3188752948\n",
      "Iteration 4289 => Loss: 23.3183691696\n",
      "Iteration 4290 => Loss: 23.3178635824\n",
      "Iteration 4291 => Loss: 23.3173585327\n",
      "Iteration 4292 => Loss: 23.3168540198\n",
      "Iteration 4293 => Loss: 23.3163500432\n",
      "Iteration 4294 => Loss: 23.3158466023\n",
      "Iteration 4295 => Loss: 23.3153436965\n",
      "Iteration 4296 => Loss: 23.3148413254\n",
      "Iteration 4297 => Loss: 23.3143394882\n",
      "Iteration 4298 => Loss: 23.3138381845\n",
      "Iteration 4299 => Loss: 23.3133374137\n",
      "Iteration 4300 => Loss: 23.3128371752\n",
      "Iteration 4301 => Loss: 23.3123374684\n",
      "Iteration 4302 => Loss: 23.3118382928\n",
      "Iteration 4303 => Loss: 23.3113396478\n",
      "Iteration 4304 => Loss: 23.3108415328\n",
      "Iteration 4305 => Loss: 23.3103439474\n",
      "Iteration 4306 => Loss: 23.3098468909\n",
      "Iteration 4307 => Loss: 23.3093503627\n",
      "Iteration 4308 => Loss: 23.3088543623\n",
      "Iteration 4309 => Loss: 23.3083588892\n",
      "Iteration 4310 => Loss: 23.3078639427\n",
      "Iteration 4311 => Loss: 23.3073695224\n",
      "Iteration 4312 => Loss: 23.3068756276\n",
      "Iteration 4313 => Loss: 23.3063822578\n",
      "Iteration 4314 => Loss: 23.3058894125\n",
      "Iteration 4315 => Loss: 23.3053970910\n",
      "Iteration 4316 => Loss: 23.3049052929\n",
      "Iteration 4317 => Loss: 23.3044140175\n",
      "Iteration 4318 => Loss: 23.3039232644\n",
      "Iteration 4319 => Loss: 23.3034330329\n",
      "Iteration 4320 => Loss: 23.3029433225\n",
      "Iteration 4321 => Loss: 23.3024541327\n",
      "Iteration 4322 => Loss: 23.3019654629\n",
      "Iteration 4323 => Loss: 23.3014773125\n",
      "Iteration 4324 => Loss: 23.3009896810\n",
      "Iteration 4325 => Loss: 23.3005025678\n",
      "Iteration 4326 => Loss: 23.3000159725\n",
      "Iteration 4327 => Loss: 23.2995298944\n",
      "Iteration 4328 => Loss: 23.2990443329\n",
      "Iteration 4329 => Loss: 23.2985592877\n",
      "Iteration 4330 => Loss: 23.2980747580\n",
      "Iteration 4331 => Loss: 23.2975907433\n",
      "Iteration 4332 => Loss: 23.2971072432\n",
      "Iteration 4333 => Loss: 23.2966242570\n",
      "Iteration 4334 => Loss: 23.2961417842\n",
      "Iteration 4335 => Loss: 23.2956598242\n",
      "Iteration 4336 => Loss: 23.2951783766\n",
      "Iteration 4337 => Loss: 23.2946974408\n",
      "Iteration 4338 => Loss: 23.2942170161\n",
      "Iteration 4339 => Loss: 23.2937371022\n",
      "Iteration 4340 => Loss: 23.2932576984\n",
      "Iteration 4341 => Loss: 23.2927788042\n",
      "Iteration 4342 => Loss: 23.2923004190\n",
      "Iteration 4343 => Loss: 23.2918225424\n",
      "Iteration 4344 => Loss: 23.2913451737\n",
      "Iteration 4345 => Loss: 23.2908683124\n",
      "Iteration 4346 => Loss: 23.2903919581\n",
      "Iteration 4347 => Loss: 23.2899161101\n",
      "Iteration 4348 => Loss: 23.2894407679\n",
      "Iteration 4349 => Loss: 23.2889659310\n",
      "Iteration 4350 => Loss: 23.2884915989\n",
      "Iteration 4351 => Loss: 23.2880177709\n",
      "Iteration 4352 => Loss: 23.2875444466\n",
      "Iteration 4353 => Loss: 23.2870716255\n",
      "Iteration 4354 => Loss: 23.2865993069\n",
      "Iteration 4355 => Loss: 23.2861274904\n",
      "Iteration 4356 => Loss: 23.2856561755\n",
      "Iteration 4357 => Loss: 23.2851853615\n",
      "Iteration 4358 => Loss: 23.2847150480\n",
      "Iteration 4359 => Loss: 23.2842452345\n",
      "Iteration 4360 => Loss: 23.2837759203\n",
      "Iteration 4361 => Loss: 23.2833071050\n",
      "Iteration 4362 => Loss: 23.2828387881\n",
      "Iteration 4363 => Loss: 23.2823709690\n",
      "Iteration 4364 => Loss: 23.2819036471\n",
      "Iteration 4365 => Loss: 23.2814368220\n",
      "Iteration 4366 => Loss: 23.2809704931\n",
      "Iteration 4367 => Loss: 23.2805046600\n",
      "Iteration 4368 => Loss: 23.2800393220\n",
      "Iteration 4369 => Loss: 23.2795744786\n",
      "Iteration 4370 => Loss: 23.2791101294\n",
      "Iteration 4371 => Loss: 23.2786462737\n",
      "Iteration 4372 => Loss: 23.2781829111\n",
      "Iteration 4373 => Loss: 23.2777200411\n",
      "Iteration 4374 => Loss: 23.2772576631\n",
      "Iteration 4375 => Loss: 23.2767957766\n",
      "Iteration 4376 => Loss: 23.2763343810\n",
      "Iteration 4377 => Loss: 23.2758734759\n",
      "Iteration 4378 => Loss: 23.2754130608\n",
      "Iteration 4379 => Loss: 23.2749531350\n",
      "Iteration 4380 => Loss: 23.2744936982\n",
      "Iteration 4381 => Loss: 23.2740347497\n",
      "Iteration 4382 => Loss: 23.2735762891\n",
      "Iteration 4383 => Loss: 23.2731183158\n",
      "Iteration 4384 => Loss: 23.2726608293\n",
      "Iteration 4385 => Loss: 23.2722038291\n",
      "Iteration 4386 => Loss: 23.2717473147\n",
      "Iteration 4387 => Loss: 23.2712912856\n",
      "Iteration 4388 => Loss: 23.2708357412\n",
      "Iteration 4389 => Loss: 23.2703806811\n",
      "Iteration 4390 => Loss: 23.2699261046\n",
      "Iteration 4391 => Loss: 23.2694720114\n",
      "Iteration 4392 => Loss: 23.2690184009\n",
      "Iteration 4393 => Loss: 23.2685652725\n",
      "Iteration 4394 => Loss: 23.2681126258\n",
      "Iteration 4395 => Loss: 23.2676604603\n",
      "Iteration 4396 => Loss: 23.2672087754\n",
      "Iteration 4397 => Loss: 23.2667575706\n",
      "Iteration 4398 => Loss: 23.2663068455\n",
      "Iteration 4399 => Loss: 23.2658565995\n",
      "Iteration 4400 => Loss: 23.2654068320\n",
      "Iteration 4401 => Loss: 23.2649575427\n",
      "Iteration 4402 => Loss: 23.2645087310\n",
      "Iteration 4403 => Loss: 23.2640603963\n",
      "Iteration 4404 => Loss: 23.2636125382\n",
      "Iteration 4405 => Loss: 23.2631651561\n",
      "Iteration 4406 => Loss: 23.2627182497\n",
      "Iteration 4407 => Loss: 23.2622718182\n",
      "Iteration 4408 => Loss: 23.2618258613\n",
      "Iteration 4409 => Loss: 23.2613803785\n",
      "Iteration 4410 => Loss: 23.2609353692\n",
      "Iteration 4411 => Loss: 23.2604908329\n",
      "Iteration 4412 => Loss: 23.2600467692\n",
      "Iteration 4413 => Loss: 23.2596031775\n",
      "Iteration 4414 => Loss: 23.2591600573\n",
      "Iteration 4415 => Loss: 23.2587174082\n",
      "Iteration 4416 => Loss: 23.2582752296\n",
      "Iteration 4417 => Loss: 23.2578335210\n",
      "Iteration 4418 => Loss: 23.2573922819\n",
      "Iteration 4419 => Loss: 23.2569515119\n",
      "Iteration 4420 => Loss: 23.2565112104\n",
      "Iteration 4421 => Loss: 23.2560713769\n",
      "Iteration 4422 => Loss: 23.2556320109\n",
      "Iteration 4423 => Loss: 23.2551931120\n",
      "Iteration 4424 => Loss: 23.2547546797\n",
      "Iteration 4425 => Loss: 23.2543167133\n",
      "Iteration 4426 => Loss: 23.2538792126\n",
      "Iteration 4427 => Loss: 23.2534421769\n",
      "Iteration 4428 => Loss: 23.2530056057\n",
      "Iteration 4429 => Loss: 23.2525694986\n",
      "Iteration 4430 => Loss: 23.2521338551\n",
      "Iteration 4431 => Loss: 23.2516986746\n",
      "Iteration 4432 => Loss: 23.2512639568\n",
      "Iteration 4433 => Loss: 23.2508297010\n",
      "Iteration 4434 => Loss: 23.2503959069\n",
      "Iteration 4435 => Loss: 23.2499625738\n",
      "Iteration 4436 => Loss: 23.2495297014\n",
      "Iteration 4437 => Loss: 23.2490972891\n",
      "Iteration 4438 => Loss: 23.2486653365\n",
      "Iteration 4439 => Loss: 23.2482338430\n",
      "Iteration 4440 => Loss: 23.2478028082\n",
      "Iteration 4441 => Loss: 23.2473722316\n",
      "Iteration 4442 => Loss: 23.2469421126\n",
      "Iteration 4443 => Loss: 23.2465124509\n",
      "Iteration 4444 => Loss: 23.2460832459\n",
      "Iteration 4445 => Loss: 23.2456544971\n",
      "Iteration 4446 => Loss: 23.2452262041\n",
      "Iteration 4447 => Loss: 23.2447983663\n",
      "Iteration 4448 => Loss: 23.2443709834\n",
      "Iteration 4449 => Loss: 23.2439440547\n",
      "Iteration 4450 => Loss: 23.2435175798\n",
      "Iteration 4451 => Loss: 23.2430915583\n",
      "Iteration 4452 => Loss: 23.2426659896\n",
      "Iteration 4453 => Loss: 23.2422408733\n",
      "Iteration 4454 => Loss: 23.2418162089\n",
      "Iteration 4455 => Loss: 23.2413919959\n",
      "Iteration 4456 => Loss: 23.2409682338\n",
      "Iteration 4457 => Loss: 23.2405449222\n",
      "Iteration 4458 => Loss: 23.2401220606\n",
      "Iteration 4459 => Loss: 23.2396996484\n",
      "Iteration 4460 => Loss: 23.2392776853\n",
      "Iteration 4461 => Loss: 23.2388561707\n",
      "Iteration 4462 => Loss: 23.2384351041\n",
      "Iteration 4463 => Loss: 23.2380144851\n",
      "Iteration 4464 => Loss: 23.2375943133\n",
      "Iteration 4465 => Loss: 23.2371745881\n",
      "Iteration 4466 => Loss: 23.2367553090\n",
      "Iteration 4467 => Loss: 23.2363364756\n",
      "Iteration 4468 => Loss: 23.2359180875\n",
      "Iteration 4469 => Loss: 23.2355001441\n",
      "Iteration 4470 => Loss: 23.2350826449\n",
      "Iteration 4471 => Loss: 23.2346655895\n",
      "Iteration 4472 => Loss: 23.2342489775\n",
      "Iteration 4473 => Loss: 23.2338328083\n",
      "Iteration 4474 => Loss: 23.2334170815\n",
      "Iteration 4475 => Loss: 23.2330017966\n",
      "Iteration 4476 => Loss: 23.2325869531\n",
      "Iteration 4477 => Loss: 23.2321725506\n",
      "Iteration 4478 => Loss: 23.2317585886\n",
      "Iteration 4479 => Loss: 23.2313450666\n",
      "Iteration 4480 => Loss: 23.2309319842\n",
      "Iteration 4481 => Loss: 23.2305193409\n",
      "Iteration 4482 => Loss: 23.2301071362\n",
      "Iteration 4483 => Loss: 23.2296953697\n",
      "Iteration 4484 => Loss: 23.2292840409\n",
      "Iteration 4485 => Loss: 23.2288731493\n",
      "Iteration 4486 => Loss: 23.2284626945\n",
      "Iteration 4487 => Loss: 23.2280526760\n",
      "Iteration 4488 => Loss: 23.2276430934\n",
      "Iteration 4489 => Loss: 23.2272339461\n",
      "Iteration 4490 => Loss: 23.2268252337\n",
      "Iteration 4491 => Loss: 23.2264169558\n",
      "Iteration 4492 => Loss: 23.2260091119\n",
      "Iteration 4493 => Loss: 23.2256017015\n",
      "Iteration 4494 => Loss: 23.2251947242\n",
      "Iteration 4495 => Loss: 23.2247881794\n",
      "Iteration 4496 => Loss: 23.2243820669\n",
      "Iteration 4497 => Loss: 23.2239763860\n",
      "Iteration 4498 => Loss: 23.2235711363\n",
      "Iteration 4499 => Loss: 23.2231663175\n",
      "Iteration 4500 => Loss: 23.2227619289\n",
      "Iteration 4501 => Loss: 23.2223579702\n",
      "Iteration 4502 => Loss: 23.2219544409\n",
      "Iteration 4503 => Loss: 23.2215513405\n",
      "Iteration 4504 => Loss: 23.2211486686\n",
      "Iteration 4505 => Loss: 23.2207464248\n",
      "Iteration 4506 => Loss: 23.2203446085\n",
      "Iteration 4507 => Loss: 23.2199432194\n",
      "Iteration 4508 => Loss: 23.2195422569\n",
      "Iteration 4509 => Loss: 23.2191417206\n",
      "Iteration 4510 => Loss: 23.2187416101\n",
      "Iteration 4511 => Loss: 23.2183419249\n",
      "Iteration 4512 => Loss: 23.2179426646\n",
      "Iteration 4513 => Loss: 23.2175438287\n",
      "Iteration 4514 => Loss: 23.2171454167\n",
      "Iteration 4515 => Loss: 23.2167474282\n",
      "Iteration 4516 => Loss: 23.2163498628\n",
      "Iteration 4517 => Loss: 23.2159527200\n",
      "Iteration 4518 => Loss: 23.2155559993\n",
      "Iteration 4519 => Loss: 23.2151597003\n",
      "Iteration 4520 => Loss: 23.2147638226\n",
      "Iteration 4521 => Loss: 23.2143683658\n",
      "Iteration 4522 => Loss: 23.2139733292\n",
      "Iteration 4523 => Loss: 23.2135787126\n",
      "Iteration 4524 => Loss: 23.2131845155\n",
      "Iteration 4525 => Loss: 23.2127907373\n",
      "Iteration 4526 => Loss: 23.2123973778\n",
      "Iteration 4527 => Loss: 23.2120044364\n",
      "Iteration 4528 => Loss: 23.2116119127\n",
      "Iteration 4529 => Loss: 23.2112198062\n",
      "Iteration 4530 => Loss: 23.2108281165\n",
      "Iteration 4531 => Loss: 23.2104368432\n",
      "Iteration 4532 => Loss: 23.2100459858\n",
      "Iteration 4533 => Loss: 23.2096555439\n",
      "Iteration 4534 => Loss: 23.2092655170\n",
      "Iteration 4535 => Loss: 23.2088759046\n",
      "Iteration 4536 => Loss: 23.2084867065\n",
      "Iteration 4537 => Loss: 23.2080979220\n",
      "Iteration 4538 => Loss: 23.2077095509\n",
      "Iteration 4539 => Loss: 23.2073215925\n",
      "Iteration 4540 => Loss: 23.2069340465\n",
      "Iteration 4541 => Loss: 23.2065469125\n",
      "Iteration 4542 => Loss: 23.2061601900\n",
      "Iteration 4543 => Loss: 23.2057738786\n",
      "Iteration 4544 => Loss: 23.2053879779\n",
      "Iteration 4545 => Loss: 23.2050024873\n",
      "Iteration 4546 => Loss: 23.2046174065\n",
      "Iteration 4547 => Loss: 23.2042327350\n",
      "Iteration 4548 => Loss: 23.2038484725\n",
      "Iteration 4549 => Loss: 23.2034646184\n",
      "Iteration 4550 => Loss: 23.2030811723\n",
      "Iteration 4551 => Loss: 23.2026981338\n",
      "Iteration 4552 => Loss: 23.2023155025\n",
      "Iteration 4553 => Loss: 23.2019332779\n",
      "Iteration 4554 => Loss: 23.2015514596\n",
      "Iteration 4555 => Loss: 23.2011700472\n",
      "Iteration 4556 => Loss: 23.2007890402\n",
      "Iteration 4557 => Loss: 23.2004084382\n",
      "Iteration 4558 => Loss: 23.2000282407\n",
      "Iteration 4559 => Loss: 23.1996484475\n",
      "Iteration 4560 => Loss: 23.1992690579\n",
      "Iteration 4561 => Loss: 23.1988900716\n",
      "Iteration 4562 => Loss: 23.1985114882\n",
      "Iteration 4563 => Loss: 23.1981333072\n",
      "Iteration 4564 => Loss: 23.1977555282\n",
      "Iteration 4565 => Loss: 23.1973781507\n",
      "Iteration 4566 => Loss: 23.1970011744\n",
      "Iteration 4567 => Loss: 23.1966245989\n",
      "Iteration 4568 => Loss: 23.1962484236\n",
      "Iteration 4569 => Loss: 23.1958726482\n",
      "Iteration 4570 => Loss: 23.1954972722\n",
      "Iteration 4571 => Loss: 23.1951222952\n",
      "Iteration 4572 => Loss: 23.1947477169\n",
      "Iteration 4573 => Loss: 23.1943735367\n",
      "Iteration 4574 => Loss: 23.1939997542\n",
      "Iteration 4575 => Loss: 23.1936263691\n",
      "Iteration 4576 => Loss: 23.1932533809\n",
      "Iteration 4577 => Loss: 23.1928807891\n",
      "Iteration 4578 => Loss: 23.1925085934\n",
      "Iteration 4579 => Loss: 23.1921367934\n",
      "Iteration 4580 => Loss: 23.1917653885\n",
      "Iteration 4581 => Loss: 23.1913943785\n",
      "Iteration 4582 => Loss: 23.1910237628\n",
      "Iteration 4583 => Loss: 23.1906535411\n",
      "Iteration 4584 => Loss: 23.1902837129\n",
      "Iteration 4585 => Loss: 23.1899142779\n",
      "Iteration 4586 => Loss: 23.1895452355\n",
      "Iteration 4587 => Loss: 23.1891765855\n",
      "Iteration 4588 => Loss: 23.1888083273\n",
      "Iteration 4589 => Loss: 23.1884404605\n",
      "Iteration 4590 => Loss: 23.1880729848\n",
      "Iteration 4591 => Loss: 23.1877058997\n",
      "Iteration 4592 => Loss: 23.1873392048\n",
      "Iteration 4593 => Loss: 23.1869728997\n",
      "Iteration 4594 => Loss: 23.1866069840\n",
      "Iteration 4595 => Loss: 23.1862414572\n",
      "Iteration 4596 => Loss: 23.1858763190\n",
      "Iteration 4597 => Loss: 23.1855115689\n",
      "Iteration 4598 => Loss: 23.1851472065\n",
      "Iteration 4599 => Loss: 23.1847832315\n",
      "Iteration 4600 => Loss: 23.1844196433\n",
      "Iteration 4601 => Loss: 23.1840564416\n",
      "Iteration 4602 => Loss: 23.1836936260\n",
      "Iteration 4603 => Loss: 23.1833311961\n",
      "Iteration 4604 => Loss: 23.1829691514\n",
      "Iteration 4605 => Loss: 23.1826074916\n",
      "Iteration 4606 => Loss: 23.1822462162\n",
      "Iteration 4607 => Loss: 23.1818853248\n",
      "Iteration 4608 => Loss: 23.1815248171\n",
      "Iteration 4609 => Loss: 23.1811646925\n",
      "Iteration 4610 => Loss: 23.1808049508\n",
      "Iteration 4611 => Loss: 23.1804455915\n",
      "Iteration 4612 => Loss: 23.1800866141\n",
      "Iteration 4613 => Loss: 23.1797280184\n",
      "Iteration 4614 => Loss: 23.1793698038\n",
      "Iteration 4615 => Loss: 23.1790119700\n",
      "Iteration 4616 => Loss: 23.1786545166\n",
      "Iteration 4617 => Loss: 23.1782974431\n",
      "Iteration 4618 => Loss: 23.1779407492\n",
      "Iteration 4619 => Loss: 23.1775844345\n",
      "Iteration 4620 => Loss: 23.1772284985\n",
      "Iteration 4621 => Loss: 23.1768729408\n",
      "Iteration 4622 => Loss: 23.1765177611\n",
      "Iteration 4623 => Loss: 23.1761629590\n",
      "Iteration 4624 => Loss: 23.1758085340\n",
      "Iteration 4625 => Loss: 23.1754544858\n",
      "Iteration 4626 => Loss: 23.1751008139\n",
      "Iteration 4627 => Loss: 23.1747475179\n",
      "Iteration 4628 => Loss: 23.1743945975\n",
      "Iteration 4629 => Loss: 23.1740420522\n",
      "Iteration 4630 => Loss: 23.1736898817\n",
      "Iteration 4631 => Loss: 23.1733380855\n",
      "Iteration 4632 => Loss: 23.1729866633\n",
      "Iteration 4633 => Loss: 23.1726356147\n",
      "Iteration 4634 => Loss: 23.1722849392\n",
      "Iteration 4635 => Loss: 23.1719346364\n",
      "Iteration 4636 => Loss: 23.1715847061\n",
      "Iteration 4637 => Loss: 23.1712351476\n",
      "Iteration 4638 => Loss: 23.1708859608\n",
      "Iteration 4639 => Loss: 23.1705371452\n",
      "Iteration 4640 => Loss: 23.1701887003\n",
      "Iteration 4641 => Loss: 23.1698406258\n",
      "Iteration 4642 => Loss: 23.1694929213\n",
      "Iteration 4643 => Loss: 23.1691455864\n",
      "Iteration 4644 => Loss: 23.1687986208\n",
      "Iteration 4645 => Loss: 23.1684520239\n",
      "Iteration 4646 => Loss: 23.1681057955\n",
      "Iteration 4647 => Loss: 23.1677599351\n",
      "Iteration 4648 => Loss: 23.1674144423\n",
      "Iteration 4649 => Loss: 23.1670693168\n",
      "Iteration 4650 => Loss: 23.1667245582\n",
      "Iteration 4651 => Loss: 23.1663801660\n",
      "Iteration 4652 => Loss: 23.1660361399\n",
      "Iteration 4653 => Loss: 23.1656924795\n",
      "Iteration 4654 => Loss: 23.1653491844\n",
      "Iteration 4655 => Loss: 23.1650062542\n",
      "Iteration 4656 => Loss: 23.1646636886\n",
      "Iteration 4657 => Loss: 23.1643214870\n",
      "Iteration 4658 => Loss: 23.1639796493\n",
      "Iteration 4659 => Loss: 23.1636381749\n",
      "Iteration 4660 => Loss: 23.1632970635\n",
      "Iteration 4661 => Loss: 23.1629563147\n",
      "Iteration 4662 => Loss: 23.1626159280\n",
      "Iteration 4663 => Loss: 23.1622759033\n",
      "Iteration 4664 => Loss: 23.1619362399\n",
      "Iteration 4665 => Loss: 23.1615969376\n",
      "Iteration 4666 => Loss: 23.1612579960\n",
      "Iteration 4667 => Loss: 23.1609194147\n",
      "Iteration 4668 => Loss: 23.1605811932\n",
      "Iteration 4669 => Loss: 23.1602433313\n",
      "Iteration 4670 => Loss: 23.1599058286\n",
      "Iteration 4671 => Loss: 23.1595686845\n",
      "Iteration 4672 => Loss: 23.1592318989\n",
      "Iteration 4673 => Loss: 23.1588954713\n",
      "Iteration 4674 => Loss: 23.1585594013\n",
      "Iteration 4675 => Loss: 23.1582236885\n",
      "Iteration 4676 => Loss: 23.1578883325\n",
      "Iteration 4677 => Loss: 23.1575533331\n",
      "Iteration 4678 => Loss: 23.1572186897\n",
      "Iteration 4679 => Loss: 23.1568844021\n",
      "Iteration 4680 => Loss: 23.1565504698\n",
      "Iteration 4681 => Loss: 23.1562168925\n",
      "Iteration 4682 => Loss: 23.1558836697\n",
      "Iteration 4683 => Loss: 23.1555508012\n",
      "Iteration 4684 => Loss: 23.1552182865\n",
      "Iteration 4685 => Loss: 23.1548861252\n",
      "Iteration 4686 => Loss: 23.1545543170\n",
      "Iteration 4687 => Loss: 23.1542228616\n",
      "Iteration 4688 => Loss: 23.1538917584\n",
      "Iteration 4689 => Loss: 23.1535610073\n",
      "Iteration 4690 => Loss: 23.1532306077\n",
      "Iteration 4691 => Loss: 23.1529005593\n",
      "Iteration 4692 => Loss: 23.1525708617\n",
      "Iteration 4693 => Loss: 23.1522415146\n",
      "Iteration 4694 => Loss: 23.1519125176\n",
      "Iteration 4695 => Loss: 23.1515838703\n",
      "Iteration 4696 => Loss: 23.1512555724\n",
      "Iteration 4697 => Loss: 23.1509276234\n",
      "Iteration 4698 => Loss: 23.1506000230\n",
      "Iteration 4699 => Loss: 23.1502727709\n",
      "Iteration 4700 => Loss: 23.1499458666\n",
      "Iteration 4701 => Loss: 23.1496193099\n",
      "Iteration 4702 => Loss: 23.1492931002\n",
      "Iteration 4703 => Loss: 23.1489672373\n",
      "Iteration 4704 => Loss: 23.1486417208\n",
      "Iteration 4705 => Loss: 23.1483165503\n",
      "Iteration 4706 => Loss: 23.1479917254\n",
      "Iteration 4707 => Loss: 23.1476672459\n",
      "Iteration 4708 => Loss: 23.1473431112\n",
      "Iteration 4709 => Loss: 23.1470193211\n",
      "Iteration 4710 => Loss: 23.1466958752\n",
      "Iteration 4711 => Loss: 23.1463727731\n",
      "Iteration 4712 => Loss: 23.1460500144\n",
      "Iteration 4713 => Loss: 23.1457275988\n",
      "Iteration 4714 => Loss: 23.1454055260\n",
      "Iteration 4715 => Loss: 23.1450837955\n",
      "Iteration 4716 => Loss: 23.1447624070\n",
      "Iteration 4717 => Loss: 23.1444413601\n",
      "Iteration 4718 => Loss: 23.1441206545\n",
      "Iteration 4719 => Loss: 23.1438002898\n",
      "Iteration 4720 => Loss: 23.1434802656\n",
      "Iteration 4721 => Loss: 23.1431605816\n",
      "Iteration 4722 => Loss: 23.1428412375\n",
      "Iteration 4723 => Loss: 23.1425222328\n",
      "Iteration 4724 => Loss: 23.1422035671\n",
      "Iteration 4725 => Loss: 23.1418852403\n",
      "Iteration 4726 => Loss: 23.1415672518\n",
      "Iteration 4727 => Loss: 23.1412496013\n",
      "Iteration 4728 => Loss: 23.1409322884\n",
      "Iteration 4729 => Loss: 23.1406153129\n",
      "Iteration 4730 => Loss: 23.1402986743\n",
      "Iteration 4731 => Loss: 23.1399823723\n",
      "Iteration 4732 => Loss: 23.1396664065\n",
      "Iteration 4733 => Loss: 23.1393507765\n",
      "Iteration 4734 => Loss: 23.1390354821\n",
      "Iteration 4735 => Loss: 23.1387205228\n",
      "Iteration 4736 => Loss: 23.1384058984\n",
      "Iteration 4737 => Loss: 23.1380916083\n",
      "Iteration 4738 => Loss: 23.1377776524\n",
      "Iteration 4739 => Loss: 23.1374640301\n",
      "Iteration 4740 => Loss: 23.1371507413\n",
      "Iteration 4741 => Loss: 23.1368377854\n",
      "Iteration 4742 => Loss: 23.1365251623\n",
      "Iteration 4743 => Loss: 23.1362128714\n",
      "Iteration 4744 => Loss: 23.1359009125\n",
      "Iteration 4745 => Loss: 23.1355892852\n",
      "Iteration 4746 => Loss: 23.1352779892\n",
      "Iteration 4747 => Loss: 23.1349670241\n",
      "Iteration 4748 => Loss: 23.1346563895\n",
      "Iteration 4749 => Loss: 23.1343460851\n",
      "Iteration 4750 => Loss: 23.1340361105\n",
      "Iteration 4751 => Loss: 23.1337264655\n",
      "Iteration 4752 => Loss: 23.1334171496\n",
      "Iteration 4753 => Loss: 23.1331081625\n",
      "Iteration 4754 => Loss: 23.1327995038\n",
      "Iteration 4755 => Loss: 23.1324911732\n",
      "Iteration 4756 => Loss: 23.1321831704\n",
      "Iteration 4757 => Loss: 23.1318754950\n",
      "Iteration 4758 => Loss: 23.1315681467\n",
      "Iteration 4759 => Loss: 23.1312611250\n",
      "Iteration 4760 => Loss: 23.1309544297\n",
      "Iteration 4761 => Loss: 23.1306480604\n",
      "Iteration 4762 => Loss: 23.1303420168\n",
      "Iteration 4763 => Loss: 23.1300362985\n",
      "Iteration 4764 => Loss: 23.1297309052\n",
      "Iteration 4765 => Loss: 23.1294258365\n",
      "Iteration 4766 => Loss: 23.1291210920\n",
      "Iteration 4767 => Loss: 23.1288166715\n",
      "Iteration 4768 => Loss: 23.1285125746\n",
      "Iteration 4769 => Loss: 23.1282088010\n",
      "Iteration 4770 => Loss: 23.1279053503\n",
      "Iteration 4771 => Loss: 23.1276022221\n",
      "Iteration 4772 => Loss: 23.1272994161\n",
      "Iteration 4773 => Loss: 23.1269969320\n",
      "Iteration 4774 => Loss: 23.1266947695\n",
      "Iteration 4775 => Loss: 23.1263929281\n",
      "Iteration 4776 => Loss: 23.1260914076\n",
      "Iteration 4777 => Loss: 23.1257902076\n",
      "Iteration 4778 => Loss: 23.1254893278\n",
      "Iteration 4779 => Loss: 23.1251887678\n",
      "Iteration 4780 => Loss: 23.1248885273\n",
      "Iteration 4781 => Loss: 23.1245886059\n",
      "Iteration 4782 => Loss: 23.1242890034\n",
      "Iteration 4783 => Loss: 23.1239897193\n",
      "Iteration 4784 => Loss: 23.1236907533\n",
      "Iteration 4785 => Loss: 23.1233921052\n",
      "Iteration 4786 => Loss: 23.1230937745\n",
      "Iteration 4787 => Loss: 23.1227957609\n",
      "Iteration 4788 => Loss: 23.1224980641\n",
      "Iteration 4789 => Loss: 23.1222006838\n",
      "Iteration 4790 => Loss: 23.1219036195\n",
      "Iteration 4791 => Loss: 23.1216068711\n",
      "Iteration 4792 => Loss: 23.1213104380\n",
      "Iteration 4793 => Loss: 23.1210143201\n",
      "Iteration 4794 => Loss: 23.1207185169\n",
      "Iteration 4795 => Loss: 23.1204230282\n",
      "Iteration 4796 => Loss: 23.1201278536\n",
      "Iteration 4797 => Loss: 23.1198329927\n",
      "Iteration 4798 => Loss: 23.1195384453\n",
      "Iteration 4799 => Loss: 23.1192442109\n",
      "Iteration 4800 => Loss: 23.1189502894\n",
      "Iteration 4801 => Loss: 23.1186566802\n",
      "Iteration 4802 => Loss: 23.1183633832\n",
      "Iteration 4803 => Loss: 23.1180703979\n",
      "Iteration 4804 => Loss: 23.1177777241\n",
      "Iteration 4805 => Loss: 23.1174853613\n",
      "Iteration 4806 => Loss: 23.1171933094\n",
      "Iteration 4807 => Loss: 23.1169015679\n",
      "Iteration 4808 => Loss: 23.1166101365\n",
      "Iteration 4809 => Loss: 23.1163190149\n",
      "Iteration 4810 => Loss: 23.1160282027\n",
      "Iteration 4811 => Loss: 23.1157376997\n",
      "Iteration 4812 => Loss: 23.1154475055\n",
      "Iteration 4813 => Loss: 23.1151576197\n",
      "Iteration 4814 => Loss: 23.1148680421\n",
      "Iteration 4815 => Loss: 23.1145787723\n",
      "Iteration 4816 => Loss: 23.1142898100\n",
      "Iteration 4817 => Loss: 23.1140011548\n",
      "Iteration 4818 => Loss: 23.1137128065\n",
      "Iteration 4819 => Loss: 23.1134247647\n",
      "Iteration 4820 => Loss: 23.1131370291\n",
      "Iteration 4821 => Loss: 23.1128495993\n",
      "Iteration 4822 => Loss: 23.1125624751\n",
      "Iteration 4823 => Loss: 23.1122756561\n",
      "Iteration 4824 => Loss: 23.1119891419\n",
      "Iteration 4825 => Loss: 23.1117029323\n",
      "Iteration 4826 => Loss: 23.1114170270\n",
      "Iteration 4827 => Loss: 23.1111314255\n",
      "Iteration 4828 => Loss: 23.1108461277\n",
      "Iteration 4829 => Loss: 23.1105611331\n",
      "Iteration 4830 => Loss: 23.1102764414\n",
      "Iteration 4831 => Loss: 23.1099920524\n",
      "Iteration 4832 => Loss: 23.1097079657\n",
      "Iteration 4833 => Loss: 23.1094241809\n",
      "Iteration 4834 => Loss: 23.1091406978\n",
      "Iteration 4835 => Loss: 23.1088575161\n",
      "Iteration 4836 => Loss: 23.1085746354\n",
      "Iteration 4837 => Loss: 23.1082920553\n",
      "Iteration 4838 => Loss: 23.1080097757\n",
      "Iteration 4839 => Loss: 23.1077277960\n",
      "Iteration 4840 => Loss: 23.1074461162\n",
      "Iteration 4841 => Loss: 23.1071647357\n",
      "Iteration 4842 => Loss: 23.1068836544\n",
      "Iteration 4843 => Loss: 23.1066028718\n",
      "Iteration 4844 => Loss: 23.1063223877\n",
      "Iteration 4845 => Loss: 23.1060422018\n",
      "Iteration 4846 => Loss: 23.1057623137\n",
      "Iteration 4847 => Loss: 23.1054827230\n",
      "Iteration 4848 => Loss: 23.1052034296\n",
      "Iteration 4849 => Loss: 23.1049244331\n",
      "Iteration 4850 => Loss: 23.1046457332\n",
      "Iteration 4851 => Loss: 23.1043673295\n",
      "Iteration 4852 => Loss: 23.1040892217\n",
      "Iteration 4853 => Loss: 23.1038114096\n",
      "Iteration 4854 => Loss: 23.1035338927\n",
      "Iteration 4855 => Loss: 23.1032566709\n",
      "Iteration 4856 => Loss: 23.1029797437\n",
      "Iteration 4857 => Loss: 23.1027031109\n",
      "Iteration 4858 => Loss: 23.1024267722\n",
      "Iteration 4859 => Loss: 23.1021507272\n",
      "Iteration 4860 => Loss: 23.1018749757\n",
      "Iteration 4861 => Loss: 23.1015995172\n",
      "Iteration 4862 => Loss: 23.1013243516\n",
      "Iteration 4863 => Loss: 23.1010494784\n",
      "Iteration 4864 => Loss: 23.1007748975\n",
      "Iteration 4865 => Loss: 23.1005006084\n",
      "Iteration 4866 => Loss: 23.1002266109\n",
      "Iteration 4867 => Loss: 23.0999529046\n",
      "Iteration 4868 => Loss: 23.0996794893\n",
      "Iteration 4869 => Loss: 23.0994063646\n",
      "Iteration 4870 => Loss: 23.0991335302\n",
      "Iteration 4871 => Loss: 23.0988609859\n",
      "Iteration 4872 => Loss: 23.0985887312\n",
      "Iteration 4873 => Loss: 23.0983167660\n",
      "Iteration 4874 => Loss: 23.0980450898\n",
      "Iteration 4875 => Loss: 23.0977737025\n",
      "Iteration 4876 => Loss: 23.0975026036\n",
      "Iteration 4877 => Loss: 23.0972317929\n",
      "Iteration 4878 => Loss: 23.0969612701\n",
      "Iteration 4879 => Loss: 23.0966910348\n",
      "Iteration 4880 => Loss: 23.0964210868\n",
      "Iteration 4881 => Loss: 23.0961514257\n",
      "Iteration 4882 => Loss: 23.0958820512\n",
      "Iteration 4883 => Loss: 23.0956129632\n",
      "Iteration 4884 => Loss: 23.0953441611\n",
      "Iteration 4885 => Loss: 23.0950756448\n",
      "Iteration 4886 => Loss: 23.0948074139\n",
      "Iteration 4887 => Loss: 23.0945394681\n",
      "Iteration 4888 => Loss: 23.0942718071\n",
      "Iteration 4889 => Loss: 23.0940044307\n",
      "Iteration 4890 => Loss: 23.0937373385\n",
      "Iteration 4891 => Loss: 23.0934705302\n",
      "Iteration 4892 => Loss: 23.0932040055\n",
      "Iteration 4893 => Loss: 23.0929377641\n",
      "Iteration 4894 => Loss: 23.0926718057\n",
      "Iteration 4895 => Loss: 23.0924061300\n",
      "Iteration 4896 => Loss: 23.0921407368\n",
      "Iteration 4897 => Loss: 23.0918756256\n",
      "Iteration 4898 => Loss: 23.0916107963\n",
      "Iteration 4899 => Loss: 23.0913462484\n",
      "Iteration 4900 => Loss: 23.0910819818\n",
      "Iteration 4901 => Loss: 23.0908179961\n",
      "Iteration 4902 => Loss: 23.0905542910\n",
      "Iteration 4903 => Loss: 23.0902908662\n",
      "Iteration 4904 => Loss: 23.0900277214\n",
      "Iteration 4905 => Loss: 23.0897648563\n",
      "Iteration 4906 => Loss: 23.0895022707\n",
      "Iteration 4907 => Loss: 23.0892399641\n",
      "Iteration 4908 => Loss: 23.0889779364\n",
      "Iteration 4909 => Loss: 23.0887161873\n",
      "Iteration 4910 => Loss: 23.0884547163\n",
      "Iteration 4911 => Loss: 23.0881935233\n",
      "Iteration 4912 => Loss: 23.0879326080\n",
      "Iteration 4913 => Loss: 23.0876719700\n",
      "Iteration 4914 => Loss: 23.0874116090\n",
      "Iteration 4915 => Loss: 23.0871515248\n",
      "Iteration 4916 => Loss: 23.0868917171\n",
      "Iteration 4917 => Loss: 23.0866321856\n",
      "Iteration 4918 => Loss: 23.0863729299\n",
      "Iteration 4919 => Loss: 23.0861139498\n",
      "Iteration 4920 => Loss: 23.0858552450\n",
      "Iteration 4921 => Loss: 23.0855968152\n",
      "Iteration 4922 => Loss: 23.0853386600\n",
      "Iteration 4923 => Loss: 23.0850807794\n",
      "Iteration 4924 => Loss: 23.0848231728\n",
      "Iteration 4925 => Loss: 23.0845658400\n",
      "Iteration 4926 => Loss: 23.0843087808\n",
      "Iteration 4927 => Loss: 23.0840519949\n",
      "Iteration 4928 => Loss: 23.0837954819\n",
      "Iteration 4929 => Loss: 23.0835392416\n",
      "Iteration 4930 => Loss: 23.0832832736\n",
      "Iteration 4931 => Loss: 23.0830275778\n",
      "Iteration 4932 => Loss: 23.0827721537\n",
      "Iteration 4933 => Loss: 23.0825170011\n",
      "Iteration 4934 => Loss: 23.0822621198\n",
      "Iteration 4935 => Loss: 23.0820075094\n",
      "Iteration 4936 => Loss: 23.0817531697\n",
      "Iteration 4937 => Loss: 23.0814991003\n",
      "Iteration 4938 => Loss: 23.0812453010\n",
      "Iteration 4939 => Loss: 23.0809917714\n",
      "Iteration 4940 => Loss: 23.0807385114\n",
      "Iteration 4941 => Loss: 23.0804855205\n",
      "Iteration 4942 => Loss: 23.0802327986\n",
      "Iteration 4943 => Loss: 23.0799803454\n",
      "Iteration 4944 => Loss: 23.0797281604\n",
      "Iteration 4945 => Loss: 23.0794762436\n",
      "Iteration 4946 => Loss: 23.0792245945\n",
      "Iteration 4947 => Loss: 23.0789732130\n",
      "Iteration 4948 => Loss: 23.0787220986\n",
      "Iteration 4949 => Loss: 23.0784712512\n",
      "Iteration 4950 => Loss: 23.0782206704\n",
      "Iteration 4951 => Loss: 23.0779703560\n",
      "Iteration 4952 => Loss: 23.0777203076\n",
      "Iteration 4953 => Loss: 23.0774705251\n",
      "Iteration 4954 => Loss: 23.0772210080\n",
      "Iteration 4955 => Loss: 23.0769717562\n",
      "Iteration 4956 => Loss: 23.0767227694\n",
      "Iteration 4957 => Loss: 23.0764740472\n",
      "Iteration 4958 => Loss: 23.0762255894\n",
      "Iteration 4959 => Loss: 23.0759773957\n",
      "Iteration 4960 => Loss: 23.0757294658\n",
      "Iteration 4961 => Loss: 23.0754817995\n",
      "Iteration 4962 => Loss: 23.0752343965\n",
      "Iteration 4963 => Loss: 23.0749872564\n",
      "Iteration 4964 => Loss: 23.0747403790\n",
      "Iteration 4965 => Loss: 23.0744937641\n",
      "Iteration 4966 => Loss: 23.0742474113\n",
      "Iteration 4967 => Loss: 23.0740013203\n",
      "Iteration 4968 => Loss: 23.0737554910\n",
      "Iteration 4969 => Loss: 23.0735099230\n",
      "Iteration 4970 => Loss: 23.0732646160\n",
      "Iteration 4971 => Loss: 23.0730195697\n",
      "Iteration 4972 => Loss: 23.0727747840\n",
      "Iteration 4973 => Loss: 23.0725302584\n",
      "Iteration 4974 => Loss: 23.0722859928\n",
      "Iteration 4975 => Loss: 23.0720419868\n",
      "Iteration 4976 => Loss: 23.0717982402\n",
      "Iteration 4977 => Loss: 23.0715547527\n",
      "Iteration 4978 => Loss: 23.0713115240\n",
      "Iteration 4979 => Loss: 23.0710685538\n",
      "Iteration 4980 => Loss: 23.0708258420\n",
      "Iteration 4981 => Loss: 23.0705833881\n",
      "Iteration 4982 => Loss: 23.0703411919\n",
      "Iteration 4983 => Loss: 23.0700992532\n",
      "Iteration 4984 => Loss: 23.0698575717\n",
      "Iteration 4985 => Loss: 23.0696161471\n",
      "Iteration 4986 => Loss: 23.0693749791\n",
      "Iteration 4987 => Loss: 23.0691340674\n",
      "Iteration 4988 => Loss: 23.0688934119\n",
      "Iteration 4989 => Loss: 23.0686530121\n",
      "Iteration 4990 => Loss: 23.0684128679\n",
      "Iteration 4991 => Loss: 23.0681729790\n",
      "Iteration 4992 => Loss: 23.0679333451\n",
      "Iteration 4993 => Loss: 23.0676939659\n",
      "Iteration 4994 => Loss: 23.0674548411\n",
      "Iteration 4995 => Loss: 23.0672159705\n",
      "Iteration 4996 => Loss: 23.0669773539\n",
      "Iteration 4997 => Loss: 23.0667389908\n",
      "Iteration 4998 => Loss: 23.0665008812\n",
      "Iteration 4999 => Loss: 23.0662630247\n",
      "Iteration 5000 => Loss: 23.0660254210\n",
      "Iteration 5001 => Loss: 23.0657880698\n",
      "Iteration 5002 => Loss: 23.0655509710\n",
      "Iteration 5003 => Loss: 23.0653141242\n",
      "Iteration 5004 => Loss: 23.0650775292\n",
      "Iteration 5005 => Loss: 23.0648411856\n",
      "Iteration 5006 => Loss: 23.0646050933\n",
      "Iteration 5007 => Loss: 23.0643692520\n",
      "Iteration 5008 => Loss: 23.0641336613\n",
      "Iteration 5009 => Loss: 23.0638983211\n",
      "Iteration 5010 => Loss: 23.0636632310\n",
      "Iteration 5011 => Loss: 23.0634283908\n",
      "Iteration 5012 => Loss: 23.0631938003\n",
      "Iteration 5013 => Loss: 23.0629594591\n",
      "Iteration 5014 => Loss: 23.0627253671\n",
      "Iteration 5015 => Loss: 23.0624915238\n",
      "Iteration 5016 => Loss: 23.0622579291\n",
      "Iteration 5017 => Loss: 23.0620245828\n",
      "Iteration 5018 => Loss: 23.0617914844\n",
      "Iteration 5019 => Loss: 23.0615586339\n",
      "Iteration 5020 => Loss: 23.0613260309\n",
      "Iteration 5021 => Loss: 23.0610936751\n",
      "Iteration 5022 => Loss: 23.0608615663\n",
      "Iteration 5023 => Loss: 23.0606297042\n",
      "Iteration 5024 => Loss: 23.0603980886\n",
      "Iteration 5025 => Loss: 23.0601667192\n",
      "Iteration 5026 => Loss: 23.0599355958\n",
      "Iteration 5027 => Loss: 23.0597047180\n",
      "Iteration 5028 => Loss: 23.0594740857\n",
      "Iteration 5029 => Loss: 23.0592436985\n",
      "Iteration 5030 => Loss: 23.0590135562\n",
      "Iteration 5031 => Loss: 23.0587836585\n",
      "Iteration 5032 => Loss: 23.0585540052\n",
      "Iteration 5033 => Loss: 23.0583245960\n",
      "Iteration 5034 => Loss: 23.0580954307\n",
      "Iteration 5035 => Loss: 23.0578665090\n",
      "Iteration 5036 => Loss: 23.0576378306\n",
      "Iteration 5037 => Loss: 23.0574093953\n",
      "Iteration 5038 => Loss: 23.0571812028\n",
      "Iteration 5039 => Loss: 23.0569532529\n",
      "Iteration 5040 => Loss: 23.0567255453\n",
      "Iteration 5041 => Loss: 23.0564980798\n",
      "Iteration 5042 => Loss: 23.0562708560\n",
      "Iteration 5043 => Loss: 23.0560438738\n",
      "Iteration 5044 => Loss: 23.0558171328\n",
      "Iteration 5045 => Loss: 23.0555906329\n",
      "Iteration 5046 => Loss: 23.0553643737\n",
      "Iteration 5047 => Loss: 23.0551383550\n",
      "Iteration 5048 => Loss: 23.0549125766\n",
      "Iteration 5049 => Loss: 23.0546870382\n",
      "Iteration 5050 => Loss: 23.0544617395\n",
      "Iteration 5051 => Loss: 23.0542366803\n",
      "Iteration 5052 => Loss: 23.0540118604\n",
      "Iteration 5053 => Loss: 23.0537872794\n",
      "Iteration 5054 => Loss: 23.0535629372\n",
      "Iteration 5055 => Loss: 23.0533388334\n",
      "Iteration 5056 => Loss: 23.0531149679\n",
      "Iteration 5057 => Loss: 23.0528913403\n",
      "Iteration 5058 => Loss: 23.0526679504\n",
      "Iteration 5059 => Loss: 23.0524447980\n",
      "Iteration 5060 => Loss: 23.0522218827\n",
      "Iteration 5061 => Loss: 23.0519992045\n",
      "Iteration 5062 => Loss: 23.0517767629\n",
      "Iteration 5063 => Loss: 23.0515545578\n",
      "Iteration 5064 => Loss: 23.0513325889\n",
      "Iteration 5065 => Loss: 23.0511108559\n",
      "Iteration 5066 => Loss: 23.0508893587\n",
      "Iteration 5067 => Loss: 23.0506680969\n",
      "Iteration 5068 => Loss: 23.0504470702\n",
      "Iteration 5069 => Loss: 23.0502262786\n",
      "Iteration 5070 => Loss: 23.0500057216\n",
      "Iteration 5071 => Loss: 23.0497853991\n",
      "Iteration 5072 => Loss: 23.0495653107\n",
      "Iteration 5073 => Loss: 23.0493454563\n",
      "Iteration 5074 => Loss: 23.0491258357\n",
      "Iteration 5075 => Loss: 23.0489064484\n",
      "Iteration 5076 => Loss: 23.0486872944\n",
      "Iteration 5077 => Loss: 23.0484683733\n",
      "Iteration 5078 => Loss: 23.0482496850\n",
      "Iteration 5079 => Loss: 23.0480312291\n",
      "Iteration 5080 => Loss: 23.0478130054\n",
      "Iteration 5081 => Loss: 23.0475950137\n",
      "Iteration 5082 => Loss: 23.0473772537\n",
      "Iteration 5083 => Loss: 23.0471597251\n",
      "Iteration 5084 => Loss: 23.0469424278\n",
      "Iteration 5085 => Loss: 23.0467253615\n",
      "Iteration 5086 => Loss: 23.0465085260\n",
      "Iteration 5087 => Loss: 23.0462919209\n",
      "Iteration 5088 => Loss: 23.0460755460\n",
      "Iteration 5089 => Loss: 23.0458594012\n",
      "Iteration 5090 => Loss: 23.0456434861\n",
      "Iteration 5091 => Loss: 23.0454278006\n",
      "Iteration 5092 => Loss: 23.0452123443\n",
      "Iteration 5093 => Loss: 23.0449971170\n",
      "Iteration 5094 => Loss: 23.0447821185\n",
      "Iteration 5095 => Loss: 23.0445673485\n",
      "Iteration 5096 => Loss: 23.0443528069\n",
      "Iteration 5097 => Loss: 23.0441384933\n",
      "Iteration 5098 => Loss: 23.0439244075\n",
      "Iteration 5099 => Loss: 23.0437105493\n",
      "Iteration 5100 => Loss: 23.0434969184\n",
      "Iteration 5101 => Loss: 23.0432835146\n",
      "Iteration 5102 => Loss: 23.0430703376\n",
      "Iteration 5103 => Loss: 23.0428573872\n",
      "Iteration 5104 => Loss: 23.0426446632\n",
      "Iteration 5105 => Loss: 23.0424321654\n",
      "Iteration 5106 => Loss: 23.0422198934\n",
      "Iteration 5107 => Loss: 23.0420078470\n",
      "Iteration 5108 => Loss: 23.0417960260\n",
      "Iteration 5109 => Loss: 23.0415844302\n",
      "Iteration 5110 => Loss: 23.0413730594\n",
      "Iteration 5111 => Loss: 23.0411619132\n",
      "Iteration 5112 => Loss: 23.0409509914\n",
      "Iteration 5113 => Loss: 23.0407402939\n",
      "Iteration 5114 => Loss: 23.0405298203\n",
      "Iteration 5115 => Loss: 23.0403195705\n",
      "Iteration 5116 => Loss: 23.0401095441\n",
      "Iteration 5117 => Loss: 23.0398997410\n",
      "Iteration 5118 => Loss: 23.0396901609\n",
      "Iteration 5119 => Loss: 23.0394808036\n",
      "Iteration 5120 => Loss: 23.0392716688\n",
      "Iteration 5121 => Loss: 23.0390627564\n",
      "Iteration 5122 => Loss: 23.0388540660\n",
      "Iteration 5123 => Loss: 23.0386455974\n",
      "Iteration 5124 => Loss: 23.0384373505\n",
      "Iteration 5125 => Loss: 23.0382293249\n",
      "Iteration 5126 => Loss: 23.0380215204\n",
      "Iteration 5127 => Loss: 23.0378139368\n",
      "Iteration 5128 => Loss: 23.0376065739\n",
      "Iteration 5129 => Loss: 23.0373994314\n",
      "Iteration 5130 => Loss: 23.0371925091\n",
      "Iteration 5131 => Loss: 23.0369858067\n",
      "Iteration 5132 => Loss: 23.0367793241\n",
      "Iteration 5133 => Loss: 23.0365730609\n",
      "Iteration 5134 => Loss: 23.0363670170\n",
      "Iteration 5135 => Loss: 23.0361611922\n",
      "Iteration 5136 => Loss: 23.0359555861\n",
      "Iteration 5137 => Loss: 23.0357501985\n",
      "Iteration 5138 => Loss: 23.0355450293\n",
      "Iteration 5139 => Loss: 23.0353400782\n",
      "Iteration 5140 => Loss: 23.0351353450\n",
      "Iteration 5141 => Loss: 23.0349308293\n",
      "Iteration 5142 => Loss: 23.0347265311\n",
      "Iteration 5143 => Loss: 23.0345224500\n",
      "Iteration 5144 => Loss: 23.0343185859\n",
      "Iteration 5145 => Loss: 23.0341149384\n",
      "Iteration 5146 => Loss: 23.0339115075\n",
      "Iteration 5147 => Loss: 23.0337082927\n",
      "Iteration 5148 => Loss: 23.0335052940\n",
      "Iteration 5149 => Loss: 23.0333025111\n",
      "Iteration 5150 => Loss: 23.0330999437\n",
      "Iteration 5151 => Loss: 23.0328975917\n",
      "Iteration 5152 => Loss: 23.0326954547\n",
      "Iteration 5153 => Loss: 23.0324935326\n",
      "Iteration 5154 => Loss: 23.0322918252\n",
      "Iteration 5155 => Loss: 23.0320903322\n",
      "Iteration 5156 => Loss: 23.0318890533\n",
      "Iteration 5157 => Loss: 23.0316879884\n",
      "Iteration 5158 => Loss: 23.0314871373\n",
      "Iteration 5159 => Loss: 23.0312864996\n",
      "Iteration 5160 => Loss: 23.0310860752\n",
      "Iteration 5161 => Loss: 23.0308858638\n",
      "Iteration 5162 => Loss: 23.0306858653\n",
      "Iteration 5163 => Loss: 23.0304860794\n",
      "Iteration 5164 => Loss: 23.0302865058\n",
      "Iteration 5165 => Loss: 23.0300871444\n",
      "Iteration 5166 => Loss: 23.0298879949\n",
      "Iteration 5167 => Loss: 23.0296890571\n",
      "Iteration 5168 => Loss: 23.0294903307\n",
      "Iteration 5169 => Loss: 23.0292918156\n",
      "Iteration 5170 => Loss: 23.0290935115\n",
      "Iteration 5171 => Loss: 23.0288954182\n",
      "Iteration 5172 => Loss: 23.0286975355\n",
      "Iteration 5173 => Loss: 23.0284998631\n",
      "Iteration 5174 => Loss: 23.0283024009\n",
      "Iteration 5175 => Loss: 23.0281051485\n",
      "Iteration 5176 => Loss: 23.0279081058\n",
      "Iteration 5177 => Loss: 23.0277112726\n",
      "Iteration 5178 => Loss: 23.0275146486\n",
      "Iteration 5179 => Loss: 23.0273182336\n",
      "Iteration 5180 => Loss: 23.0271220274\n",
      "Iteration 5181 => Loss: 23.0269260297\n",
      "Iteration 5182 => Loss: 23.0267302404\n",
      "Iteration 5183 => Loss: 23.0265346592\n",
      "Iteration 5184 => Loss: 23.0263392859\n",
      "Iteration 5185 => Loss: 23.0261441203\n",
      "Iteration 5186 => Loss: 23.0259491622\n",
      "Iteration 5187 => Loss: 23.0257544113\n",
      "Iteration 5188 => Loss: 23.0255598674\n",
      "Iteration 5189 => Loss: 23.0253655303\n",
      "Iteration 5190 => Loss: 23.0251713997\n",
      "Iteration 5191 => Loss: 23.0249774756\n",
      "Iteration 5192 => Loss: 23.0247837575\n",
      "Iteration 5193 => Loss: 23.0245902454\n",
      "Iteration 5194 => Loss: 23.0243969390\n",
      "Iteration 5195 => Loss: 23.0242038380\n",
      "Iteration 5196 => Loss: 23.0240109424\n",
      "Iteration 5197 => Loss: 23.0238182517\n",
      "Iteration 5198 => Loss: 23.0236257659\n",
      "Iteration 5199 => Loss: 23.0234334847\n",
      "Iteration 5200 => Loss: 23.0232414079\n",
      "Iteration 5201 => Loss: 23.0230495353\n",
      "Iteration 5202 => Loss: 23.0228578666\n",
      "Iteration 5203 => Loss: 23.0226664017\n",
      "Iteration 5204 => Loss: 23.0224751403\n",
      "Iteration 5205 => Loss: 23.0222840822\n",
      "Iteration 5206 => Loss: 23.0220932271\n",
      "Iteration 5207 => Loss: 23.0219025750\n",
      "Iteration 5208 => Loss: 23.0217121255\n",
      "Iteration 5209 => Loss: 23.0215218785\n",
      "Iteration 5210 => Loss: 23.0213318337\n",
      "Iteration 5211 => Loss: 23.0211419909\n",
      "Iteration 5212 => Loss: 23.0209523499\n",
      "Iteration 5213 => Loss: 23.0207629105\n",
      "Iteration 5214 => Loss: 23.0205736724\n",
      "Iteration 5215 => Loss: 23.0203846355\n",
      "Iteration 5216 => Loss: 23.0201957996\n",
      "Iteration 5217 => Loss: 23.0200071644\n",
      "Iteration 5218 => Loss: 23.0198187297\n",
      "Iteration 5219 => Loss: 23.0196304953\n",
      "Iteration 5220 => Loss: 23.0194424610\n",
      "Iteration 5221 => Loss: 23.0192546265\n",
      "Iteration 5222 => Loss: 23.0190669918\n",
      "Iteration 5223 => Loss: 23.0188795565\n",
      "Iteration 5224 => Loss: 23.0186923204\n",
      "Iteration 5225 => Loss: 23.0185052833\n",
      "Iteration 5226 => Loss: 23.0183184451\n",
      "Iteration 5227 => Loss: 23.0181318055\n",
      "Iteration 5228 => Loss: 23.0179453642\n",
      "Iteration 5229 => Loss: 23.0177591212\n",
      "Iteration 5230 => Loss: 23.0175730761\n",
      "Iteration 5231 => Loss: 23.0173872288\n",
      "Iteration 5232 => Loss: 23.0172015790\n",
      "Iteration 5233 => Loss: 23.0170161266\n",
      "Iteration 5234 => Loss: 23.0168308713\n",
      "Iteration 5235 => Loss: 23.0166458129\n",
      "Iteration 5236 => Loss: 23.0164609513\n",
      "Iteration 5237 => Loss: 23.0162762861\n",
      "Iteration 5238 => Loss: 23.0160918173\n",
      "Iteration 5239 => Loss: 23.0159075445\n",
      "Iteration 5240 => Loss: 23.0157234676\n",
      "Iteration 5241 => Loss: 23.0155395864\n",
      "Iteration 5242 => Loss: 23.0153559006\n",
      "Iteration 5243 => Loss: 23.0151724101\n",
      "Iteration 5244 => Loss: 23.0149891147\n",
      "Iteration 5245 => Loss: 23.0148060140\n",
      "Iteration 5246 => Loss: 23.0146231081\n",
      "Iteration 5247 => Loss: 23.0144403965\n",
      "Iteration 5248 => Loss: 23.0142578791\n",
      "Iteration 5249 => Loss: 23.0140755558\n",
      "Iteration 5250 => Loss: 23.0138934263\n",
      "Iteration 5251 => Loss: 23.0137114904\n",
      "Iteration 5252 => Loss: 23.0135297478\n",
      "Iteration 5253 => Loss: 23.0133481985\n",
      "Iteration 5254 => Loss: 23.0131668421\n",
      "Iteration 5255 => Loss: 23.0129856785\n",
      "Iteration 5256 => Loss: 23.0128047075\n",
      "Iteration 5257 => Loss: 23.0126239289\n",
      "Iteration 5258 => Loss: 23.0124433424\n",
      "Iteration 5259 => Loss: 23.0122629479\n",
      "Iteration 5260 => Loss: 23.0120827451\n",
      "Iteration 5261 => Loss: 23.0119027339\n",
      "Iteration 5262 => Loss: 23.0117229141\n",
      "Iteration 5263 => Loss: 23.0115432853\n",
      "Iteration 5264 => Loss: 23.0113638476\n",
      "Iteration 5265 => Loss: 23.0111846005\n",
      "Iteration 5266 => Loss: 23.0110055440\n",
      "Iteration 5267 => Loss: 23.0108266778\n",
      "Iteration 5268 => Loss: 23.0106480018\n",
      "Iteration 5269 => Loss: 23.0104695157\n",
      "Iteration 5270 => Loss: 23.0102912193\n",
      "Iteration 5271 => Loss: 23.0101131125\n",
      "Iteration 5272 => Loss: 23.0099351949\n",
      "Iteration 5273 => Loss: 23.0097574665\n",
      "Iteration 5274 => Loss: 23.0095799270\n",
      "Iteration 5275 => Loss: 23.0094025763\n",
      "Iteration 5276 => Loss: 23.0092254140\n",
      "Iteration 5277 => Loss: 23.0090484401\n",
      "Iteration 5278 => Loss: 23.0088716543\n",
      "Iteration 5279 => Loss: 23.0086950564\n",
      "Iteration 5280 => Loss: 23.0085186462\n",
      "Iteration 5281 => Loss: 23.0083424236\n",
      "Iteration 5282 => Loss: 23.0081663882\n",
      "Iteration 5283 => Loss: 23.0079905400\n",
      "Iteration 5284 => Loss: 23.0078148787\n",
      "Iteration 5285 => Loss: 23.0076394042\n",
      "Iteration 5286 => Loss: 23.0074641161\n",
      "Iteration 5287 => Loss: 23.0072890144\n",
      "Iteration 5288 => Loss: 23.0071140989\n",
      "Iteration 5289 => Loss: 23.0069393692\n",
      "Iteration 5290 => Loss: 23.0067648253\n",
      "Iteration 5291 => Loss: 23.0065904669\n",
      "Iteration 5292 => Loss: 23.0064162939\n",
      "Iteration 5293 => Loss: 23.0062423060\n",
      "Iteration 5294 => Loss: 23.0060685030\n",
      "Iteration 5295 => Loss: 23.0058948848\n",
      "Iteration 5296 => Loss: 23.0057214512\n",
      "Iteration 5297 => Loss: 23.0055482019\n",
      "Iteration 5298 => Loss: 23.0053751368\n",
      "Iteration 5299 => Loss: 23.0052022556\n",
      "Iteration 5300 => Loss: 23.0050295582\n",
      "Iteration 5301 => Loss: 23.0048570444\n",
      "Iteration 5302 => Loss: 23.0046847139\n",
      "Iteration 5303 => Loss: 23.0045125667\n",
      "Iteration 5304 => Loss: 23.0043406024\n",
      "Iteration 5305 => Loss: 23.0041688209\n",
      "Iteration 5306 => Loss: 23.0039972221\n",
      "Iteration 5307 => Loss: 23.0038258056\n",
      "Iteration 5308 => Loss: 23.0036545713\n",
      "Iteration 5309 => Loss: 23.0034835191\n",
      "Iteration 5310 => Loss: 23.0033126487\n",
      "Iteration 5311 => Loss: 23.0031419599\n",
      "Iteration 5312 => Loss: 23.0029714525\n",
      "Iteration 5313 => Loss: 23.0028011264\n",
      "Iteration 5314 => Loss: 23.0026309814\n",
      "Iteration 5315 => Loss: 23.0024610172\n",
      "Iteration 5316 => Loss: 23.0022912337\n",
      "Iteration 5317 => Loss: 23.0021216306\n",
      "Iteration 5318 => Loss: 23.0019522079\n",
      "Iteration 5319 => Loss: 23.0017829652\n",
      "Iteration 5320 => Loss: 23.0016139024\n",
      "Iteration 5321 => Loss: 23.0014450194\n",
      "Iteration 5322 => Loss: 23.0012763159\n",
      "Iteration 5323 => Loss: 23.0011077917\n",
      "Iteration 5324 => Loss: 23.0009394466\n",
      "Iteration 5325 => Loss: 23.0007712805\n",
      "Iteration 5326 => Loss: 23.0006032931\n",
      "Iteration 5327 => Loss: 23.0004354843\n",
      "Iteration 5328 => Loss: 23.0002678539\n",
      "Iteration 5329 => Loss: 23.0001004016\n",
      "Iteration 5330 => Loss: 22.9999331274\n",
      "Iteration 5331 => Loss: 22.9997660310\n",
      "Iteration 5332 => Loss: 22.9995991122\n",
      "Iteration 5333 => Loss: 22.9994323708\n",
      "Iteration 5334 => Loss: 22.9992658067\n",
      "Iteration 5335 => Loss: 22.9990994196\n",
      "Iteration 5336 => Loss: 22.9989332094\n",
      "Iteration 5337 => Loss: 22.9987671758\n",
      "Iteration 5338 => Loss: 22.9986013188\n",
      "Iteration 5339 => Loss: 22.9984356381\n",
      "Iteration 5340 => Loss: 22.9982701334\n",
      "Iteration 5341 => Loss: 22.9981048047\n",
      "Iteration 5342 => Loss: 22.9979396518\n",
      "Iteration 5343 => Loss: 22.9977746744\n",
      "Iteration 5344 => Loss: 22.9976098723\n",
      "Iteration 5345 => Loss: 22.9974452455\n",
      "Iteration 5346 => Loss: 22.9972807936\n",
      "Iteration 5347 => Loss: 22.9971165166\n",
      "Iteration 5348 => Loss: 22.9969524141\n",
      "Iteration 5349 => Loss: 22.9967884862\n",
      "Iteration 5350 => Loss: 22.9966247324\n",
      "Iteration 5351 => Loss: 22.9964611527\n",
      "Iteration 5352 => Loss: 22.9962977470\n",
      "Iteration 5353 => Loss: 22.9961345149\n",
      "Iteration 5354 => Loss: 22.9959714563\n",
      "Iteration 5355 => Loss: 22.9958085710\n",
      "Iteration 5356 => Loss: 22.9956458589\n",
      "Iteration 5357 => Loss: 22.9954833198\n",
      "Iteration 5358 => Loss: 22.9953209534\n",
      "Iteration 5359 => Loss: 22.9951587596\n",
      "Iteration 5360 => Loss: 22.9949967382\n",
      "Iteration 5361 => Loss: 22.9948348891\n",
      "Iteration 5362 => Loss: 22.9946732120\n",
      "Iteration 5363 => Loss: 22.9945117067\n",
      "Iteration 5364 => Loss: 22.9943503732\n",
      "Iteration 5365 => Loss: 22.9941892111\n",
      "Iteration 5366 => Loss: 22.9940282203\n",
      "Iteration 5367 => Loss: 22.9938674007\n",
      "Iteration 5368 => Loss: 22.9937067520\n",
      "Iteration 5369 => Loss: 22.9935462741\n",
      "Iteration 5370 => Loss: 22.9933859667\n",
      "Iteration 5371 => Loss: 22.9932258298\n",
      "Iteration 5372 => Loss: 22.9930658631\n",
      "Iteration 5373 => Loss: 22.9929060664\n",
      "Iteration 5374 => Loss: 22.9927464396\n",
      "Iteration 5375 => Loss: 22.9925869825\n",
      "Iteration 5376 => Loss: 22.9924276949\n",
      "Iteration 5377 => Loss: 22.9922685765\n",
      "Iteration 5378 => Loss: 22.9921096274\n",
      "Iteration 5379 => Loss: 22.9919508472\n",
      "Iteration 5380 => Loss: 22.9917922357\n",
      "Iteration 5381 => Loss: 22.9916337929\n",
      "Iteration 5382 => Loss: 22.9914755185\n",
      "Iteration 5383 => Loss: 22.9913174123\n",
      "Iteration 5384 => Loss: 22.9911594742\n",
      "Iteration 5385 => Loss: 22.9910017040\n",
      "Iteration 5386 => Loss: 22.9908441015\n",
      "Iteration 5387 => Loss: 22.9906866665\n",
      "Iteration 5388 => Loss: 22.9905293989\n",
      "Iteration 5389 => Loss: 22.9903722984\n",
      "Iteration 5390 => Loss: 22.9902153649\n",
      "Iteration 5391 => Loss: 22.9900585983\n",
      "Iteration 5392 => Loss: 22.9899019983\n",
      "Iteration 5393 => Loss: 22.9897455647\n",
      "Iteration 5394 => Loss: 22.9895892975\n",
      "Iteration 5395 => Loss: 22.9894331963\n",
      "Iteration 5396 => Loss: 22.9892772611\n",
      "Iteration 5397 => Loss: 22.9891214916\n",
      "Iteration 5398 => Loss: 22.9889658877\n",
      "Iteration 5399 => Loss: 22.9888104493\n",
      "Iteration 5400 => Loss: 22.9886551760\n",
      "Iteration 5401 => Loss: 22.9885000678\n",
      "Iteration 5402 => Loss: 22.9883451245\n",
      "Iteration 5403 => Loss: 22.9881903458\n",
      "Iteration 5404 => Loss: 22.9880357317\n",
      "Iteration 5405 => Loss: 22.9878812820\n",
      "Iteration 5406 => Loss: 22.9877269964\n",
      "Iteration 5407 => Loss: 22.9875728749\n",
      "Iteration 5408 => Loss: 22.9874189171\n",
      "Iteration 5409 => Loss: 22.9872651230\n",
      "Iteration 5410 => Loss: 22.9871114924\n",
      "Iteration 5411 => Loss: 22.9869580251\n",
      "Iteration 5412 => Loss: 22.9868047210\n",
      "Iteration 5413 => Loss: 22.9866515798\n",
      "Iteration 5414 => Loss: 22.9864986013\n",
      "Iteration 5415 => Loss: 22.9863457855\n",
      "Iteration 5416 => Loss: 22.9861931322\n",
      "Iteration 5417 => Loss: 22.9860406410\n",
      "Iteration 5418 => Loss: 22.9858883120\n",
      "Iteration 5419 => Loss: 22.9857361450\n",
      "Iteration 5420 => Loss: 22.9855841396\n",
      "Iteration 5421 => Loss: 22.9854322959\n",
      "Iteration 5422 => Loss: 22.9852806135\n",
      "Iteration 5423 => Loss: 22.9851290924\n",
      "Iteration 5424 => Loss: 22.9849777323\n",
      "Iteration 5425 => Loss: 22.9848265332\n",
      "Iteration 5426 => Loss: 22.9846754948\n",
      "Iteration 5427 => Loss: 22.9845246169\n",
      "Iteration 5428 => Loss: 22.9843738994\n",
      "Iteration 5429 => Loss: 22.9842233421\n",
      "Iteration 5430 => Loss: 22.9840729448\n",
      "Iteration 5431 => Loss: 22.9839227074\n",
      "Iteration 5432 => Loss: 22.9837726297\n",
      "Iteration 5433 => Loss: 22.9836227116\n",
      "Iteration 5434 => Loss: 22.9834729528\n",
      "Iteration 5435 => Loss: 22.9833233532\n",
      "Iteration 5436 => Loss: 22.9831739126\n",
      "Iteration 5437 => Loss: 22.9830246308\n",
      "Iteration 5438 => Loss: 22.9828755078\n",
      "Iteration 5439 => Loss: 22.9827265432\n",
      "Iteration 5440 => Loss: 22.9825777370\n",
      "Iteration 5441 => Loss: 22.9824290890\n",
      "Iteration 5442 => Loss: 22.9822805990\n",
      "Iteration 5443 => Loss: 22.9821322669\n",
      "Iteration 5444 => Loss: 22.9819840924\n",
      "Iteration 5445 => Loss: 22.9818360754\n",
      "Iteration 5446 => Loss: 22.9816882157\n",
      "Iteration 5447 => Loss: 22.9815405133\n",
      "Iteration 5448 => Loss: 22.9813929678\n",
      "Iteration 5449 => Loss: 22.9812455792\n",
      "Iteration 5450 => Loss: 22.9810983472\n",
      "Iteration 5451 => Loss: 22.9809512718\n",
      "Iteration 5452 => Loss: 22.9808043526\n",
      "Iteration 5453 => Loss: 22.9806575897\n",
      "Iteration 5454 => Loss: 22.9805109828\n",
      "Iteration 5455 => Loss: 22.9803645317\n",
      "Iteration 5456 => Loss: 22.9802182362\n",
      "Iteration 5457 => Loss: 22.9800720963\n",
      "Iteration 5458 => Loss: 22.9799261118\n",
      "Iteration 5459 => Loss: 22.9797802824\n",
      "Iteration 5460 => Loss: 22.9796346080\n",
      "Iteration 5461 => Loss: 22.9794890885\n",
      "Iteration 5462 => Loss: 22.9793437236\n",
      "Iteration 5463 => Loss: 22.9791985133\n",
      "Iteration 5464 => Loss: 22.9790534573\n",
      "Iteration 5465 => Loss: 22.9789085555\n",
      "Iteration 5466 => Loss: 22.9787638078\n",
      "Iteration 5467 => Loss: 22.9786192139\n",
      "Iteration 5468 => Loss: 22.9784747737\n",
      "Iteration 5469 => Loss: 22.9783304870\n",
      "Iteration 5470 => Loss: 22.9781863538\n",
      "Iteration 5471 => Loss: 22.9780423737\n",
      "Iteration 5472 => Loss: 22.9778985467\n",
      "Iteration 5473 => Loss: 22.9777548725\n",
      "Iteration 5474 => Loss: 22.9776113511\n",
      "Iteration 5475 => Loss: 22.9774679823\n",
      "Iteration 5476 => Loss: 22.9773247658\n",
      "Iteration 5477 => Loss: 22.9771817016\n",
      "Iteration 5478 => Loss: 22.9770387895\n",
      "Iteration 5479 => Loss: 22.9768960292\n",
      "Iteration 5480 => Loss: 22.9767534208\n",
      "Iteration 5481 => Loss: 22.9766109639\n",
      "Iteration 5482 => Loss: 22.9764686584\n",
      "Iteration 5483 => Loss: 22.9763265042\n",
      "Iteration 5484 => Loss: 22.9761845011\n",
      "Iteration 5485 => Loss: 22.9760426490\n",
      "Iteration 5486 => Loss: 22.9759009476\n",
      "Iteration 5487 => Loss: 22.9757593969\n",
      "Iteration 5488 => Loss: 22.9756179966\n",
      "Iteration 5489 => Loss: 22.9754767467\n",
      "Iteration 5490 => Loss: 22.9753356469\n",
      "Iteration 5491 => Loss: 22.9751946970\n",
      "Iteration 5492 => Loss: 22.9750538970\n",
      "Iteration 5493 => Loss: 22.9749132467\n",
      "Iteration 5494 => Loss: 22.9747727459\n",
      "Iteration 5495 => Loss: 22.9746323944\n",
      "Iteration 5496 => Loss: 22.9744921921\n",
      "Iteration 5497 => Loss: 22.9743521389\n",
      "Iteration 5498 => Loss: 22.9742122345\n",
      "Iteration 5499 => Loss: 22.9740724788\n",
      "Iteration 5500 => Loss: 22.9739328717\n",
      "Iteration 5501 => Loss: 22.9737934130\n",
      "Iteration 5502 => Loss: 22.9736541026\n",
      "Iteration 5503 => Loss: 22.9735149402\n",
      "Iteration 5504 => Loss: 22.9733759257\n",
      "Iteration 5505 => Loss: 22.9732370590\n",
      "Iteration 5506 => Loss: 22.9730983400\n",
      "Iteration 5507 => Loss: 22.9729597683\n",
      "Iteration 5508 => Loss: 22.9728213440\n",
      "Iteration 5509 => Loss: 22.9726830669\n",
      "Iteration 5510 => Loss: 22.9725449367\n",
      "Iteration 5511 => Loss: 22.9724069533\n",
      "Iteration 5512 => Loss: 22.9722691166\n",
      "Iteration 5513 => Loss: 22.9721314264\n",
      "Iteration 5514 => Loss: 22.9719938826\n",
      "Iteration 5515 => Loss: 22.9718564850\n",
      "Iteration 5516 => Loss: 22.9717192335\n",
      "Iteration 5517 => Loss: 22.9715821278\n",
      "Iteration 5518 => Loss: 22.9714451679\n",
      "Iteration 5519 => Loss: 22.9713083536\n",
      "Iteration 5520 => Loss: 22.9711716847\n",
      "Iteration 5521 => Loss: 22.9710351611\n",
      "Iteration 5522 => Loss: 22.9708987826\n",
      "Iteration 5523 => Loss: 22.9707625490\n",
      "Iteration 5524 => Loss: 22.9706264603\n",
      "Iteration 5525 => Loss: 22.9704905162\n",
      "Iteration 5526 => Loss: 22.9703547167\n",
      "Iteration 5527 => Loss: 22.9702190615\n",
      "Iteration 5528 => Loss: 22.9700835505\n",
      "Iteration 5529 => Loss: 22.9699481835\n",
      "Iteration 5530 => Loss: 22.9698129605\n",
      "Iteration 5531 => Loss: 22.9696778811\n",
      "Iteration 5532 => Loss: 22.9695429454\n",
      "Iteration 5533 => Loss: 22.9694081531\n",
      "Iteration 5534 => Loss: 22.9692735040\n",
      "Iteration 5535 => Loss: 22.9691389982\n",
      "Iteration 5536 => Loss: 22.9690046352\n",
      "Iteration 5537 => Loss: 22.9688704151\n",
      "Iteration 5538 => Loss: 22.9687363377\n",
      "Iteration 5539 => Loss: 22.9686024028\n",
      "Iteration 5540 => Loss: 22.9684686103\n",
      "Iteration 5541 => Loss: 22.9683349600\n",
      "Iteration 5542 => Loss: 22.9682014517\n",
      "Iteration 5543 => Loss: 22.9680680854\n",
      "Iteration 5544 => Loss: 22.9679348608\n",
      "Iteration 5545 => Loss: 22.9678017779\n",
      "Iteration 5546 => Loss: 22.9676688364\n",
      "Iteration 5547 => Loss: 22.9675360362\n",
      "Iteration 5548 => Loss: 22.9674033772\n",
      "Iteration 5549 => Loss: 22.9672708592\n",
      "Iteration 5550 => Loss: 22.9671384821\n",
      "Iteration 5551 => Loss: 22.9670062457\n",
      "Iteration 5552 => Loss: 22.9668741498\n",
      "Iteration 5553 => Loss: 22.9667421944\n",
      "Iteration 5554 => Loss: 22.9666103792\n",
      "Iteration 5555 => Loss: 22.9664787042\n",
      "Iteration 5556 => Loss: 22.9663471691\n",
      "Iteration 5557 => Loss: 22.9662157738\n",
      "Iteration 5558 => Loss: 22.9660845182\n",
      "Iteration 5559 => Loss: 22.9659534022\n",
      "Iteration 5560 => Loss: 22.9658224255\n",
      "Iteration 5561 => Loss: 22.9656915880\n",
      "Iteration 5562 => Loss: 22.9655608896\n",
      "Iteration 5563 => Loss: 22.9654303301\n",
      "Iteration 5564 => Loss: 22.9652999094\n",
      "Iteration 5565 => Loss: 22.9651696274\n",
      "Iteration 5566 => Loss: 22.9650394838\n",
      "Iteration 5567 => Loss: 22.9649094786\n",
      "Iteration 5568 => Loss: 22.9647796116\n",
      "Iteration 5569 => Loss: 22.9646498826\n",
      "Iteration 5570 => Loss: 22.9645202915\n",
      "Iteration 5571 => Loss: 22.9643908382\n",
      "Iteration 5572 => Loss: 22.9642615224\n",
      "Iteration 5573 => Loss: 22.9641323442\n",
      "Iteration 5574 => Loss: 22.9640033032\n",
      "Iteration 5575 => Loss: 22.9638743994\n",
      "Iteration 5576 => Loss: 22.9637456327\n",
      "Iteration 5577 => Loss: 22.9636170028\n",
      "Iteration 5578 => Loss: 22.9634885096\n",
      "Iteration 5579 => Loss: 22.9633601531\n",
      "Iteration 5580 => Loss: 22.9632319329\n",
      "Iteration 5581 => Loss: 22.9631038491\n",
      "Iteration 5582 => Loss: 22.9629759014\n",
      "Iteration 5583 => Loss: 22.9628480897\n",
      "Iteration 5584 => Loss: 22.9627204139\n",
      "Iteration 5585 => Loss: 22.9625928738\n",
      "Iteration 5586 => Loss: 22.9624654693\n",
      "Iteration 5587 => Loss: 22.9623382002\n",
      "Iteration 5588 => Loss: 22.9622110664\n",
      "Iteration 5589 => Loss: 22.9620840677\n",
      "Iteration 5590 => Loss: 22.9619572040\n",
      "Iteration 5591 => Loss: 22.9618304752\n",
      "Iteration 5592 => Loss: 22.9617038811\n",
      "Iteration 5593 => Loss: 22.9615774215\n",
      "Iteration 5594 => Loss: 22.9614510964\n",
      "Iteration 5595 => Loss: 22.9613249055\n",
      "Iteration 5596 => Loss: 22.9611988488\n",
      "Iteration 5597 => Loss: 22.9610729261\n",
      "Iteration 5598 => Loss: 22.9609471373\n",
      "Iteration 5599 => Loss: 22.9608214821\n",
      "Iteration 5600 => Loss: 22.9606959605\n",
      "Iteration 5601 => Loss: 22.9605705724\n",
      "Iteration 5602 => Loss: 22.9604453175\n",
      "Iteration 5603 => Loss: 22.9603201958\n",
      "Iteration 5604 => Loss: 22.9601952071\n",
      "Iteration 5605 => Loss: 22.9600703512\n",
      "Iteration 5606 => Loss: 22.9599456281\n",
      "Iteration 5607 => Loss: 22.9598210375\n",
      "Iteration 5608 => Loss: 22.9596965794\n",
      "Iteration 5609 => Loss: 22.9595722536\n",
      "Iteration 5610 => Loss: 22.9594480599\n",
      "Iteration 5611 => Loss: 22.9593239982\n",
      "Iteration 5612 => Loss: 22.9592000684\n",
      "Iteration 5613 => Loss: 22.9590762704\n",
      "Iteration 5614 => Loss: 22.9589526039\n",
      "Iteration 5615 => Loss: 22.9588290689\n",
      "Iteration 5616 => Loss: 22.9587056653\n",
      "Iteration 5617 => Loss: 22.9585823927\n",
      "Iteration 5618 => Loss: 22.9584592513\n",
      "Iteration 5619 => Loss: 22.9583362407\n",
      "Iteration 5620 => Loss: 22.9582133609\n",
      "Iteration 5621 => Loss: 22.9580906117\n",
      "Iteration 5622 => Loss: 22.9579679930\n",
      "Iteration 5623 => Loss: 22.9578455046\n",
      "Iteration 5624 => Loss: 22.9577231464\n",
      "Iteration 5625 => Loss: 22.9576009183\n",
      "Iteration 5626 => Loss: 22.9574788201\n",
      "Iteration 5627 => Loss: 22.9573568517\n",
      "Iteration 5628 => Loss: 22.9572350130\n",
      "Iteration 5629 => Loss: 22.9571133037\n",
      "Iteration 5630 => Loss: 22.9569917239\n",
      "Iteration 5631 => Loss: 22.9568702732\n",
      "Iteration 5632 => Loss: 22.9567489517\n",
      "Iteration 5633 => Loss: 22.9566277591\n",
      "Iteration 5634 => Loss: 22.9565066954\n",
      "Iteration 5635 => Loss: 22.9563857603\n",
      "Iteration 5636 => Loss: 22.9562649538\n",
      "Iteration 5637 => Loss: 22.9561442758\n",
      "Iteration 5638 => Loss: 22.9560237260\n",
      "Iteration 5639 => Loss: 22.9559033043\n",
      "Iteration 5640 => Loss: 22.9557830106\n",
      "Iteration 5641 => Loss: 22.9556628448\n",
      "Iteration 5642 => Loss: 22.9555428068\n",
      "Iteration 5643 => Loss: 22.9554228963\n",
      "Iteration 5644 => Loss: 22.9553031133\n",
      "Iteration 5645 => Loss: 22.9551834577\n",
      "Iteration 5646 => Loss: 22.9550639292\n",
      "Iteration 5647 => Loss: 22.9549445278\n",
      "Iteration 5648 => Loss: 22.9548252533\n",
      "Iteration 5649 => Loss: 22.9547061055\n",
      "Iteration 5650 => Loss: 22.9545870845\n",
      "Iteration 5651 => Loss: 22.9544681899\n",
      "Iteration 5652 => Loss: 22.9543494218\n",
      "Iteration 5653 => Loss: 22.9542307799\n",
      "Iteration 5654 => Loss: 22.9541122641\n",
      "Iteration 5655 => Loss: 22.9539938742\n",
      "Iteration 5656 => Loss: 22.9538756103\n",
      "Iteration 5657 => Loss: 22.9537574720\n",
      "Iteration 5658 => Loss: 22.9536394593\n",
      "Iteration 5659 => Loss: 22.9535215721\n",
      "Iteration 5660 => Loss: 22.9534038101\n",
      "Iteration 5661 => Loss: 22.9532861734\n",
      "Iteration 5662 => Loss: 22.9531686617\n",
      "Iteration 5663 => Loss: 22.9530512749\n",
      "Iteration 5664 => Loss: 22.9529340129\n",
      "Iteration 5665 => Loss: 22.9528168755\n",
      "Iteration 5666 => Loss: 22.9526998627\n",
      "Iteration 5667 => Loss: 22.9525829742\n",
      "Iteration 5668 => Loss: 22.9524662100\n",
      "Iteration 5669 => Loss: 22.9523495699\n",
      "Iteration 5670 => Loss: 22.9522330538\n",
      "Iteration 5671 => Loss: 22.9521166615\n",
      "Iteration 5672 => Loss: 22.9520003930\n",
      "Iteration 5673 => Loss: 22.9518842480\n",
      "Iteration 5674 => Loss: 22.9517682265\n",
      "Iteration 5675 => Loss: 22.9516523284\n",
      "Iteration 5676 => Loss: 22.9515365534\n",
      "Iteration 5677 => Loss: 22.9514209015\n",
      "Iteration 5678 => Loss: 22.9513053726\n",
      "Iteration 5679 => Loss: 22.9511899664\n",
      "Iteration 5680 => Loss: 22.9510746829\n",
      "Iteration 5681 => Loss: 22.9509595220\n",
      "Iteration 5682 => Loss: 22.9508444835\n",
      "Iteration 5683 => Loss: 22.9507295672\n",
      "Iteration 5684 => Loss: 22.9506147731\n",
      "Iteration 5685 => Loss: 22.9505001011\n",
      "Iteration 5686 => Loss: 22.9503855509\n",
      "Iteration 5687 => Loss: 22.9502711225\n",
      "Iteration 5688 => Loss: 22.9501568157\n",
      "Iteration 5689 => Loss: 22.9500426305\n",
      "Iteration 5690 => Loss: 22.9499285666\n",
      "Iteration 5691 => Loss: 22.9498146239\n",
      "Iteration 5692 => Loss: 22.9497008024\n",
      "Iteration 5693 => Loss: 22.9495871019\n",
      "Iteration 5694 => Loss: 22.9494735222\n",
      "Iteration 5695 => Loss: 22.9493600633\n",
      "Iteration 5696 => Loss: 22.9492467249\n",
      "Iteration 5697 => Loss: 22.9491335071\n",
      "Iteration 5698 => Loss: 22.9490204096\n",
      "Iteration 5699 => Loss: 22.9489074323\n",
      "Iteration 5700 => Loss: 22.9487945751\n",
      "Iteration 5701 => Loss: 22.9486818379\n",
      "Iteration 5702 => Loss: 22.9485692205\n",
      "Iteration 5703 => Loss: 22.9484567228\n",
      "Iteration 5704 => Loss: 22.9483443447\n",
      "Iteration 5705 => Loss: 22.9482320860\n",
      "Iteration 5706 => Loss: 22.9481199467\n",
      "Iteration 5707 => Loss: 22.9480079266\n",
      "Iteration 5708 => Loss: 22.9478960256\n",
      "Iteration 5709 => Loss: 22.9477842435\n",
      "Iteration 5710 => Loss: 22.9476725802\n",
      "Iteration 5711 => Loss: 22.9475610356\n",
      "Iteration 5712 => Loss: 22.9474496096\n",
      "Iteration 5713 => Loss: 22.9473383021\n",
      "Iteration 5714 => Loss: 22.9472271128\n",
      "Iteration 5715 => Loss: 22.9471160418\n",
      "Iteration 5716 => Loss: 22.9470050888\n",
      "Iteration 5717 => Loss: 22.9468942537\n",
      "Iteration 5718 => Loss: 22.9467835365\n",
      "Iteration 5719 => Loss: 22.9466729370\n",
      "Iteration 5720 => Loss: 22.9465624550\n",
      "Iteration 5721 => Loss: 22.9464520905\n",
      "Iteration 5722 => Loss: 22.9463418432\n",
      "Iteration 5723 => Loss: 22.9462317132\n",
      "Iteration 5724 => Loss: 22.9461217003\n",
      "Iteration 5725 => Loss: 22.9460118042\n",
      "Iteration 5726 => Loss: 22.9459020250\n",
      "Iteration 5727 => Loss: 22.9457923625\n",
      "Iteration 5728 => Loss: 22.9456828166\n",
      "Iteration 5729 => Loss: 22.9455733871\n",
      "Iteration 5730 => Loss: 22.9454640739\n",
      "Iteration 5731 => Loss: 22.9453548769\n",
      "Iteration 5732 => Loss: 22.9452457960\n",
      "Iteration 5733 => Loss: 22.9451368311\n",
      "Iteration 5734 => Loss: 22.9450279819\n",
      "Iteration 5735 => Loss: 22.9449192485\n",
      "Iteration 5736 => Loss: 22.9448106307\n",
      "Iteration 5737 => Loss: 22.9447021283\n",
      "Iteration 5738 => Loss: 22.9445937412\n",
      "Iteration 5739 => Loss: 22.9444854694\n",
      "Iteration 5740 => Loss: 22.9443773127\n",
      "Iteration 5741 => Loss: 22.9442692709\n",
      "Iteration 5742 => Loss: 22.9441613440\n",
      "Iteration 5743 => Loss: 22.9440535318\n",
      "Iteration 5744 => Loss: 22.9439458342\n",
      "Iteration 5745 => Loss: 22.9438382510\n",
      "Iteration 5746 => Loss: 22.9437307823\n",
      "Iteration 5747 => Loss: 22.9436234277\n",
      "Iteration 5748 => Loss: 22.9435161873\n",
      "Iteration 5749 => Loss: 22.9434090609\n",
      "Iteration 5750 => Loss: 22.9433020484\n",
      "Iteration 5751 => Loss: 22.9431951496\n",
      "Iteration 5752 => Loss: 22.9430883644\n",
      "Iteration 5753 => Loss: 22.9429816928\n",
      "Iteration 5754 => Loss: 22.9428751345\n",
      "Iteration 5755 => Loss: 22.9427686895\n",
      "Iteration 5756 => Loss: 22.9426623577\n",
      "Iteration 5757 => Loss: 22.9425561389\n",
      "Iteration 5758 => Loss: 22.9424500329\n",
      "Iteration 5759 => Loss: 22.9423440398\n",
      "Iteration 5760 => Loss: 22.9422381594\n",
      "Iteration 5761 => Loss: 22.9421323915\n",
      "Iteration 5762 => Loss: 22.9420267360\n",
      "Iteration 5763 => Loss: 22.9419211928\n",
      "Iteration 5764 => Loss: 22.9418157619\n",
      "Iteration 5765 => Loss: 22.9417104430\n",
      "Iteration 5766 => Loss: 22.9416052360\n",
      "Iteration 5767 => Loss: 22.9415001409\n",
      "Iteration 5768 => Loss: 22.9413951575\n",
      "Iteration 5769 => Loss: 22.9412902857\n",
      "Iteration 5770 => Loss: 22.9411855254\n",
      "Iteration 5771 => Loss: 22.9410808764\n",
      "Iteration 5772 => Loss: 22.9409763387\n",
      "Iteration 5773 => Loss: 22.9408719121\n",
      "Iteration 5774 => Loss: 22.9407675964\n",
      "Iteration 5775 => Loss: 22.9406633917\n",
      "Iteration 5776 => Loss: 22.9405592978\n",
      "Iteration 5777 => Loss: 22.9404553145\n",
      "Iteration 5778 => Loss: 22.9403514417\n",
      "Iteration 5779 => Loss: 22.9402476793\n",
      "Iteration 5780 => Loss: 22.9401440273\n",
      "Iteration 5781 => Loss: 22.9400404854\n",
      "Iteration 5782 => Loss: 22.9399370536\n",
      "Iteration 5783 => Loss: 22.9398337317\n",
      "Iteration 5784 => Loss: 22.9397305196\n",
      "Iteration 5785 => Loss: 22.9396274173\n",
      "Iteration 5786 => Loss: 22.9395244246\n",
      "Iteration 5787 => Loss: 22.9394215413\n",
      "Iteration 5788 => Loss: 22.9393187674\n",
      "Iteration 5789 => Loss: 22.9392161028\n",
      "Iteration 5790 => Loss: 22.9391135473\n",
      "Iteration 5791 => Loss: 22.9390111008\n",
      "Iteration 5792 => Loss: 22.9389087631\n",
      "Iteration 5793 => Loss: 22.9388065343\n",
      "Iteration 5794 => Loss: 22.9387044142\n",
      "Iteration 5795 => Loss: 22.9386024026\n",
      "Iteration 5796 => Loss: 22.9385004994\n",
      "Iteration 5797 => Loss: 22.9383987045\n",
      "Iteration 5798 => Loss: 22.9382970179\n",
      "Iteration 5799 => Loss: 22.9381954394\n",
      "Iteration 5800 => Loss: 22.9380939688\n",
      "Iteration 5801 => Loss: 22.9379926061\n",
      "Iteration 5802 => Loss: 22.9378913511\n",
      "Iteration 5803 => Loss: 22.9377902038\n",
      "Iteration 5804 => Loss: 22.9376891639\n",
      "Iteration 5805 => Loss: 22.9375882315\n",
      "Iteration 5806 => Loss: 22.9374874064\n",
      "Iteration 5807 => Loss: 22.9373866885\n",
      "Iteration 5808 => Loss: 22.9372860776\n",
      "Iteration 5809 => Loss: 22.9371855736\n",
      "Iteration 5810 => Loss: 22.9370851765\n",
      "Iteration 5811 => Loss: 22.9369848861\n",
      "Iteration 5812 => Loss: 22.9368847023\n",
      "Iteration 5813 => Loss: 22.9367846251\n",
      "Iteration 5814 => Loss: 22.9366846541\n",
      "Iteration 5815 => Loss: 22.9365847895\n",
      "Iteration 5816 => Loss: 22.9364850310\n",
      "Iteration 5817 => Loss: 22.9363853786\n",
      "Iteration 5818 => Loss: 22.9362858320\n",
      "Iteration 5819 => Loss: 22.9361863913\n",
      "Iteration 5820 => Loss: 22.9360870563\n",
      "Iteration 5821 => Loss: 22.9359878269\n",
      "Iteration 5822 => Loss: 22.9358887030\n",
      "Iteration 5823 => Loss: 22.9357896844\n",
      "Iteration 5824 => Loss: 22.9356907711\n",
      "Iteration 5825 => Loss: 22.9355919630\n",
      "Iteration 5826 => Loss: 22.9354932598\n",
      "Iteration 5827 => Loss: 22.9353946616\n",
      "Iteration 5828 => Loss: 22.9352961682\n",
      "Iteration 5829 => Loss: 22.9351977795\n",
      "Iteration 5830 => Loss: 22.9350994954\n",
      "Iteration 5831 => Loss: 22.9350013157\n",
      "Iteration 5832 => Loss: 22.9349032404\n",
      "Iteration 5833 => Loss: 22.9348052694\n",
      "Iteration 5834 => Loss: 22.9347074025\n",
      "Iteration 5835 => Loss: 22.9346096396\n",
      "Iteration 5836 => Loss: 22.9345119807\n",
      "Iteration 5837 => Loss: 22.9344144256\n",
      "Iteration 5838 => Loss: 22.9343169741\n",
      "Iteration 5839 => Loss: 22.9342196263\n",
      "Iteration 5840 => Loss: 22.9341223819\n",
      "Iteration 5841 => Loss: 22.9340252409\n",
      "Iteration 5842 => Loss: 22.9339282032\n",
      "Iteration 5843 => Loss: 22.9338312686\n",
      "Iteration 5844 => Loss: 22.9337344370\n",
      "Iteration 5845 => Loss: 22.9336377084\n",
      "Iteration 5846 => Loss: 22.9335410826\n",
      "Iteration 5847 => Loss: 22.9334445595\n",
      "Iteration 5848 => Loss: 22.9333481390\n",
      "Iteration 5849 => Loss: 22.9332518210\n",
      "Iteration 5850 => Loss: 22.9331556054\n",
      "Iteration 5851 => Loss: 22.9330594920\n",
      "Iteration 5852 => Loss: 22.9329634809\n",
      "Iteration 5853 => Loss: 22.9328675718\n",
      "Iteration 5854 => Loss: 22.9327717646\n",
      "Iteration 5855 => Loss: 22.9326760593\n",
      "Iteration 5856 => Loss: 22.9325804557\n",
      "Iteration 5857 => Loss: 22.9324849537\n",
      "Iteration 5858 => Loss: 22.9323895533\n",
      "Iteration 5859 => Loss: 22.9322942542\n",
      "Iteration 5860 => Loss: 22.9321990565\n",
      "Iteration 5861 => Loss: 22.9321039599\n",
      "Iteration 5862 => Loss: 22.9320089645\n",
      "Iteration 5863 => Loss: 22.9319140700\n",
      "Iteration 5864 => Loss: 22.9318192764\n",
      "Iteration 5865 => Loss: 22.9317245835\n",
      "Iteration 5866 => Loss: 22.9316299913\n",
      "Iteration 5867 => Loss: 22.9315354997\n",
      "Iteration 5868 => Loss: 22.9314411085\n",
      "Iteration 5869 => Loss: 22.9313468176\n",
      "Iteration 5870 => Loss: 22.9312526270\n",
      "Iteration 5871 => Loss: 22.9311585365\n",
      "Iteration 5872 => Loss: 22.9310645460\n",
      "Iteration 5873 => Loss: 22.9309706554\n",
      "Iteration 5874 => Loss: 22.9308768646\n",
      "Iteration 5875 => Loss: 22.9307831735\n",
      "Iteration 5876 => Loss: 22.9306895820\n",
      "Iteration 5877 => Loss: 22.9305960900\n",
      "Iteration 5878 => Loss: 22.9305026974\n",
      "Iteration 5879 => Loss: 22.9304094040\n",
      "Iteration 5880 => Loss: 22.9303162099\n",
      "Iteration 5881 => Loss: 22.9302231147\n",
      "Iteration 5882 => Loss: 22.9301301186\n",
      "Iteration 5883 => Loss: 22.9300372213\n",
      "Iteration 5884 => Loss: 22.9299444227\n",
      "Iteration 5885 => Loss: 22.9298517228\n",
      "Iteration 5886 => Loss: 22.9297591214\n",
      "Iteration 5887 => Loss: 22.9296666185\n",
      "Iteration 5888 => Loss: 22.9295742138\n",
      "Iteration 5889 => Loss: 22.9294819074\n",
      "Iteration 5890 => Loss: 22.9293896992\n",
      "Iteration 5891 => Loss: 22.9292975889\n",
      "Iteration 5892 => Loss: 22.9292055766\n",
      "Iteration 5893 => Loss: 22.9291136620\n",
      "Iteration 5894 => Loss: 22.9290218452\n",
      "Iteration 5895 => Loss: 22.9289301259\n",
      "Iteration 5896 => Loss: 22.9288385042\n",
      "Iteration 5897 => Loss: 22.9287469798\n",
      "Iteration 5898 => Loss: 22.9286555528\n",
      "Iteration 5899 => Loss: 22.9285642229\n",
      "Iteration 5900 => Loss: 22.9284729901\n",
      "Iteration 5901 => Loss: 22.9283818543\n",
      "Iteration 5902 => Loss: 22.9282908153\n",
      "Iteration 5903 => Loss: 22.9281998732\n",
      "Iteration 5904 => Loss: 22.9281090277\n",
      "Iteration 5905 => Loss: 22.9280182787\n",
      "Iteration 5906 => Loss: 22.9279276263\n",
      "Iteration 5907 => Loss: 22.9278370702\n",
      "Iteration 5908 => Loss: 22.9277466103\n",
      "Iteration 5909 => Loss: 22.9276562466\n",
      "Iteration 5910 => Loss: 22.9275659790\n",
      "Iteration 5911 => Loss: 22.9274758073\n",
      "Iteration 5912 => Loss: 22.9273857315\n",
      "Iteration 5913 => Loss: 22.9272957514\n",
      "Iteration 5914 => Loss: 22.9272058669\n",
      "Iteration 5915 => Loss: 22.9271160781\n",
      "Iteration 5916 => Loss: 22.9270263846\n",
      "Iteration 5917 => Loss: 22.9269367865\n",
      "Iteration 5918 => Loss: 22.9268472836\n",
      "Iteration 5919 => Loss: 22.9267578759\n",
      "Iteration 5920 => Loss: 22.9266685632\n",
      "Iteration 5921 => Loss: 22.9265793455\n",
      "Iteration 5922 => Loss: 22.9264902226\n",
      "Iteration 5923 => Loss: 22.9264011944\n",
      "Iteration 5924 => Loss: 22.9263122608\n",
      "Iteration 5925 => Loss: 22.9262234218\n",
      "Iteration 5926 => Loss: 22.9261346773\n",
      "Iteration 5927 => Loss: 22.9260460270\n",
      "Iteration 5928 => Loss: 22.9259574710\n",
      "Iteration 5929 => Loss: 22.9258690091\n",
      "Iteration 5930 => Loss: 22.9257806413\n",
      "Iteration 5931 => Loss: 22.9256923674\n",
      "Iteration 5932 => Loss: 22.9256041873\n",
      "Iteration 5933 => Loss: 22.9255161010\n",
      "Iteration 5934 => Loss: 22.9254281083\n",
      "Iteration 5935 => Loss: 22.9253402091\n",
      "Iteration 5936 => Loss: 22.9252524033\n",
      "Iteration 5937 => Loss: 22.9251646909\n",
      "Iteration 5938 => Loss: 22.9250770718\n",
      "Iteration 5939 => Loss: 22.9249895457\n",
      "Iteration 5940 => Loss: 22.9249021128\n",
      "Iteration 5941 => Loss: 22.9248147727\n",
      "Iteration 5942 => Loss: 22.9247275255\n",
      "Iteration 5943 => Loss: 22.9246403710\n",
      "Iteration 5944 => Loss: 22.9245533092\n",
      "Iteration 5945 => Loss: 22.9244663399\n",
      "Iteration 5946 => Loss: 22.9243794631\n",
      "Iteration 5947 => Loss: 22.9242926786\n",
      "Iteration 5948 => Loss: 22.9242059864\n",
      "Iteration 5949 => Loss: 22.9241193863\n",
      "Iteration 5950 => Loss: 22.9240328783\n",
      "Iteration 5951 => Loss: 22.9239464622\n",
      "Iteration 5952 => Loss: 22.9238601380\n",
      "Iteration 5953 => Loss: 22.9237739055\n",
      "Iteration 5954 => Loss: 22.9236877647\n",
      "Iteration 5955 => Loss: 22.9236017155\n",
      "Iteration 5956 => Loss: 22.9235157577\n",
      "Iteration 5957 => Loss: 22.9234298914\n",
      "Iteration 5958 => Loss: 22.9233441162\n",
      "Iteration 5959 => Loss: 22.9232584323\n",
      "Iteration 5960 => Loss: 22.9231728395\n",
      "Iteration 5961 => Loss: 22.9230873376\n",
      "Iteration 5962 => Loss: 22.9230019266\n",
      "Iteration 5963 => Loss: 22.9229166064\n",
      "Iteration 5964 => Loss: 22.9228313769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5965 => Loss: 22.9227462380\n",
      "Iteration 5966 => Loss: 22.9226611896\n",
      "Iteration 5967 => Loss: 22.9225762316\n",
      "Iteration 5968 => Loss: 22.9224913639\n",
      "Iteration 5969 => Loss: 22.9224065864\n",
      "Iteration 5970 => Loss: 22.9223218991\n",
      "Iteration 5971 => Loss: 22.9222373017\n",
      "Iteration 5972 => Loss: 22.9221527943\n",
      "Iteration 5973 => Loss: 22.9220683767\n",
      "Iteration 5974 => Loss: 22.9219840489\n",
      "Iteration 5975 => Loss: 22.9218998107\n",
      "Iteration 5976 => Loss: 22.9218156620\n",
      "Iteration 5977 => Loss: 22.9217316028\n",
      "Iteration 5978 => Loss: 22.9216476329\n",
      "Iteration 5979 => Loss: 22.9215637523\n",
      "Iteration 5980 => Loss: 22.9214799609\n",
      "Iteration 5981 => Loss: 22.9213962585\n",
      "Iteration 5982 => Loss: 22.9213126451\n",
      "Iteration 5983 => Loss: 22.9212291206\n",
      "Iteration 5984 => Loss: 22.9211456848\n",
      "Iteration 5985 => Loss: 22.9210623378\n",
      "Iteration 5986 => Loss: 22.9209790793\n",
      "Iteration 5987 => Loss: 22.9208959094\n",
      "Iteration 5988 => Loss: 22.9208128278\n",
      "Iteration 5989 => Loss: 22.9207298346\n",
      "Iteration 5990 => Loss: 22.9206469296\n",
      "Iteration 5991 => Loss: 22.9205641127\n",
      "Iteration 5992 => Loss: 22.9204813839\n",
      "Iteration 5993 => Loss: 22.9203987430\n",
      "Iteration 5994 => Loss: 22.9203161899\n",
      "Iteration 5995 => Loss: 22.9202337246\n",
      "Iteration 5996 => Loss: 22.9201513469\n",
      "Iteration 5997 => Loss: 22.9200690569\n",
      "Iteration 5998 => Loss: 22.9199868542\n",
      "Iteration 5999 => Loss: 22.9199047390\n",
      "Iteration 6000 => Loss: 22.9198227111\n",
      "Iteration 6001 => Loss: 22.9197407703\n",
      "Iteration 6002 => Loss: 22.9196589166\n",
      "Iteration 6003 => Loss: 22.9195771500\n",
      "Iteration 6004 => Loss: 22.9194954703\n",
      "Iteration 6005 => Loss: 22.9194138774\n",
      "Iteration 6006 => Loss: 22.9193323712\n",
      "Iteration 6007 => Loss: 22.9192509517\n",
      "Iteration 6008 => Loss: 22.9191696187\n",
      "Iteration 6009 => Loss: 22.9190883721\n",
      "Iteration 6010 => Loss: 22.9190072120\n",
      "Iteration 6011 => Loss: 22.9189261381\n",
      "Iteration 6012 => Loss: 22.9188451504\n",
      "Iteration 6013 => Loss: 22.9187642487\n",
      "Iteration 6014 => Loss: 22.9186834331\n",
      "Iteration 6015 => Loss: 22.9186027034\n",
      "Iteration 6016 => Loss: 22.9185220595\n",
      "Iteration 6017 => Loss: 22.9184415013\n",
      "Iteration 6018 => Loss: 22.9183610287\n",
      "Iteration 6019 => Loss: 22.9182806417\n",
      "Iteration 6020 => Loss: 22.9182003401\n",
      "Iteration 6021 => Loss: 22.9181201239\n",
      "Iteration 6022 => Loss: 22.9180399930\n",
      "Iteration 6023 => Loss: 22.9179599472\n",
      "Iteration 6024 => Loss: 22.9178799865\n",
      "Iteration 6025 => Loss: 22.9178001109\n",
      "Iteration 6026 => Loss: 22.9177203201\n",
      "Iteration 6027 => Loss: 22.9176406141\n",
      "Iteration 6028 => Loss: 22.9175609929\n",
      "Iteration 6029 => Loss: 22.9174814563\n",
      "Iteration 6030 => Loss: 22.9174020042\n",
      "Iteration 6031 => Loss: 22.9173226366\n",
      "Iteration 6032 => Loss: 22.9172433534\n",
      "Iteration 6033 => Loss: 22.9171641545\n",
      "Iteration 6034 => Loss: 22.9170850397\n",
      "Iteration 6035 => Loss: 22.9170060090\n",
      "Iteration 6036 => Loss: 22.9169270624\n",
      "Iteration 6037 => Loss: 22.9168481996\n",
      "Iteration 6038 => Loss: 22.9167694207\n",
      "Iteration 6039 => Loss: 22.9166907255\n",
      "Iteration 6040 => Loss: 22.9166121140\n",
      "Iteration 6041 => Loss: 22.9165335861\n",
      "Iteration 6042 => Loss: 22.9164551416\n",
      "Iteration 6043 => Loss: 22.9163767805\n",
      "Iteration 6044 => Loss: 22.9162985027\n",
      "Iteration 6045 => Loss: 22.9162203081\n",
      "Iteration 6046 => Loss: 22.9161421966\n",
      "Iteration 6047 => Loss: 22.9160641682\n",
      "Iteration 6048 => Loss: 22.9159862227\n",
      "Iteration 6049 => Loss: 22.9159083600\n",
      "Iteration 6050 => Loss: 22.9158305801\n",
      "Iteration 6051 => Loss: 22.9157528829\n",
      "Iteration 6052 => Loss: 22.9156752683\n",
      "Iteration 6053 => Loss: 22.9155977362\n",
      "Iteration 6054 => Loss: 22.9155202865\n",
      "Iteration 6055 => Loss: 22.9154429191\n",
      "Iteration 6056 => Loss: 22.9153656340\n",
      "Iteration 6057 => Loss: 22.9152884310\n",
      "Iteration 6058 => Loss: 22.9152113101\n",
      "Iteration 6059 => Loss: 22.9151342712\n",
      "Iteration 6060 => Loss: 22.9150573141\n",
      "Iteration 6061 => Loss: 22.9149804389\n",
      "Iteration 6062 => Loss: 22.9149036454\n",
      "Iteration 6063 => Loss: 22.9148269335\n",
      "Iteration 6064 => Loss: 22.9147503031\n",
      "Iteration 6065 => Loss: 22.9146737542\n",
      "Iteration 6066 => Loss: 22.9145972867\n",
      "Iteration 6067 => Loss: 22.9145209005\n",
      "Iteration 6068 => Loss: 22.9144445954\n",
      "Iteration 6069 => Loss: 22.9143683715\n",
      "Iteration 6070 => Loss: 22.9142922286\n",
      "Iteration 6071 => Loss: 22.9142161666\n",
      "Iteration 6072 => Loss: 22.9141401855\n",
      "Iteration 6073 => Loss: 22.9140642852\n",
      "Iteration 6074 => Loss: 22.9139884655\n",
      "Iteration 6075 => Loss: 22.9139127264\n",
      "Iteration 6076 => Loss: 22.9138370678\n",
      "Iteration 6077 => Loss: 22.9137614897\n",
      "Iteration 6078 => Loss: 22.9136859919\n",
      "Iteration 6079 => Loss: 22.9136105743\n",
      "Iteration 6080 => Loss: 22.9135352370\n",
      "Iteration 6081 => Loss: 22.9134599797\n",
      "Iteration 6082 => Loss: 22.9133848023\n",
      "Iteration 6083 => Loss: 22.9133097049\n",
      "Iteration 6084 => Loss: 22.9132346874\n",
      "Iteration 6085 => Loss: 22.9131597496\n",
      "Iteration 6086 => Loss: 22.9130848914\n",
      "Iteration 6087 => Loss: 22.9130101128\n",
      "Iteration 6088 => Loss: 22.9129354137\n",
      "Iteration 6089 => Loss: 22.9128607940\n",
      "Iteration 6090 => Loss: 22.9127862536\n",
      "Iteration 6091 => Loss: 22.9127117924\n",
      "Iteration 6092 => Loss: 22.9126374104\n",
      "Iteration 6093 => Loss: 22.9125631075\n",
      "Iteration 6094 => Loss: 22.9124888836\n",
      "Iteration 6095 => Loss: 22.9124147385\n",
      "Iteration 6096 => Loss: 22.9123406723\n",
      "Iteration 6097 => Loss: 22.9122666848\n",
      "Iteration 6098 => Loss: 22.9121927759\n",
      "Iteration 6099 => Loss: 22.9121189456\n",
      "Iteration 6100 => Loss: 22.9120451938\n",
      "Iteration 6101 => Loss: 22.9119715204\n",
      "Iteration 6102 => Loss: 22.9118979253\n",
      "Iteration 6103 => Loss: 22.9118244084\n",
      "Iteration 6104 => Loss: 22.9117509697\n",
      "Iteration 6105 => Loss: 22.9116776090\n",
      "Iteration 6106 => Loss: 22.9116043263\n",
      "Iteration 6107 => Loss: 22.9115311215\n",
      "Iteration 6108 => Loss: 22.9114579946\n",
      "Iteration 6109 => Loss: 22.9113849453\n",
      "Iteration 6110 => Loss: 22.9113119737\n",
      "Iteration 6111 => Loss: 22.9112390797\n",
      "Iteration 6112 => Loss: 22.9111662632\n",
      "Iteration 6113 => Loss: 22.9110935240\n",
      "Iteration 6114 => Loss: 22.9110208622\n",
      "Iteration 6115 => Loss: 22.9109482776\n",
      "Iteration 6116 => Loss: 22.9108757702\n",
      "Iteration 6117 => Loss: 22.9108033399\n",
      "Iteration 6118 => Loss: 22.9107309865\n",
      "Iteration 6119 => Loss: 22.9106587101\n",
      "Iteration 6120 => Loss: 22.9105865105\n",
      "Iteration 6121 => Loss: 22.9105143876\n",
      "Iteration 6122 => Loss: 22.9104423414\n",
      "Iteration 6123 => Loss: 22.9103703718\n",
      "Iteration 6124 => Loss: 22.9102984786\n",
      "Iteration 6125 => Loss: 22.9102266619\n",
      "Iteration 6126 => Loss: 22.9101549216\n",
      "Iteration 6127 => Loss: 22.9100832575\n",
      "Iteration 6128 => Loss: 22.9100116696\n",
      "Iteration 6129 => Loss: 22.9099401577\n",
      "Iteration 6130 => Loss: 22.9098687219\n",
      "Iteration 6131 => Loss: 22.9097973621\n",
      "Iteration 6132 => Loss: 22.9097260780\n",
      "Iteration 6133 => Loss: 22.9096548698\n",
      "Iteration 6134 => Loss: 22.9095837372\n",
      "Iteration 6135 => Loss: 22.9095126803\n",
      "Iteration 6136 => Loss: 22.9094416989\n",
      "Iteration 6137 => Loss: 22.9093707929\n",
      "Iteration 6138 => Loss: 22.9092999623\n",
      "Iteration 6139 => Loss: 22.9092292070\n",
      "Iteration 6140 => Loss: 22.9091585269\n",
      "Iteration 6141 => Loss: 22.9090879220\n",
      "Iteration 6142 => Loss: 22.9090173921\n",
      "Iteration 6143 => Loss: 22.9089469372\n",
      "Iteration 6144 => Loss: 22.9088765571\n",
      "Iteration 6145 => Loss: 22.9088062519\n",
      "Iteration 6146 => Loss: 22.9087360214\n",
      "Iteration 6147 => Loss: 22.9086658656\n",
      "Iteration 6148 => Loss: 22.9085957843\n",
      "Iteration 6149 => Loss: 22.9085257775\n",
      "Iteration 6150 => Loss: 22.9084558452\n",
      "Iteration 6151 => Loss: 22.9083859872\n",
      "Iteration 6152 => Loss: 22.9083162034\n",
      "Iteration 6153 => Loss: 22.9082464938\n",
      "Iteration 6154 => Loss: 22.9081768583\n",
      "Iteration 6155 => Loss: 22.9081072969\n",
      "Iteration 6156 => Loss: 22.9080378094\n",
      "Iteration 6157 => Loss: 22.9079683957\n",
      "Iteration 6158 => Loss: 22.9078990558\n",
      "Iteration 6159 => Loss: 22.9078297897\n",
      "Iteration 6160 => Loss: 22.9077605971\n",
      "Iteration 6161 => Loss: 22.9076914781\n",
      "Iteration 6162 => Loss: 22.9076224326\n",
      "Iteration 6163 => Loss: 22.9075534605\n",
      "Iteration 6164 => Loss: 22.9074845617\n",
      "Iteration 6165 => Loss: 22.9074157362\n",
      "Iteration 6166 => Loss: 22.9073469837\n",
      "Iteration 6167 => Loss: 22.9072783044\n",
      "Iteration 6168 => Loss: 22.9072096981\n",
      "Iteration 6169 => Loss: 22.9071411647\n",
      "Iteration 6170 => Loss: 22.9070727042\n",
      "Iteration 6171 => Loss: 22.9070043164\n",
      "Iteration 6172 => Loss: 22.9069360013\n",
      "Iteration 6173 => Loss: 22.9068677589\n",
      "Iteration 6174 => Loss: 22.9067995890\n",
      "Iteration 6175 => Loss: 22.9067314915\n",
      "Iteration 6176 => Loss: 22.9066634664\n",
      "Iteration 6177 => Loss: 22.9065955137\n",
      "Iteration 6178 => Loss: 22.9065276332\n",
      "Iteration 6179 => Loss: 22.9064598248\n",
      "Iteration 6180 => Loss: 22.9063920885\n",
      "Iteration 6181 => Loss: 22.9063244242\n",
      "Iteration 6182 => Loss: 22.9062568318\n",
      "Iteration 6183 => Loss: 22.9061893113\n",
      "Iteration 6184 => Loss: 22.9061218626\n",
      "Iteration 6185 => Loss: 22.9060544856\n",
      "Iteration 6186 => Loss: 22.9059871801\n",
      "Iteration 6187 => Loss: 22.9059199462\n",
      "Iteration 6188 => Loss: 22.9058527838\n",
      "Iteration 6189 => Loss: 22.9057856928\n",
      "Iteration 6190 => Loss: 22.9057186731\n",
      "Iteration 6191 => Loss: 22.9056517247\n",
      "Iteration 6192 => Loss: 22.9055848474\n",
      "Iteration 6193 => Loss: 22.9055180411\n",
      "Iteration 6194 => Loss: 22.9054513060\n",
      "Iteration 6195 => Loss: 22.9053846417\n",
      "Iteration 6196 => Loss: 22.9053180483\n",
      "Iteration 6197 => Loss: 22.9052515257\n",
      "Iteration 6198 => Loss: 22.9051850738\n",
      "Iteration 6199 => Loss: 22.9051186925\n",
      "Iteration 6200 => Loss: 22.9050523818\n",
      "Iteration 6201 => Loss: 22.9049861416\n",
      "Iteration 6202 => Loss: 22.9049199718\n",
      "Iteration 6203 => Loss: 22.9048538724\n",
      "Iteration 6204 => Loss: 22.9047878432\n",
      "Iteration 6205 => Loss: 22.9047218842\n",
      "Iteration 6206 => Loss: 22.9046559953\n",
      "Iteration 6207 => Loss: 22.9045901764\n",
      "Iteration 6208 => Loss: 22.9045244275\n",
      "Iteration 6209 => Loss: 22.9044587485\n",
      "Iteration 6210 => Loss: 22.9043931393\n",
      "Iteration 6211 => Loss: 22.9043275999\n",
      "Iteration 6212 => Loss: 22.9042621301\n",
      "Iteration 6213 => Loss: 22.9041967299\n",
      "Iteration 6214 => Loss: 22.9041313992\n",
      "Iteration 6215 => Loss: 22.9040661380\n",
      "Iteration 6216 => Loss: 22.9040009462\n",
      "Iteration 6217 => Loss: 22.9039358236\n",
      "Iteration 6218 => Loss: 22.9038707703\n",
      "Iteration 6219 => Loss: 22.9038057861\n",
      "Iteration 6220 => Loss: 22.9037408710\n",
      "Iteration 6221 => Loss: 22.9036760249\n",
      "Iteration 6222 => Loss: 22.9036112477\n",
      "Iteration 6223 => Loss: 22.9035465394\n",
      "Iteration 6224 => Loss: 22.9034818999\n",
      "Iteration 6225 => Loss: 22.9034173291\n",
      "Iteration 6226 => Loss: 22.9033528269\n",
      "Iteration 6227 => Loss: 22.9032883933\n",
      "Iteration 6228 => Loss: 22.9032240281\n",
      "Iteration 6229 => Loss: 22.9031597314\n",
      "Iteration 6230 => Loss: 22.9030955031\n",
      "Iteration 6231 => Loss: 22.9030313430\n",
      "Iteration 6232 => Loss: 22.9029672511\n",
      "Iteration 6233 => Loss: 22.9029032273\n",
      "Iteration 6234 => Loss: 22.9028392716\n",
      "Iteration 6235 => Loss: 22.9027753839\n",
      "Iteration 6236 => Loss: 22.9027115641\n",
      "Iteration 6237 => Loss: 22.9026478121\n",
      "Iteration 6238 => Loss: 22.9025841279\n",
      "Iteration 6239 => Loss: 22.9025205114\n",
      "Iteration 6240 => Loss: 22.9024569625\n",
      "Iteration 6241 => Loss: 22.9023934812\n",
      "Iteration 6242 => Loss: 22.9023300674\n",
      "Iteration 6243 => Loss: 22.9022667209\n",
      "Iteration 6244 => Loss: 22.9022034418\n",
      "Iteration 6245 => Loss: 22.9021402300\n",
      "Iteration 6246 => Loss: 22.9020770853\n",
      "Iteration 6247 => Loss: 22.9020140078\n",
      "Iteration 6248 => Loss: 22.9019509973\n",
      "Iteration 6249 => Loss: 22.9018880538\n",
      "Iteration 6250 => Loss: 22.9018251772\n",
      "Iteration 6251 => Loss: 22.9017623674\n",
      "Iteration 6252 => Loss: 22.9016996244\n",
      "Iteration 6253 => Loss: 22.9016369481\n",
      "Iteration 6254 => Loss: 22.9015743385\n",
      "Iteration 6255 => Loss: 22.9015117953\n",
      "Iteration 6256 => Loss: 22.9014493187\n",
      "Iteration 6257 => Loss: 22.9013869085\n",
      "Iteration 6258 => Loss: 22.9013245646\n",
      "Iteration 6259 => Loss: 22.9012622870\n",
      "Iteration 6260 => Loss: 22.9012000755\n",
      "Iteration 6261 => Loss: 22.9011379303\n",
      "Iteration 6262 => Loss: 22.9010758510\n",
      "Iteration 6263 => Loss: 22.9010138378\n",
      "Iteration 6264 => Loss: 22.9009518905\n",
      "Iteration 6265 => Loss: 22.9008900090\n",
      "Iteration 6266 => Loss: 22.9008281933\n",
      "Iteration 6267 => Loss: 22.9007664433\n",
      "Iteration 6268 => Loss: 22.9007047590\n",
      "Iteration 6269 => Loss: 22.9006431402\n",
      "Iteration 6270 => Loss: 22.9005815869\n",
      "Iteration 6271 => Loss: 22.9005200991\n",
      "Iteration 6272 => Loss: 22.9004586766\n",
      "Iteration 6273 => Loss: 22.9003973194\n",
      "Iteration 6274 => Loss: 22.9003360274\n",
      "Iteration 6275 => Loss: 22.9002748006\n",
      "Iteration 6276 => Loss: 22.9002136388\n",
      "Iteration 6277 => Loss: 22.9001525421\n",
      "Iteration 6278 => Loss: 22.9000915103\n",
      "Iteration 6279 => Loss: 22.9000305434\n",
      "Iteration 6280 => Loss: 22.8999696413\n",
      "Iteration 6281 => Loss: 22.8999088039\n",
      "Iteration 6282 => Loss: 22.8998480313\n",
      "Iteration 6283 => Loss: 22.8997873232\n",
      "Iteration 6284 => Loss: 22.8997266796\n",
      "Iteration 6285 => Loss: 22.8996661005\n",
      "Iteration 6286 => Loss: 22.8996055858\n",
      "Iteration 6287 => Loss: 22.8995451354\n",
      "Iteration 6288 => Loss: 22.8994847493\n",
      "Iteration 6289 => Loss: 22.8994244274\n",
      "Iteration 6290 => Loss: 22.8993641695\n",
      "Iteration 6291 => Loss: 22.8993039758\n",
      "Iteration 6292 => Loss: 22.8992438460\n",
      "Iteration 6293 => Loss: 22.8991837801\n",
      "Iteration 6294 => Loss: 22.8991237781\n",
      "Iteration 6295 => Loss: 22.8990638399\n",
      "Iteration 6296 => Loss: 22.8990039654\n",
      "Iteration 6297 => Loss: 22.8989441545\n",
      "Iteration 6298 => Loss: 22.8988844072\n",
      "Iteration 6299 => Loss: 22.8988247234\n",
      "Iteration 6300 => Loss: 22.8987651031\n",
      "Iteration 6301 => Loss: 22.8987055461\n",
      "Iteration 6302 => Loss: 22.8986460525\n",
      "Iteration 6303 => Loss: 22.8985866221\n",
      "Iteration 6304 => Loss: 22.8985272548\n",
      "Iteration 6305 => Loss: 22.8984679507\n",
      "Iteration 6306 => Loss: 22.8984087096\n",
      "Iteration 6307 => Loss: 22.8983495315\n",
      "Iteration 6308 => Loss: 22.8982904162\n",
      "Iteration 6309 => Loss: 22.8982313639\n",
      "Iteration 6310 => Loss: 22.8981723742\n",
      "Iteration 6311 => Loss: 22.8981134473\n",
      "Iteration 6312 => Loss: 22.8980545831\n",
      "Iteration 6313 => Loss: 22.8979957814\n",
      "Iteration 6314 => Loss: 22.8979370422\n",
      "Iteration 6315 => Loss: 22.8978783654\n",
      "Iteration 6316 => Loss: 22.8978197510\n",
      "Iteration 6317 => Loss: 22.8977611990\n",
      "Iteration 6318 => Loss: 22.8977027091\n",
      "Iteration 6319 => Loss: 22.8976442815\n",
      "Iteration 6320 => Loss: 22.8975859159\n",
      "Iteration 6321 => Loss: 22.8975276124\n",
      "Iteration 6322 => Loss: 22.8974693709\n",
      "Iteration 6323 => Loss: 22.8974111912\n",
      "Iteration 6324 => Loss: 22.8973530735\n",
      "Iteration 6325 => Loss: 22.8972950174\n",
      "Iteration 6326 => Loss: 22.8972370231\n",
      "Iteration 6327 => Loss: 22.8971790905\n",
      "Iteration 6328 => Loss: 22.8971212194\n",
      "Iteration 6329 => Loss: 22.8970634099\n",
      "Iteration 6330 => Loss: 22.8970056618\n",
      "Iteration 6331 => Loss: 22.8969479751\n",
      "Iteration 6332 => Loss: 22.8968903497\n",
      "Iteration 6333 => Loss: 22.8968327855\n",
      "Iteration 6334 => Loss: 22.8967752826\n",
      "Iteration 6335 => Loss: 22.8967178407\n",
      "Iteration 6336 => Loss: 22.8966604600\n",
      "Iteration 6337 => Loss: 22.8966031402\n",
      "Iteration 6338 => Loss: 22.8965458814\n",
      "Iteration 6339 => Loss: 22.8964886834\n",
      "Iteration 6340 => Loss: 22.8964315462\n",
      "Iteration 6341 => Loss: 22.8963744698\n",
      "Iteration 6342 => Loss: 22.8963174540\n",
      "Iteration 6343 => Loss: 22.8962604988\n",
      "Iteration 6344 => Loss: 22.8962036042\n",
      "Iteration 6345 => Loss: 22.8961467700\n",
      "Iteration 6346 => Loss: 22.8960899963\n",
      "Iteration 6347 => Loss: 22.8960332829\n",
      "Iteration 6348 => Loss: 22.8959766298\n",
      "Iteration 6349 => Loss: 22.8959200370\n",
      "Iteration 6350 => Loss: 22.8958635042\n",
      "Iteration 6351 => Loss: 22.8958070316\n",
      "Iteration 6352 => Loss: 22.8957506190\n",
      "Iteration 6353 => Loss: 22.8956942664\n",
      "Iteration 6354 => Loss: 22.8956379736\n",
      "Iteration 6355 => Loss: 22.8955817408\n",
      "Iteration 6356 => Loss: 22.8955255676\n",
      "Iteration 6357 => Loss: 22.8954694542\n",
      "Iteration 6358 => Loss: 22.8954134005\n",
      "Iteration 6359 => Loss: 22.8953574063\n",
      "Iteration 6360 => Loss: 22.8953014716\n",
      "Iteration 6361 => Loss: 22.8952455964\n",
      "Iteration 6362 => Loss: 22.8951897806\n",
      "Iteration 6363 => Loss: 22.8951340242\n",
      "Iteration 6364 => Loss: 22.8950783270\n",
      "Iteration 6365 => Loss: 22.8950226890\n",
      "Iteration 6366 => Loss: 22.8949671101\n",
      "Iteration 6367 => Loss: 22.8949115903\n",
      "Iteration 6368 => Loss: 22.8948561296\n",
      "Iteration 6369 => Loss: 22.8948007277\n",
      "Iteration 6370 => Loss: 22.8947453848\n",
      "Iteration 6371 => Loss: 22.8946901007\n",
      "Iteration 6372 => Loss: 22.8946348754\n",
      "Iteration 6373 => Loss: 22.8945797088\n",
      "Iteration 6374 => Loss: 22.8945246008\n",
      "Iteration 6375 => Loss: 22.8944695514\n",
      "Iteration 6376 => Loss: 22.8944145605\n",
      "Iteration 6377 => Loss: 22.8943596281\n",
      "Iteration 6378 => Loss: 22.8943047541\n",
      "Iteration 6379 => Loss: 22.8942499384\n",
      "Iteration 6380 => Loss: 22.8941951809\n",
      "Iteration 6381 => Loss: 22.8941404817\n",
      "Iteration 6382 => Loss: 22.8940858406\n",
      "Iteration 6383 => Loss: 22.8940312576\n",
      "Iteration 6384 => Loss: 22.8939767326\n",
      "Iteration 6385 => Loss: 22.8939222656\n",
      "Iteration 6386 => Loss: 22.8938678564\n",
      "Iteration 6387 => Loss: 22.8938135051\n",
      "Iteration 6388 => Loss: 22.8937592116\n",
      "Iteration 6389 => Loss: 22.8937049758\n",
      "Iteration 6390 => Loss: 22.8936507976\n",
      "Iteration 6391 => Loss: 22.8935966771\n",
      "Iteration 6392 => Loss: 22.8935426140\n",
      "Iteration 6393 => Loss: 22.8934886085\n",
      "Iteration 6394 => Loss: 22.8934346603\n",
      "Iteration 6395 => Loss: 22.8933807695\n",
      "Iteration 6396 => Loss: 22.8933269360\n",
      "Iteration 6397 => Loss: 22.8932731597\n",
      "Iteration 6398 => Loss: 22.8932194405\n",
      "Iteration 6399 => Loss: 22.8931657785\n",
      "Iteration 6400 => Loss: 22.8931121735\n",
      "Iteration 6401 => Loss: 22.8930586254\n",
      "Iteration 6402 => Loss: 22.8930051343\n",
      "Iteration 6403 => Loss: 22.8929517001\n",
      "Iteration 6404 => Loss: 22.8928983227\n",
      "Iteration 6405 => Loss: 22.8928450020\n",
      "Iteration 6406 => Loss: 22.8927917379\n",
      "Iteration 6407 => Loss: 22.8927385305\n",
      "Iteration 6408 => Loss: 22.8926853797\n",
      "Iteration 6409 => Loss: 22.8926322853\n",
      "Iteration 6410 => Loss: 22.8925792474\n",
      "Iteration 6411 => Loss: 22.8925262659\n",
      "Iteration 6412 => Loss: 22.8924733407\n",
      "Iteration 6413 => Loss: 22.8924204717\n",
      "Iteration 6414 => Loss: 22.8923676590\n",
      "Iteration 6415 => Loss: 22.8923149023\n",
      "Iteration 6416 => Loss: 22.8922622018\n",
      "Iteration 6417 => Loss: 22.8922095573\n",
      "Iteration 6418 => Loss: 22.8921569687\n",
      "Iteration 6419 => Loss: 22.8921044361\n",
      "Iteration 6420 => Loss: 22.8920519593\n",
      "Iteration 6421 => Loss: 22.8919995382\n",
      "Iteration 6422 => Loss: 22.8919471729\n",
      "Iteration 6423 => Loss: 22.8918948633\n",
      "Iteration 6424 => Loss: 22.8918426092\n",
      "Iteration 6425 => Loss: 22.8917904107\n",
      "Iteration 6426 => Loss: 22.8917382677\n",
      "Iteration 6427 => Loss: 22.8916861801\n",
      "Iteration 6428 => Loss: 22.8916341479\n",
      "Iteration 6429 => Loss: 22.8915821710\n",
      "Iteration 6430 => Loss: 22.8915302493\n",
      "Iteration 6431 => Loss: 22.8914783828\n",
      "Iteration 6432 => Loss: 22.8914265715\n",
      "Iteration 6433 => Loss: 22.8913748152\n",
      "Iteration 6434 => Loss: 22.8913231140\n",
      "Iteration 6435 => Loss: 22.8912714677\n",
      "Iteration 6436 => Loss: 22.8912198763\n",
      "Iteration 6437 => Loss: 22.8911683398\n",
      "Iteration 6438 => Loss: 22.8911168580\n",
      "Iteration 6439 => Loss: 22.8910654310\n",
      "Iteration 6440 => Loss: 22.8910140586\n",
      "Iteration 6441 => Loss: 22.8909627408\n",
      "Iteration 6442 => Loss: 22.8909114776\n",
      "Iteration 6443 => Loss: 22.8908602689\n",
      "Iteration 6444 => Loss: 22.8908091146\n",
      "Iteration 6445 => Loss: 22.8907580147\n",
      "Iteration 6446 => Loss: 22.8907069691\n",
      "Iteration 6447 => Loss: 22.8906559777\n",
      "Iteration 6448 => Loss: 22.8906050406\n",
      "Iteration 6449 => Loss: 22.8905541576\n",
      "Iteration 6450 => Loss: 22.8905033287\n",
      "Iteration 6451 => Loss: 22.8904525538\n",
      "Iteration 6452 => Loss: 22.8904018329\n",
      "Iteration 6453 => Loss: 22.8903511659\n",
      "Iteration 6454 => Loss: 22.8903005528\n",
      "Iteration 6455 => Loss: 22.8902499935\n",
      "Iteration 6456 => Loss: 22.8901994879\n",
      "Iteration 6457 => Loss: 22.8901490360\n",
      "Iteration 6458 => Loss: 22.8900986377\n",
      "Iteration 6459 => Loss: 22.8900482930\n",
      "Iteration 6460 => Loss: 22.8899980018\n",
      "Iteration 6461 => Loss: 22.8899477641\n",
      "Iteration 6462 => Loss: 22.8898975798\n",
      "Iteration 6463 => Loss: 22.8898474488\n",
      "Iteration 6464 => Loss: 22.8897973711\n",
      "Iteration 6465 => Loss: 22.8897473467\n",
      "Iteration 6466 => Loss: 22.8896973754\n",
      "Iteration 6467 => Loss: 22.8896474572\n",
      "Iteration 6468 => Loss: 22.8895975921\n",
      "Iteration 6469 => Loss: 22.8895477800\n",
      "Iteration 6470 => Loss: 22.8894980209\n",
      "Iteration 6471 => Loss: 22.8894483146\n",
      "Iteration 6472 => Loss: 22.8893986612\n",
      "Iteration 6473 => Loss: 22.8893490606\n",
      "Iteration 6474 => Loss: 22.8892995127\n",
      "Iteration 6475 => Loss: 22.8892500174\n",
      "Iteration 6476 => Loss: 22.8892005748\n",
      "Iteration 6477 => Loss: 22.8891511847\n",
      "Iteration 6478 => Loss: 22.8891018471\n",
      "Iteration 6479 => Loss: 22.8890525620\n",
      "Iteration 6480 => Loss: 22.8890033293\n",
      "Iteration 6481 => Loss: 22.8889541489\n",
      "Iteration 6482 => Loss: 22.8889050207\n",
      "Iteration 6483 => Loss: 22.8888559448\n",
      "Iteration 6484 => Loss: 22.8888069211\n",
      "Iteration 6485 => Loss: 22.8887579495\n",
      "Iteration 6486 => Loss: 22.8887090299\n",
      "Iteration 6487 => Loss: 22.8886601623\n",
      "Iteration 6488 => Loss: 22.8886113467\n",
      "Iteration 6489 => Loss: 22.8885625830\n",
      "Iteration 6490 => Loss: 22.8885138711\n",
      "Iteration 6491 => Loss: 22.8884652109\n",
      "Iteration 6492 => Loss: 22.8884166025\n",
      "Iteration 6493 => Loss: 22.8883680458\n",
      "Iteration 6494 => Loss: 22.8883195407\n",
      "Iteration 6495 => Loss: 22.8882710871\n",
      "Iteration 6496 => Loss: 22.8882226851\n",
      "Iteration 6497 => Loss: 22.8881743345\n",
      "Iteration 6498 => Loss: 22.8881260353\n",
      "Iteration 6499 => Loss: 22.8880777874\n",
      "Iteration 6500 => Loss: 22.8880295908\n",
      "Iteration 6501 => Loss: 22.8879814455\n",
      "Iteration 6502 => Loss: 22.8879333513\n",
      "Iteration 6503 => Loss: 22.8878853083\n",
      "Iteration 6504 => Loss: 22.8878373163\n",
      "Iteration 6505 => Loss: 22.8877893754\n",
      "Iteration 6506 => Loss: 22.8877414854\n",
      "Iteration 6507 => Loss: 22.8876936463\n",
      "Iteration 6508 => Loss: 22.8876458580\n",
      "Iteration 6509 => Loss: 22.8875981206\n",
      "Iteration 6510 => Loss: 22.8875504339\n",
      "Iteration 6511 => Loss: 22.8875027979\n",
      "Iteration 6512 => Loss: 22.8874552125\n",
      "Iteration 6513 => Loss: 22.8874076777\n",
      "Iteration 6514 => Loss: 22.8873601934\n",
      "Iteration 6515 => Loss: 22.8873127597\n",
      "Iteration 6516 => Loss: 22.8872653763\n",
      "Iteration 6517 => Loss: 22.8872180433\n",
      "Iteration 6518 => Loss: 22.8871707606\n",
      "Iteration 6519 => Loss: 22.8871235282\n",
      "Iteration 6520 => Loss: 22.8870763460\n",
      "Iteration 6521 => Loss: 22.8870292139\n",
      "Iteration 6522 => Loss: 22.8869821319\n",
      "Iteration 6523 => Loss: 22.8869351000\n",
      "Iteration 6524 => Loss: 22.8868881181\n",
      "Iteration 6525 => Loss: 22.8868411861\n",
      "Iteration 6526 => Loss: 22.8867943040\n",
      "Iteration 6527 => Loss: 22.8867474718\n",
      "Iteration 6528 => Loss: 22.8867006893\n",
      "Iteration 6529 => Loss: 22.8866539565\n",
      "Iteration 6530 => Loss: 22.8866072735\n",
      "Iteration 6531 => Loss: 22.8865606400\n",
      "Iteration 6532 => Loss: 22.8865140561\n",
      "Iteration 6533 => Loss: 22.8864675218\n",
      "Iteration 6534 => Loss: 22.8864210369\n",
      "Iteration 6535 => Loss: 22.8863746014\n",
      "Iteration 6536 => Loss: 22.8863282153\n",
      "Iteration 6537 => Loss: 22.8862818784\n",
      "Iteration 6538 => Loss: 22.8862355909\n",
      "Iteration 6539 => Loss: 22.8861893525\n",
      "Iteration 6540 => Loss: 22.8861431633\n",
      "Iteration 6541 => Loss: 22.8860970232\n",
      "Iteration 6542 => Loss: 22.8860509321\n",
      "Iteration 6543 => Loss: 22.8860048901\n",
      "Iteration 6544 => Loss: 22.8859588969\n",
      "Iteration 6545 => Loss: 22.8859129527\n",
      "Iteration 6546 => Loss: 22.8858670573\n",
      "Iteration 6547 => Loss: 22.8858212107\n",
      "Iteration 6548 => Loss: 22.8857754128\n",
      "Iteration 6549 => Loss: 22.8857296636\n",
      "Iteration 6550 => Loss: 22.8856839630\n",
      "Iteration 6551 => Loss: 22.8856383110\n",
      "Iteration 6552 => Loss: 22.8855927076\n",
      "Iteration 6553 => Loss: 22.8855471526\n",
      "Iteration 6554 => Loss: 22.8855016460\n",
      "Iteration 6555 => Loss: 22.8854561878\n",
      "Iteration 6556 => Loss: 22.8854107780\n",
      "Iteration 6557 => Loss: 22.8853654164\n",
      "Iteration 6558 => Loss: 22.8853201030\n",
      "Iteration 6559 => Loss: 22.8852748378\n",
      "Iteration 6560 => Loss: 22.8852296207\n",
      "Iteration 6561 => Loss: 22.8851844516\n",
      "Iteration 6562 => Loss: 22.8851393306\n",
      "Iteration 6563 => Loss: 22.8850942575\n",
      "Iteration 6564 => Loss: 22.8850492324\n",
      "Iteration 6565 => Loss: 22.8850042551\n",
      "Iteration 6566 => Loss: 22.8849593256\n",
      "Iteration 6567 => Loss: 22.8849144439\n",
      "Iteration 6568 => Loss: 22.8848696099\n",
      "Iteration 6569 => Loss: 22.8848248236\n",
      "Iteration 6570 => Loss: 22.8847800848\n",
      "Iteration 6571 => Loss: 22.8847353936\n",
      "Iteration 6572 => Loss: 22.8846907499\n",
      "Iteration 6573 => Loss: 22.8846461537\n",
      "Iteration 6574 => Loss: 22.8846016049\n",
      "Iteration 6575 => Loss: 22.8845571034\n",
      "Iteration 6576 => Loss: 22.8845126493\n",
      "Iteration 6577 => Loss: 22.8844682424\n",
      "Iteration 6578 => Loss: 22.8844238827\n",
      "Iteration 6579 => Loss: 22.8843795701\n",
      "Iteration 6580 => Loss: 22.8843353047\n",
      "Iteration 6581 => Loss: 22.8842910863\n",
      "Iteration 6582 => Loss: 22.8842469149\n",
      "Iteration 6583 => Loss: 22.8842027904\n",
      "Iteration 6584 => Loss: 22.8841587129\n",
      "Iteration 6585 => Loss: 22.8841146822\n",
      "Iteration 6586 => Loss: 22.8840706983\n",
      "Iteration 6587 => Loss: 22.8840267612\n",
      "Iteration 6588 => Loss: 22.8839828708\n",
      "Iteration 6589 => Loss: 22.8839390270\n",
      "Iteration 6590 => Loss: 22.8838952299\n",
      "Iteration 6591 => Loss: 22.8838514792\n",
      "Iteration 6592 => Loss: 22.8838077751\n",
      "Iteration 6593 => Loss: 22.8837641175\n",
      "Iteration 6594 => Loss: 22.8837205063\n",
      "Iteration 6595 => Loss: 22.8836769414\n",
      "Iteration 6596 => Loss: 22.8836334228\n",
      "Iteration 6597 => Loss: 22.8835899505\n",
      "Iteration 6598 => Loss: 22.8835465244\n",
      "Iteration 6599 => Loss: 22.8835031445\n",
      "Iteration 6600 => Loss: 22.8834598106\n",
      "Iteration 6601 => Loss: 22.8834165229\n",
      "Iteration 6602 => Loss: 22.8833732811\n",
      "Iteration 6603 => Loss: 22.8833300853\n",
      "Iteration 6604 => Loss: 22.8832869355\n",
      "Iteration 6605 => Loss: 22.8832438315\n",
      "Iteration 6606 => Loss: 22.8832007733\n",
      "Iteration 6607 => Loss: 22.8831577609\n",
      "Iteration 6608 => Loss: 22.8831147942\n",
      "Iteration 6609 => Loss: 22.8830718732\n",
      "Iteration 6610 => Loss: 22.8830289978\n",
      "Iteration 6611 => Loss: 22.8829861680\n",
      "Iteration 6612 => Loss: 22.8829433837\n",
      "Iteration 6613 => Loss: 22.8829006448\n",
      "Iteration 6614 => Loss: 22.8828579515\n",
      "Iteration 6615 => Loss: 22.8828153035\n",
      "Iteration 6616 => Loss: 22.8827727008\n",
      "Iteration 6617 => Loss: 22.8827301434\n",
      "Iteration 6618 => Loss: 22.8826876313\n",
      "Iteration 6619 => Loss: 22.8826451643\n",
      "Iteration 6620 => Loss: 22.8826027425\n",
      "Iteration 6621 => Loss: 22.8825603658\n",
      "Iteration 6622 => Loss: 22.8825180341\n",
      "Iteration 6623 => Loss: 22.8824757474\n",
      "Iteration 6624 => Loss: 22.8824335057\n",
      "Iteration 6625 => Loss: 22.8823913089\n",
      "Iteration 6626 => Loss: 22.8823491569\n",
      "Iteration 6627 => Loss: 22.8823070498\n",
      "Iteration 6628 => Loss: 22.8822649874\n",
      "Iteration 6629 => Loss: 22.8822229697\n",
      "Iteration 6630 => Loss: 22.8821809966\n",
      "Iteration 6631 => Loss: 22.8821390682\n",
      "Iteration 6632 => Loss: 22.8820971844\n",
      "Iteration 6633 => Loss: 22.8820553451\n",
      "Iteration 6634 => Loss: 22.8820135502\n",
      "Iteration 6635 => Loss: 22.8819717998\n",
      "Iteration 6636 => Loss: 22.8819300938\n",
      "Iteration 6637 => Loss: 22.8818884320\n",
      "Iteration 6638 => Loss: 22.8818468146\n",
      "Iteration 6639 => Loss: 22.8818052414\n",
      "Iteration 6640 => Loss: 22.8817637124\n",
      "Iteration 6641 => Loss: 22.8817222276\n",
      "Iteration 6642 => Loss: 22.8816807868\n",
      "Iteration 6643 => Loss: 22.8816393901\n",
      "Iteration 6644 => Loss: 22.8815980375\n",
      "Iteration 6645 => Loss: 22.8815567287\n",
      "Iteration 6646 => Loss: 22.8815154639\n",
      "Iteration 6647 => Loss: 22.8814742429\n",
      "Iteration 6648 => Loss: 22.8814330658\n",
      "Iteration 6649 => Loss: 22.8813919324\n",
      "Iteration 6650 => Loss: 22.8813508427\n",
      "Iteration 6651 => Loss: 22.8813097968\n",
      "Iteration 6652 => Loss: 22.8812687944\n",
      "Iteration 6653 => Loss: 22.8812278357\n",
      "Iteration 6654 => Loss: 22.8811869204\n",
      "Iteration 6655 => Loss: 22.8811460487\n",
      "Iteration 6656 => Loss: 22.8811052204\n",
      "Iteration 6657 => Loss: 22.8810644355\n",
      "Iteration 6658 => Loss: 22.8810236940\n",
      "Iteration 6659 => Loss: 22.8809829958\n",
      "Iteration 6660 => Loss: 22.8809423408\n",
      "Iteration 6661 => Loss: 22.8809017291\n",
      "Iteration 6662 => Loss: 22.8808611605\n",
      "Iteration 6663 => Loss: 22.8808206350\n",
      "Iteration 6664 => Loss: 22.8807801527\n",
      "Iteration 6665 => Loss: 22.8807397133\n",
      "Iteration 6666 => Loss: 22.8806993170\n",
      "Iteration 6667 => Loss: 22.8806589635\n",
      "Iteration 6668 => Loss: 22.8806186530\n",
      "Iteration 6669 => Loss: 22.8805783853\n",
      "Iteration 6670 => Loss: 22.8805381605\n",
      "Iteration 6671 => Loss: 22.8804979784\n",
      "Iteration 6672 => Loss: 22.8804578390\n",
      "Iteration 6673 => Loss: 22.8804177422\n",
      "Iteration 6674 => Loss: 22.8803776881\n",
      "Iteration 6675 => Loss: 22.8803376766\n",
      "Iteration 6676 => Loss: 22.8802977076\n",
      "Iteration 6677 => Loss: 22.8802577811\n",
      "Iteration 6678 => Loss: 22.8802178970\n",
      "Iteration 6679 => Loss: 22.8801780553\n",
      "Iteration 6680 => Loss: 22.8801382560\n",
      "Iteration 6681 => Loss: 22.8800984990\n",
      "Iteration 6682 => Loss: 22.8800587842\n",
      "Iteration 6683 => Loss: 22.8800191117\n",
      "Iteration 6684 => Loss: 22.8799794813\n",
      "Iteration 6685 => Loss: 22.8799398930\n",
      "Iteration 6686 => Loss: 22.8799003469\n",
      "Iteration 6687 => Loss: 22.8798608427\n",
      "Iteration 6688 => Loss: 22.8798213806\n",
      "Iteration 6689 => Loss: 22.8797819604\n",
      "Iteration 6690 => Loss: 22.8797425821\n",
      "Iteration 6691 => Loss: 22.8797032457\n",
      "Iteration 6692 => Loss: 22.8796639511\n",
      "Iteration 6693 => Loss: 22.8796246982\n",
      "Iteration 6694 => Loss: 22.8795854871\n",
      "Iteration 6695 => Loss: 22.8795463177\n",
      "Iteration 6696 => Loss: 22.8795071899\n",
      "Iteration 6697 => Loss: 22.8794681037\n",
      "Iteration 6698 => Loss: 22.8794290590\n",
      "Iteration 6699 => Loss: 22.8793900558\n",
      "Iteration 6700 => Loss: 22.8793510941\n",
      "Iteration 6701 => Loss: 22.8793121738\n",
      "Iteration 6702 => Loss: 22.8792732949\n",
      "Iteration 6703 => Loss: 22.8792344573\n",
      "Iteration 6704 => Loss: 22.8791956610\n",
      "Iteration 6705 => Loss: 22.8791569060\n",
      "Iteration 6706 => Loss: 22.8791181921\n",
      "Iteration 6707 => Loss: 22.8790795194\n",
      "Iteration 6708 => Loss: 22.8790408878\n",
      "Iteration 6709 => Loss: 22.8790022972\n",
      "Iteration 6710 => Loss: 22.8789637477\n",
      "Iteration 6711 => Loss: 22.8789252392\n",
      "Iteration 6712 => Loss: 22.8788867716\n",
      "Iteration 6713 => Loss: 22.8788483448\n",
      "Iteration 6714 => Loss: 22.8788099590\n",
      "Iteration 6715 => Loss: 22.8787716139\n",
      "Iteration 6716 => Loss: 22.8787333096\n",
      "Iteration 6717 => Loss: 22.8786950460\n",
      "Iteration 6718 => Loss: 22.8786568231\n",
      "Iteration 6719 => Loss: 22.8786186408\n",
      "Iteration 6720 => Loss: 22.8785804991\n",
      "Iteration 6721 => Loss: 22.8785423979\n",
      "Iteration 6722 => Loss: 22.8785043373\n",
      "Iteration 6723 => Loss: 22.8784663171\n",
      "Iteration 6724 => Loss: 22.8784283373\n",
      "Iteration 6725 => Loss: 22.8783903979\n",
      "Iteration 6726 => Loss: 22.8783524988\n",
      "Iteration 6727 => Loss: 22.8783146400\n",
      "Iteration 6728 => Loss: 22.8782768214\n",
      "Iteration 6729 => Loss: 22.8782390431\n",
      "Iteration 6730 => Loss: 22.8782013049\n",
      "Iteration 6731 => Loss: 22.8781636068\n",
      "Iteration 6732 => Loss: 22.8781259488\n",
      "Iteration 6733 => Loss: 22.8780883308\n",
      "Iteration 6734 => Loss: 22.8780507528\n",
      "Iteration 6735 => Loss: 22.8780132147\n",
      "Iteration 6736 => Loss: 22.8779757166\n",
      "Iteration 6737 => Loss: 22.8779382583\n",
      "Iteration 6738 => Loss: 22.8779008398\n",
      "Iteration 6739 => Loss: 22.8778634611\n",
      "Iteration 6740 => Loss: 22.8778261222\n",
      "Iteration 6741 => Loss: 22.8777888229\n",
      "Iteration 6742 => Loss: 22.8777515633\n",
      "Iteration 6743 => Loss: 22.8777143433\n",
      "Iteration 6744 => Loss: 22.8776771628\n",
      "Iteration 6745 => Loss: 22.8776400219\n",
      "Iteration 6746 => Loss: 22.8776029204\n",
      "Iteration 6747 => Loss: 22.8775658584\n",
      "Iteration 6748 => Loss: 22.8775288358\n",
      "Iteration 6749 => Loss: 22.8774918525\n",
      "Iteration 6750 => Loss: 22.8774549086\n",
      "Iteration 6751 => Loss: 22.8774180039\n",
      "Iteration 6752 => Loss: 22.8773811384\n",
      "Iteration 6753 => Loss: 22.8773443122\n",
      "Iteration 6754 => Loss: 22.8773075250\n",
      "Iteration 6755 => Loss: 22.8772707770\n",
      "Iteration 6756 => Loss: 22.8772340681\n",
      "Iteration 6757 => Loss: 22.8771973981\n",
      "Iteration 6758 => Loss: 22.8771607672\n",
      "Iteration 6759 => Loss: 22.8771241752\n",
      "Iteration 6760 => Loss: 22.8770876221\n",
      "Iteration 6761 => Loss: 22.8770511078\n",
      "Iteration 6762 => Loss: 22.8770146324\n",
      "Iteration 6763 => Loss: 22.8769781957\n",
      "Iteration 6764 => Loss: 22.8769417977\n",
      "Iteration 6765 => Loss: 22.8769054385\n",
      "Iteration 6766 => Loss: 22.8768691179\n",
      "Iteration 6767 => Loss: 22.8768328359\n",
      "Iteration 6768 => Loss: 22.8767965924\n",
      "Iteration 6769 => Loss: 22.8767603875\n",
      "Iteration 6770 => Loss: 22.8767242211\n",
      "Iteration 6771 => Loss: 22.8766880931\n",
      "Iteration 6772 => Loss: 22.8766520036\n",
      "Iteration 6773 => Loss: 22.8766159524\n",
      "Iteration 6774 => Loss: 22.8765799395\n",
      "Iteration 6775 => Loss: 22.8765439649\n",
      "Iteration 6776 => Loss: 22.8765080285\n",
      "Iteration 6777 => Loss: 22.8764721303\n",
      "Iteration 6778 => Loss: 22.8764362703\n",
      "Iteration 6779 => Loss: 22.8764004484\n",
      "Iteration 6780 => Loss: 22.8763646646\n",
      "Iteration 6781 => Loss: 22.8763289188\n",
      "Iteration 6782 => Loss: 22.8762932111\n",
      "Iteration 6783 => Loss: 22.8762575412\n",
      "Iteration 6784 => Loss: 22.8762219093\n",
      "Iteration 6785 => Loss: 22.8761863153\n",
      "Iteration 6786 => Loss: 22.8761507591\n",
      "Iteration 6787 => Loss: 22.8761152407\n",
      "Iteration 6788 => Loss: 22.8760797601\n",
      "Iteration 6789 => Loss: 22.8760443172\n",
      "Iteration 6790 => Loss: 22.8760089119\n",
      "Iteration 6791 => Loss: 22.8759735443\n",
      "Iteration 6792 => Loss: 22.8759382143\n",
      "Iteration 6793 => Loss: 22.8759029218\n",
      "Iteration 6794 => Loss: 22.8758676668\n",
      "Iteration 6795 => Loss: 22.8758324494\n",
      "Iteration 6796 => Loss: 22.8757972693\n",
      "Iteration 6797 => Loss: 22.8757621267\n",
      "Iteration 6798 => Loss: 22.8757270214\n",
      "Iteration 6799 => Loss: 22.8756919534\n",
      "Iteration 6800 => Loss: 22.8756569227\n",
      "Iteration 6801 => Loss: 22.8756219293\n",
      "Iteration 6802 => Loss: 22.8755869730\n",
      "Iteration 6803 => Loss: 22.8755520539\n",
      "Iteration 6804 => Loss: 22.8755171719\n",
      "Iteration 6805 => Loss: 22.8754823270\n",
      "Iteration 6806 => Loss: 22.8754475191\n",
      "Iteration 6807 => Loss: 22.8754127483\n",
      "Iteration 6808 => Loss: 22.8753780143\n",
      "Iteration 6809 => Loss: 22.8753433174\n",
      "Iteration 6810 => Loss: 22.8753086573\n",
      "Iteration 6811 => Loss: 22.8752740340\n",
      "Iteration 6812 => Loss: 22.8752394475\n",
      "Iteration 6813 => Loss: 22.8752048978\n",
      "Iteration 6814 => Loss: 22.8751703849\n",
      "Iteration 6815 => Loss: 22.8751359086\n",
      "Iteration 6816 => Loss: 22.8751014690\n",
      "Iteration 6817 => Loss: 22.8750670659\n",
      "Iteration 6818 => Loss: 22.8750326995\n",
      "Iteration 6819 => Loss: 22.8749983696\n",
      "Iteration 6820 => Loss: 22.8749640761\n",
      "Iteration 6821 => Loss: 22.8749298192\n",
      "Iteration 6822 => Loss: 22.8748955986\n",
      "Iteration 6823 => Loss: 22.8748614144\n",
      "Iteration 6824 => Loss: 22.8748272665\n",
      "Iteration 6825 => Loss: 22.8747931550\n",
      "Iteration 6826 => Loss: 22.8747590797\n",
      "Iteration 6827 => Loss: 22.8747250406\n",
      "Iteration 6828 => Loss: 22.8746910377\n",
      "Iteration 6829 => Loss: 22.8746570710\n",
      "Iteration 6830 => Loss: 22.8746231404\n",
      "Iteration 6831 => Loss: 22.8745892458\n",
      "Iteration 6832 => Loss: 22.8745553872\n",
      "Iteration 6833 => Loss: 22.8745215647\n",
      "Iteration 6834 => Loss: 22.8744877781\n",
      "Iteration 6835 => Loss: 22.8744540274\n",
      "Iteration 6836 => Loss: 22.8744203126\n",
      "Iteration 6837 => Loss: 22.8743866336\n",
      "Iteration 6838 => Loss: 22.8743529905\n",
      "Iteration 6839 => Loss: 22.8743193831\n",
      "Iteration 6840 => Loss: 22.8742858114\n",
      "Iteration 6841 => Loss: 22.8742522754\n",
      "Iteration 6842 => Loss: 22.8742187750\n",
      "Iteration 6843 => Loss: 22.8741853103\n",
      "Iteration 6844 => Loss: 22.8741518811\n",
      "Iteration 6845 => Loss: 22.8741184875\n",
      "Iteration 6846 => Loss: 22.8740851293\n",
      "Iteration 6847 => Loss: 22.8740518067\n",
      "Iteration 6848 => Loss: 22.8740185194\n",
      "Iteration 6849 => Loss: 22.8739852675\n",
      "Iteration 6850 => Loss: 22.8739520510\n",
      "Iteration 6851 => Loss: 22.8739188698\n",
      "Iteration 6852 => Loss: 22.8738857239\n",
      "Iteration 6853 => Loss: 22.8738526131\n",
      "Iteration 6854 => Loss: 22.8738195376\n",
      "Iteration 6855 => Loss: 22.8737864973\n",
      "Iteration 6856 => Loss: 22.8737534920\n",
      "Iteration 6857 => Loss: 22.8737205219\n",
      "Iteration 6858 => Loss: 22.8736875868\n",
      "Iteration 6859 => Loss: 22.8736546867\n",
      "Iteration 6860 => Loss: 22.8736218215\n",
      "Iteration 6861 => Loss: 22.8735889914\n",
      "Iteration 6862 => Loss: 22.8735561961\n",
      "Iteration 6863 => Loss: 22.8735234356\n",
      "Iteration 6864 => Loss: 22.8734907100\n",
      "Iteration 6865 => Loss: 22.8734580192\n",
      "Iteration 6866 => Loss: 22.8734253631\n",
      "Iteration 6867 => Loss: 22.8733927418\n",
      "Iteration 6868 => Loss: 22.8733601551\n",
      "Iteration 6869 => Loss: 22.8733276030\n",
      "Iteration 6870 => Loss: 22.8732950856\n",
      "Iteration 6871 => Loss: 22.8732626027\n",
      "Iteration 6872 => Loss: 22.8732301544\n",
      "Iteration 6873 => Loss: 22.8731977405\n",
      "Iteration 6874 => Loss: 22.8731653611\n",
      "Iteration 6875 => Loss: 22.8731330161\n",
      "Iteration 6876 => Loss: 22.8731007055\n",
      "Iteration 6877 => Loss: 22.8730684293\n",
      "Iteration 6878 => Loss: 22.8730361873\n",
      "Iteration 6879 => Loss: 22.8730039796\n",
      "Iteration 6880 => Loss: 22.8729718062\n",
      "Iteration 6881 => Loss: 22.8729396670\n",
      "Iteration 6882 => Loss: 22.8729075619\n",
      "Iteration 6883 => Loss: 22.8728754909\n",
      "Iteration 6884 => Loss: 22.8728434541\n",
      "Iteration 6885 => Loss: 22.8728114513\n",
      "Iteration 6886 => Loss: 22.8727794825\n",
      "Iteration 6887 => Loss: 22.8727475477\n",
      "Iteration 6888 => Loss: 22.8727156468\n",
      "Iteration 6889 => Loss: 22.8726837799\n",
      "Iteration 6890 => Loss: 22.8726519468\n",
      "Iteration 6891 => Loss: 22.8726201476\n",
      "Iteration 6892 => Loss: 22.8725883822\n",
      "Iteration 6893 => Loss: 22.8725566505\n",
      "Iteration 6894 => Loss: 22.8725249526\n",
      "Iteration 6895 => Loss: 22.8724932883\n",
      "Iteration 6896 => Loss: 22.8724616577\n",
      "Iteration 6897 => Loss: 22.8724300608\n",
      "Iteration 6898 => Loss: 22.8723984974\n",
      "Iteration 6899 => Loss: 22.8723669676\n",
      "Iteration 6900 => Loss: 22.8723354713\n",
      "Iteration 6901 => Loss: 22.8723040084\n",
      "Iteration 6902 => Loss: 22.8722725791\n",
      "Iteration 6903 => Loss: 22.8722411831\n",
      "Iteration 6904 => Loss: 22.8722098205\n",
      "Iteration 6905 => Loss: 22.8721784912\n",
      "Iteration 6906 => Loss: 22.8721471953\n",
      "Iteration 6907 => Loss: 22.8721159326\n",
      "Iteration 6908 => Loss: 22.8720847031\n",
      "Iteration 6909 => Loss: 22.8720535068\n",
      "Iteration 6910 => Loss: 22.8720223437\n",
      "Iteration 6911 => Loss: 22.8719912137\n",
      "Iteration 6912 => Loss: 22.8719601169\n",
      "Iteration 6913 => Loss: 22.8719290530\n",
      "Iteration 6914 => Loss: 22.8718980222\n",
      "Iteration 6915 => Loss: 22.8718670244\n",
      "Iteration 6916 => Loss: 22.8718360595\n",
      "Iteration 6917 => Loss: 22.8718051275\n",
      "Iteration 6918 => Loss: 22.8717742285\n",
      "Iteration 6919 => Loss: 22.8717433622\n",
      "Iteration 6920 => Loss: 22.8717125288\n",
      "Iteration 6921 => Loss: 22.8716817281\n",
      "Iteration 6922 => Loss: 22.8716509602\n",
      "Iteration 6923 => Loss: 22.8716202250\n",
      "Iteration 6924 => Loss: 22.8715895225\n",
      "Iteration 6925 => Loss: 22.8715588526\n",
      "Iteration 6926 => Loss: 22.8715282153\n",
      "Iteration 6927 => Loss: 22.8714976105\n",
      "Iteration 6928 => Loss: 22.8714670383\n",
      "Iteration 6929 => Loss: 22.8714364986\n",
      "Iteration 6930 => Loss: 22.8714059914\n",
      "Iteration 6931 => Loss: 22.8713755166\n",
      "Iteration 6932 => Loss: 22.8713450742\n",
      "Iteration 6933 => Loss: 22.8713146641\n",
      "Iteration 6934 => Loss: 22.8712842864\n",
      "Iteration 6935 => Loss: 22.8712539410\n",
      "Iteration 6936 => Loss: 22.8712236278\n",
      "Iteration 6937 => Loss: 22.8711933468\n",
      "Iteration 6938 => Loss: 22.8711630980\n",
      "Iteration 6939 => Loss: 22.8711328814\n",
      "Iteration 6940 => Loss: 22.8711026969\n",
      "Iteration 6941 => Loss: 22.8710725445\n",
      "Iteration 6942 => Loss: 22.8710424241\n",
      "Iteration 6943 => Loss: 22.8710123358\n",
      "Iteration 6944 => Loss: 22.8709822794\n",
      "Iteration 6945 => Loss: 22.8709522550\n",
      "Iteration 6946 => Loss: 22.8709222625\n",
      "Iteration 6947 => Loss: 22.8708923019\n",
      "Iteration 6948 => Loss: 22.8708623731\n",
      "Iteration 6949 => Loss: 22.8708324762\n",
      "Iteration 6950 => Loss: 22.8708026110\n",
      "Iteration 6951 => Loss: 22.8707727776\n",
      "Iteration 6952 => Loss: 22.8707429758\n",
      "Iteration 6953 => Loss: 22.8707132058\n",
      "Iteration 6954 => Loss: 22.8706834674\n",
      "Iteration 6955 => Loss: 22.8706537606\n",
      "Iteration 6956 => Loss: 22.8706240854\n",
      "Iteration 6957 => Loss: 22.8705944418\n",
      "Iteration 6958 => Loss: 22.8705648296\n",
      "Iteration 6959 => Loss: 22.8705352489\n",
      "Iteration 6960 => Loss: 22.8705056997\n",
      "Iteration 6961 => Loss: 22.8704761819\n",
      "Iteration 6962 => Loss: 22.8704466955\n",
      "Iteration 6963 => Loss: 22.8704172404\n",
      "Iteration 6964 => Loss: 22.8703878166\n",
      "Iteration 6965 => Loss: 22.8703584241\n",
      "Iteration 6966 => Loss: 22.8703290628\n",
      "Iteration 6967 => Loss: 22.8702997327\n",
      "Iteration 6968 => Loss: 22.8702704338\n",
      "Iteration 6969 => Loss: 22.8702411661\n",
      "Iteration 6970 => Loss: 22.8702119295\n",
      "Iteration 6971 => Loss: 22.8701827239\n",
      "Iteration 6972 => Loss: 22.8701535494\n",
      "Iteration 6973 => Loss: 22.8701244059\n",
      "Iteration 6974 => Loss: 22.8700952934\n",
      "Iteration 6975 => Loss: 22.8700662119\n",
      "Iteration 6976 => Loss: 22.8700371612\n",
      "Iteration 6977 => Loss: 22.8700081414\n",
      "Iteration 6978 => Loss: 22.8699791525\n",
      "Iteration 6979 => Loss: 22.8699501944\n",
      "Iteration 6980 => Loss: 22.8699212671\n",
      "Iteration 6981 => Loss: 22.8698923705\n",
      "Iteration 6982 => Loss: 22.8698635046\n",
      "Iteration 6983 => Loss: 22.8698346694\n",
      "Iteration 6984 => Loss: 22.8698058649\n",
      "Iteration 6985 => Loss: 22.8697770910\n",
      "Iteration 6986 => Loss: 22.8697483477\n",
      "Iteration 6987 => Loss: 22.8697196349\n",
      "Iteration 6988 => Loss: 22.8696909527\n",
      "Iteration 6989 => Loss: 22.8696623009\n",
      "Iteration 6990 => Loss: 22.8696336796\n",
      "Iteration 6991 => Loss: 22.8696050887\n",
      "Iteration 6992 => Loss: 22.8695765282\n",
      "Iteration 6993 => Loss: 22.8695479981\n",
      "Iteration 6994 => Loss: 22.8695194983\n",
      "Iteration 6995 => Loss: 22.8694910288\n",
      "Iteration 6996 => Loss: 22.8694625895\n",
      "Iteration 6997 => Loss: 22.8694341805\n",
      "Iteration 6998 => Loss: 22.8694058017\n",
      "Iteration 6999 => Loss: 22.8693774531\n",
      "Iteration 7000 => Loss: 22.8693491345\n",
      "Iteration 7001 => Loss: 22.8693208461\n",
      "Iteration 7002 => Loss: 22.8692925878\n",
      "Iteration 7003 => Loss: 22.8692643595\n",
      "Iteration 7004 => Loss: 22.8692361612\n",
      "Iteration 7005 => Loss: 22.8692079928\n",
      "Iteration 7006 => Loss: 22.8691798545\n",
      "Iteration 7007 => Loss: 22.8691517460\n",
      "Iteration 7008 => Loss: 22.8691236674\n",
      "Iteration 7009 => Loss: 22.8690956186\n",
      "Iteration 7010 => Loss: 22.8690675997\n",
      "Iteration 7011 => Loss: 22.8690396106\n",
      "Iteration 7012 => Loss: 22.8690116512\n",
      "Iteration 7013 => Loss: 22.8689837215\n",
      "Iteration 7014 => Loss: 22.8689558215\n",
      "Iteration 7015 => Loss: 22.8689279512\n",
      "Iteration 7016 => Loss: 22.8689001105\n",
      "Iteration 7017 => Loss: 22.8688722993\n",
      "Iteration 7018 => Loss: 22.8688445178\n",
      "Iteration 7019 => Loss: 22.8688167658\n",
      "Iteration 7020 => Loss: 22.8687890433\n",
      "Iteration 7021 => Loss: 22.8687613502\n",
      "Iteration 7022 => Loss: 22.8687336866\n",
      "Iteration 7023 => Loss: 22.8687060524\n",
      "Iteration 7024 => Loss: 22.8686784476\n",
      "Iteration 7025 => Loss: 22.8686508721\n",
      "Iteration 7026 => Loss: 22.8686233259\n",
      "Iteration 7027 => Loss: 22.8685958090\n",
      "Iteration 7028 => Loss: 22.8685683213\n",
      "Iteration 7029 => Loss: 22.8685408629\n",
      "Iteration 7030 => Loss: 22.8685134337\n",
      "Iteration 7031 => Loss: 22.8684860336\n",
      "Iteration 7032 => Loss: 22.8684586626\n",
      "Iteration 7033 => Loss: 22.8684313208\n",
      "Iteration 7034 => Loss: 22.8684040080\n",
      "Iteration 7035 => Loss: 22.8683767242\n",
      "Iteration 7036 => Loss: 22.8683494695\n",
      "Iteration 7037 => Loss: 22.8683222437\n",
      "Iteration 7038 => Loss: 22.8682950468\n",
      "Iteration 7039 => Loss: 22.8682678789\n",
      "Iteration 7040 => Loss: 22.8682407398\n",
      "Iteration 7041 => Loss: 22.8682136296\n",
      "Iteration 7042 => Loss: 22.8681865482\n",
      "Iteration 7043 => Loss: 22.8681594956\n",
      "Iteration 7044 => Loss: 22.8681324717\n",
      "Iteration 7045 => Loss: 22.8681054766\n",
      "Iteration 7046 => Loss: 22.8680785102\n",
      "Iteration 7047 => Loss: 22.8680515724\n",
      "Iteration 7048 => Loss: 22.8680246633\n",
      "Iteration 7049 => Loss: 22.8679977827\n",
      "Iteration 7050 => Loss: 22.8679709308\n",
      "Iteration 7051 => Loss: 22.8679441074\n",
      "Iteration 7052 => Loss: 22.8679173125\n",
      "Iteration 7053 => Loss: 22.8678905460\n",
      "Iteration 7054 => Loss: 22.8678638081\n",
      "Iteration 7055 => Loss: 22.8678370985\n",
      "Iteration 7056 => Loss: 22.8678104174\n",
      "Iteration 7057 => Loss: 22.8677837646\n",
      "Iteration 7058 => Loss: 22.8677571401\n",
      "Iteration 7059 => Loss: 22.8677305440\n",
      "Iteration 7060 => Loss: 22.8677039761\n",
      "Iteration 7061 => Loss: 22.8676774364\n",
      "Iteration 7062 => Loss: 22.8676509250\n",
      "Iteration 7063 => Loss: 22.8676244417\n",
      "Iteration 7064 => Loss: 22.8675979866\n",
      "Iteration 7065 => Loss: 22.8675715597\n",
      "Iteration 7066 => Loss: 22.8675451608\n",
      "Iteration 7067 => Loss: 22.8675187899\n",
      "Iteration 7068 => Loss: 22.8674924471\n",
      "Iteration 7069 => Loss: 22.8674661323\n",
      "Iteration 7070 => Loss: 22.8674398455\n",
      "Iteration 7071 => Loss: 22.8674135866\n",
      "Iteration 7072 => Loss: 22.8673873557\n",
      "Iteration 7073 => Loss: 22.8673611526\n",
      "Iteration 7074 => Loss: 22.8673349773\n",
      "Iteration 7075 => Loss: 22.8673088299\n",
      "Iteration 7076 => Loss: 22.8672827103\n",
      "Iteration 7077 => Loss: 22.8672566185\n",
      "Iteration 7078 => Loss: 22.8672305544\n",
      "Iteration 7079 => Loss: 22.8672045179\n",
      "Iteration 7080 => Loss: 22.8671785092\n",
      "Iteration 7081 => Loss: 22.8671525281\n",
      "Iteration 7082 => Loss: 22.8671265747\n",
      "Iteration 7083 => Loss: 22.8671006488\n",
      "Iteration 7084 => Loss: 22.8670747505\n",
      "Iteration 7085 => Loss: 22.8670488797\n",
      "Iteration 7086 => Loss: 22.8670230364\n",
      "Iteration 7087 => Loss: 22.8669972205\n",
      "Iteration 7088 => Loss: 22.8669714322\n",
      "Iteration 7089 => Loss: 22.8669456712\n",
      "Iteration 7090 => Loss: 22.8669199376\n",
      "Iteration 7091 => Loss: 22.8668942314\n",
      "Iteration 7092 => Loss: 22.8668685525\n",
      "Iteration 7093 => Loss: 22.8668429009\n",
      "Iteration 7094 => Loss: 22.8668172765\n",
      "Iteration 7095 => Loss: 22.8667916794\n",
      "Iteration 7096 => Loss: 22.8667661095\n",
      "Iteration 7097 => Loss: 22.8667405668\n",
      "Iteration 7098 => Loss: 22.8667150513\n",
      "Iteration 7099 => Loss: 22.8666895628\n",
      "Iteration 7100 => Loss: 22.8666641015\n",
      "Iteration 7101 => Loss: 22.8666386672\n",
      "Iteration 7102 => Loss: 22.8666132599\n",
      "Iteration 7103 => Loss: 22.8665878797\n",
      "Iteration 7104 => Loss: 22.8665625264\n",
      "Iteration 7105 => Loss: 22.8665372001\n",
      "Iteration 7106 => Loss: 22.8665119007\n",
      "Iteration 7107 => Loss: 22.8664866282\n",
      "Iteration 7108 => Loss: 22.8664613826\n",
      "Iteration 7109 => Loss: 22.8664361638\n",
      "Iteration 7110 => Loss: 22.8664109718\n",
      "Iteration 7111 => Loss: 22.8663858066\n",
      "Iteration 7112 => Loss: 22.8663606682\n",
      "Iteration 7113 => Loss: 22.8663355564\n",
      "Iteration 7114 => Loss: 22.8663104714\n",
      "Iteration 7115 => Loss: 22.8662854130\n",
      "Iteration 7116 => Loss: 22.8662603812\n",
      "Iteration 7117 => Loss: 22.8662353761\n",
      "Iteration 7118 => Loss: 22.8662103976\n",
      "Iteration 7119 => Loss: 22.8661854455\n",
      "Iteration 7120 => Loss: 22.8661605201\n",
      "Iteration 7121 => Loss: 22.8661356211\n",
      "Iteration 7122 => Loss: 22.8661107486\n",
      "Iteration 7123 => Loss: 22.8660859025\n",
      "Iteration 7124 => Loss: 22.8660610828\n",
      "Iteration 7125 => Loss: 22.8660362895\n",
      "Iteration 7126 => Loss: 22.8660115226\n",
      "Iteration 7127 => Loss: 22.8659867820\n",
      "Iteration 7128 => Loss: 22.8659620677\n",
      "Iteration 7129 => Loss: 22.8659373796\n",
      "Iteration 7130 => Loss: 22.8659127179\n",
      "Iteration 7131 => Loss: 22.8658880823\n",
      "Iteration 7132 => Loss: 22.8658634729\n",
      "Iteration 7133 => Loss: 22.8658388897\n",
      "Iteration 7134 => Loss: 22.8658143326\n",
      "Iteration 7135 => Loss: 22.8657898016\n",
      "Iteration 7136 => Loss: 22.8657652966\n",
      "Iteration 7137 => Loss: 22.8657408178\n",
      "Iteration 7138 => Loss: 22.8657163649\n",
      "Iteration 7139 => Loss: 22.8656919381\n",
      "Iteration 7140 => Loss: 22.8656675372\n",
      "Iteration 7141 => Loss: 22.8656431622\n",
      "Iteration 7142 => Loss: 22.8656188132\n",
      "Iteration 7143 => Loss: 22.8655944900\n",
      "Iteration 7144 => Loss: 22.8655701927\n",
      "Iteration 7145 => Loss: 22.8655459212\n",
      "Iteration 7146 => Loss: 22.8655216755\n",
      "Iteration 7147 => Loss: 22.8654974556\n",
      "Iteration 7148 => Loss: 22.8654732615\n",
      "Iteration 7149 => Loss: 22.8654490930\n",
      "Iteration 7150 => Loss: 22.8654249503\n",
      "Iteration 7151 => Loss: 22.8654008332\n",
      "Iteration 7152 => Loss: 22.8653767417\n",
      "Iteration 7153 => Loss: 22.8653526759\n",
      "Iteration 7154 => Loss: 22.8653286356\n",
      "Iteration 7155 => Loss: 22.8653046209\n",
      "Iteration 7156 => Loss: 22.8652806317\n",
      "Iteration 7157 => Loss: 22.8652566680\n",
      "Iteration 7158 => Loss: 22.8652327298\n",
      "Iteration 7159 => Loss: 22.8652088171\n",
      "Iteration 7160 => Loss: 22.8651849297\n",
      "Iteration 7161 => Loss: 22.8651610678\n",
      "Iteration 7162 => Loss: 22.8651372312\n",
      "Iteration 7163 => Loss: 22.8651134199\n",
      "Iteration 7164 => Loss: 22.8650896340\n",
      "Iteration 7165 => Loss: 22.8650658733\n",
      "Iteration 7166 => Loss: 22.8650421379\n",
      "Iteration 7167 => Loss: 22.8650184278\n",
      "Iteration 7168 => Loss: 22.8649947428\n",
      "Iteration 7169 => Loss: 22.8649710830\n",
      "Iteration 7170 => Loss: 22.8649474484\n",
      "Iteration 7171 => Loss: 22.8649238388\n",
      "Iteration 7172 => Loss: 22.8649002544\n",
      "Iteration 7173 => Loss: 22.8648766951\n",
      "Iteration 7174 => Loss: 22.8648531608\n",
      "Iteration 7175 => Loss: 22.8648296515\n",
      "Iteration 7176 => Loss: 22.8648061672\n",
      "Iteration 7177 => Loss: 22.8647827078\n",
      "Iteration 7178 => Loss: 22.8647592734\n",
      "Iteration 7179 => Loss: 22.8647358639\n",
      "Iteration 7180 => Loss: 22.8647124793\n",
      "Iteration 7181 => Loss: 22.8646891196\n",
      "Iteration 7182 => Loss: 22.8646657847\n",
      "Iteration 7183 => Loss: 22.8646424746\n",
      "Iteration 7184 => Loss: 22.8646191892\n",
      "Iteration 7185 => Loss: 22.8645959286\n",
      "Iteration 7186 => Loss: 22.8645726928\n",
      "Iteration 7187 => Loss: 22.8645494816\n",
      "Iteration 7188 => Loss: 22.8645262951\n",
      "Iteration 7189 => Loss: 22.8645031333\n",
      "Iteration 7190 => Loss: 22.8644799961\n",
      "Iteration 7191 => Loss: 22.8644568835\n",
      "Iteration 7192 => Loss: 22.8644337954\n",
      "Iteration 7193 => Loss: 22.8644107319\n",
      "Iteration 7194 => Loss: 22.8643876929\n",
      "Iteration 7195 => Loss: 22.8643646784\n",
      "Iteration 7196 => Loss: 22.8643416883\n",
      "Iteration 7197 => Loss: 22.8643187227\n",
      "Iteration 7198 => Loss: 22.8642957815\n",
      "Iteration 7199 => Loss: 22.8642728647\n",
      "Iteration 7200 => Loss: 22.8642499723\n",
      "Iteration 7201 => Loss: 22.8642271042\n",
      "Iteration 7202 => Loss: 22.8642042604\n",
      "Iteration 7203 => Loss: 22.8641814408\n",
      "Iteration 7204 => Loss: 22.8641586456\n",
      "Iteration 7205 => Loss: 22.8641358745\n",
      "Iteration 7206 => Loss: 22.8641131277\n",
      "Iteration 7207 => Loss: 22.8640904051\n",
      "Iteration 7208 => Loss: 22.8640677066\n",
      "Iteration 7209 => Loss: 22.8640450322\n",
      "Iteration 7210 => Loss: 22.8640223819\n",
      "Iteration 7211 => Loss: 22.8639997557\n",
      "Iteration 7212 => Loss: 22.8639771536\n",
      "Iteration 7213 => Loss: 22.8639545755\n",
      "Iteration 7214 => Loss: 22.8639320214\n",
      "Iteration 7215 => Loss: 22.8639094912\n",
      "Iteration 7216 => Loss: 22.8638869850\n",
      "Iteration 7217 => Loss: 22.8638645028\n",
      "Iteration 7218 => Loss: 22.8638420444\n",
      "Iteration 7219 => Loss: 22.8638196099\n",
      "Iteration 7220 => Loss: 22.8637971993\n",
      "Iteration 7221 => Loss: 22.8637748124\n",
      "Iteration 7222 => Loss: 22.8637524494\n",
      "Iteration 7223 => Loss: 22.8637301101\n",
      "Iteration 7224 => Loss: 22.8637077946\n",
      "Iteration 7225 => Loss: 22.8636855028\n",
      "Iteration 7226 => Loss: 22.8636632347\n",
      "Iteration 7227 => Loss: 22.8636409903\n",
      "Iteration 7228 => Loss: 22.8636187695\n",
      "Iteration 7229 => Loss: 22.8635965724\n",
      "Iteration 7230 => Loss: 22.8635743988\n",
      "Iteration 7231 => Loss: 22.8635522488\n",
      "Iteration 7232 => Loss: 22.8635301224\n",
      "Iteration 7233 => Loss: 22.8635080194\n",
      "Iteration 7234 => Loss: 22.8634859400\n",
      "Iteration 7235 => Loss: 22.8634638840\n",
      "Iteration 7236 => Loss: 22.8634418515\n",
      "Iteration 7237 => Loss: 22.8634198424\n",
      "Iteration 7238 => Loss: 22.8633978567\n",
      "Iteration 7239 => Loss: 22.8633758944\n",
      "Iteration 7240 => Loss: 22.8633539554\n",
      "Iteration 7241 => Loss: 22.8633320397\n",
      "Iteration 7242 => Loss: 22.8633101474\n",
      "Iteration 7243 => Loss: 22.8632882783\n",
      "Iteration 7244 => Loss: 22.8632664324\n",
      "Iteration 7245 => Loss: 22.8632446098\n",
      "Iteration 7246 => Loss: 22.8632228103\n",
      "Iteration 7247 => Loss: 22.8632010341\n",
      "Iteration 7248 => Loss: 22.8631792810\n",
      "Iteration 7249 => Loss: 22.8631575510\n",
      "Iteration 7250 => Loss: 22.8631358441\n",
      "Iteration 7251 => Loss: 22.8631141603\n",
      "Iteration 7252 => Loss: 22.8630924995\n",
      "Iteration 7253 => Loss: 22.8630708617\n",
      "Iteration 7254 => Loss: 22.8630492470\n",
      "Iteration 7255 => Loss: 22.8630276552\n",
      "Iteration 7256 => Loss: 22.8630060864\n",
      "Iteration 7257 => Loss: 22.8629845405\n",
      "Iteration 7258 => Loss: 22.8629630175\n",
      "Iteration 7259 => Loss: 22.8629415174\n",
      "Iteration 7260 => Loss: 22.8629200402\n",
      "Iteration 7261 => Loss: 22.8628985858\n",
      "Iteration 7262 => Loss: 22.8628771541\n",
      "Iteration 7263 => Loss: 22.8628557453\n",
      "Iteration 7264 => Loss: 22.8628343592\n",
      "Iteration 7265 => Loss: 22.8628129959\n",
      "Iteration 7266 => Loss: 22.8627916552\n",
      "Iteration 7267 => Loss: 22.8627703373\n",
      "Iteration 7268 => Loss: 22.8627490420\n",
      "Iteration 7269 => Loss: 22.8627277693\n",
      "Iteration 7270 => Loss: 22.8627065193\n",
      "Iteration 7271 => Loss: 22.8626852918\n",
      "Iteration 7272 => Loss: 22.8626640869\n",
      "Iteration 7273 => Loss: 22.8626429046\n",
      "Iteration 7274 => Loss: 22.8626217447\n",
      "Iteration 7275 => Loss: 22.8626006074\n",
      "Iteration 7276 => Loss: 22.8625794925\n",
      "Iteration 7277 => Loss: 22.8625584001\n",
      "Iteration 7278 => Loss: 22.8625373301\n",
      "Iteration 7279 => Loss: 22.8625162825\n",
      "Iteration 7280 => Loss: 22.8624952572\n",
      "Iteration 7281 => Loss: 22.8624742544\n",
      "Iteration 7282 => Loss: 22.8624532738\n",
      "Iteration 7283 => Loss: 22.8624323155\n",
      "Iteration 7284 => Loss: 22.8624113795\n",
      "Iteration 7285 => Loss: 22.8623904658\n",
      "Iteration 7286 => Loss: 22.8623695743\n",
      "Iteration 7287 => Loss: 22.8623487050\n",
      "Iteration 7288 => Loss: 22.8623278579\n",
      "Iteration 7289 => Loss: 22.8623070330\n",
      "Iteration 7290 => Loss: 22.8622862302\n",
      "Iteration 7291 => Loss: 22.8622654495\n",
      "Iteration 7292 => Loss: 22.8622446909\n",
      "Iteration 7293 => Loss: 22.8622239543\n",
      "Iteration 7294 => Loss: 22.8622032398\n",
      "Iteration 7295 => Loss: 22.8621825473\n",
      "Iteration 7296 => Loss: 22.8621618768\n",
      "Iteration 7297 => Loss: 22.8621412283\n",
      "Iteration 7298 => Loss: 22.8621206018\n",
      "Iteration 7299 => Loss: 22.8620999971\n",
      "Iteration 7300 => Loss: 22.8620794144\n",
      "Iteration 7301 => Loss: 22.8620588535\n",
      "Iteration 7302 => Loss: 22.8620383145\n",
      "Iteration 7303 => Loss: 22.8620177974\n",
      "Iteration 7304 => Loss: 22.8619973020\n",
      "Iteration 7305 => Loss: 22.8619768284\n",
      "Iteration 7306 => Loss: 22.8619563766\n",
      "Iteration 7307 => Loss: 22.8619359466\n",
      "Iteration 7308 => Loss: 22.8619155382\n",
      "Iteration 7309 => Loss: 22.8618951515\n",
      "Iteration 7310 => Loss: 22.8618747866\n",
      "Iteration 7311 => Loss: 22.8618544432\n",
      "Iteration 7312 => Loss: 22.8618341215\n",
      "Iteration 7313 => Loss: 22.8618138214\n",
      "Iteration 7314 => Loss: 22.8617935428\n",
      "Iteration 7315 => Loss: 22.8617732859\n",
      "Iteration 7316 => Loss: 22.8617530504\n",
      "Iteration 7317 => Loss: 22.8617328365\n",
      "Iteration 7318 => Loss: 22.8617126440\n",
      "Iteration 7319 => Loss: 22.8616924730\n",
      "Iteration 7320 => Loss: 22.8616723235\n",
      "Iteration 7321 => Loss: 22.8616521954\n",
      "Iteration 7322 => Loss: 22.8616320886\n",
      "Iteration 7323 => Loss: 22.8616120033\n",
      "Iteration 7324 => Loss: 22.8615919393\n",
      "Iteration 7325 => Loss: 22.8615718966\n",
      "Iteration 7326 => Loss: 22.8615518752\n",
      "Iteration 7327 => Loss: 22.8615318751\n",
      "Iteration 7328 => Loss: 22.8615118963\n",
      "Iteration 7329 => Loss: 22.8614919387\n",
      "Iteration 7330 => Loss: 22.8614720023\n",
      "Iteration 7331 => Loss: 22.8614520871\n",
      "Iteration 7332 => Loss: 22.8614321931\n",
      "Iteration 7333 => Loss: 22.8614123202\n",
      "Iteration 7334 => Loss: 22.8613924684\n",
      "Iteration 7335 => Loss: 22.8613726378\n",
      "Iteration 7336 => Loss: 22.8613528282\n",
      "Iteration 7337 => Loss: 22.8613330397\n",
      "Iteration 7338 => Loss: 22.8613132722\n",
      "Iteration 7339 => Loss: 22.8612935258\n",
      "Iteration 7340 => Loss: 22.8612738003\n",
      "Iteration 7341 => Loss: 22.8612540958\n",
      "Iteration 7342 => Loss: 22.8612344122\n",
      "Iteration 7343 => Loss: 22.8612147496\n",
      "Iteration 7344 => Loss: 22.8611951079\n",
      "Iteration 7345 => Loss: 22.8611754870\n",
      "Iteration 7346 => Loss: 22.8611558870\n",
      "Iteration 7347 => Loss: 22.8611363078\n",
      "Iteration 7348 => Loss: 22.8611167495\n",
      "Iteration 7349 => Loss: 22.8610972119\n",
      "Iteration 7350 => Loss: 22.8610776951\n",
      "Iteration 7351 => Loss: 22.8610581991\n",
      "Iteration 7352 => Loss: 22.8610387237\n",
      "Iteration 7353 => Loss: 22.8610192691\n",
      "Iteration 7354 => Loss: 22.8609998352\n",
      "Iteration 7355 => Loss: 22.8609804219\n",
      "Iteration 7356 => Loss: 22.8609610292\n",
      "Iteration 7357 => Loss: 22.8609416572\n",
      "Iteration 7358 => Loss: 22.8609223058\n",
      "Iteration 7359 => Loss: 22.8609029749\n",
      "Iteration 7360 => Loss: 22.8608836645\n",
      "Iteration 7361 => Loss: 22.8608643747\n",
      "Iteration 7362 => Loss: 22.8608451055\n",
      "Iteration 7363 => Loss: 22.8608258566\n",
      "Iteration 7364 => Loss: 22.8608066283\n",
      "Iteration 7365 => Loss: 22.8607874204\n",
      "Iteration 7366 => Loss: 22.8607682329\n",
      "Iteration 7367 => Loss: 22.8607490658\n",
      "Iteration 7368 => Loss: 22.8607299191\n",
      "Iteration 7369 => Loss: 22.8607107927\n",
      "Iteration 7370 => Loss: 22.8606916866\n",
      "Iteration 7371 => Loss: 22.8606726009\n",
      "Iteration 7372 => Loss: 22.8606535355\n",
      "Iteration 7373 => Loss: 22.8606344903\n",
      "Iteration 7374 => Loss: 22.8606154654\n",
      "Iteration 7375 => Loss: 22.8605964606\n",
      "Iteration 7376 => Loss: 22.8605774761\n",
      "Iteration 7377 => Loss: 22.8605585118\n",
      "Iteration 7378 => Loss: 22.8605395676\n",
      "Iteration 7379 => Loss: 22.8605206436\n",
      "Iteration 7380 => Loss: 22.8605017397\n",
      "Iteration 7381 => Loss: 22.8604828559\n",
      "Iteration 7382 => Loss: 22.8604639921\n",
      "Iteration 7383 => Loss: 22.8604451484\n",
      "Iteration 7384 => Loss: 22.8604263248\n",
      "Iteration 7385 => Loss: 22.8604075211\n",
      "Iteration 7386 => Loss: 22.8603887374\n",
      "Iteration 7387 => Loss: 22.8603699737\n",
      "Iteration 7388 => Loss: 22.8603512300\n",
      "Iteration 7389 => Loss: 22.8603325061\n",
      "Iteration 7390 => Loss: 22.8603138022\n",
      "Iteration 7391 => Loss: 22.8602951181\n",
      "Iteration 7392 => Loss: 22.8602764540\n",
      "Iteration 7393 => Loss: 22.8602578096\n",
      "Iteration 7394 => Loss: 22.8602391851\n",
      "Iteration 7395 => Loss: 22.8602205804\n",
      "Iteration 7396 => Loss: 22.8602019954\n",
      "Iteration 7397 => Loss: 22.8601834302\n",
      "Iteration 7398 => Loss: 22.8601648847\n",
      "Iteration 7399 => Loss: 22.8601463590\n",
      "Iteration 7400 => Loss: 22.8601278529\n",
      "Iteration 7401 => Loss: 22.8601093665\n",
      "Iteration 7402 => Loss: 22.8600908998\n",
      "Iteration 7403 => Loss: 22.8600724527\n",
      "Iteration 7404 => Loss: 22.8600540252\n",
      "Iteration 7405 => Loss: 22.8600356173\n",
      "Iteration 7406 => Loss: 22.8600172289\n",
      "Iteration 7407 => Loss: 22.8599988601\n",
      "Iteration 7408 => Loss: 22.8599805109\n",
      "Iteration 7409 => Loss: 22.8599621811\n",
      "Iteration 7410 => Loss: 22.8599438708\n",
      "Iteration 7411 => Loss: 22.8599255800\n",
      "Iteration 7412 => Loss: 22.8599073086\n",
      "Iteration 7413 => Loss: 22.8598890567\n",
      "Iteration 7414 => Loss: 22.8598708241\n",
      "Iteration 7415 => Loss: 22.8598526109\n",
      "Iteration 7416 => Loss: 22.8598344171\n",
      "Iteration 7417 => Loss: 22.8598162426\n",
      "Iteration 7418 => Loss: 22.8597980875\n",
      "Iteration 7419 => Loss: 22.8597799516\n",
      "Iteration 7420 => Loss: 22.8597618351\n",
      "Iteration 7421 => Loss: 22.8597437377\n",
      "Iteration 7422 => Loss: 22.8597256597\n",
      "Iteration 7423 => Loss: 22.8597076008\n",
      "Iteration 7424 => Loss: 22.8596895611\n",
      "Iteration 7425 => Loss: 22.8596715406\n",
      "Iteration 7426 => Loss: 22.8596535393\n",
      "Iteration 7427 => Loss: 22.8596355571\n",
      "Iteration 7428 => Loss: 22.8596175940\n",
      "Iteration 7429 => Loss: 22.8595996500\n",
      "Iteration 7430 => Loss: 22.8595817251\n",
      "Iteration 7431 => Loss: 22.8595638192\n",
      "Iteration 7432 => Loss: 22.8595459324\n",
      "Iteration 7433 => Loss: 22.8595280646\n",
      "Iteration 7434 => Loss: 22.8595102157\n",
      "Iteration 7435 => Loss: 22.8594923859\n",
      "Iteration 7436 => Loss: 22.8594745750\n",
      "Iteration 7437 => Loss: 22.8594567830\n",
      "Iteration 7438 => Loss: 22.8594390100\n",
      "Iteration 7439 => Loss: 22.8594212558\n",
      "Iteration 7440 => Loss: 22.8594035205\n",
      "Iteration 7441 => Loss: 22.8593858041\n",
      "Iteration 7442 => Loss: 22.8593681065\n",
      "Iteration 7443 => Loss: 22.8593504277\n",
      "Iteration 7444 => Loss: 22.8593327677\n",
      "Iteration 7445 => Loss: 22.8593151264\n",
      "Iteration 7446 => Loss: 22.8592975040\n",
      "Iteration 7447 => Loss: 22.8592799002\n",
      "Iteration 7448 => Loss: 22.8592623152\n",
      "Iteration 7449 => Loss: 22.8592447488\n",
      "Iteration 7450 => Loss: 22.8592272012\n",
      "Iteration 7451 => Loss: 22.8592096722\n",
      "Iteration 7452 => Loss: 22.8591921618\n",
      "Iteration 7453 => Loss: 22.8591746700\n",
      "Iteration 7454 => Loss: 22.8591571968\n",
      "Iteration 7455 => Loss: 22.8591397422\n",
      "Iteration 7456 => Loss: 22.8591223062\n",
      "Iteration 7457 => Loss: 22.8591048887\n",
      "Iteration 7458 => Loss: 22.8590874897\n",
      "Iteration 7459 => Loss: 22.8590701092\n",
      "Iteration 7460 => Loss: 22.8590527471\n",
      "Iteration 7461 => Loss: 22.8590354036\n",
      "Iteration 7462 => Loss: 22.8590180784\n",
      "Iteration 7463 => Loss: 22.8590007717\n",
      "Iteration 7464 => Loss: 22.8589834834\n",
      "Iteration 7465 => Loss: 22.8589662134\n",
      "Iteration 7466 => Loss: 22.8589489618\n",
      "Iteration 7467 => Loss: 22.8589317286\n",
      "Iteration 7468 => Loss: 22.8589145136\n",
      "Iteration 7469 => Loss: 22.8588973170\n",
      "Iteration 7470 => Loss: 22.8588801387\n",
      "Iteration 7471 => Loss: 22.8588629786\n",
      "Iteration 7472 => Loss: 22.8588458367\n",
      "Iteration 7473 => Loss: 22.8588287131\n",
      "Iteration 7474 => Loss: 22.8588116076\n",
      "Iteration 7475 => Loss: 22.8587945204\n",
      "Iteration 7476 => Loss: 22.8587774513\n",
      "Iteration 7477 => Loss: 22.8587604004\n",
      "Iteration 7478 => Loss: 22.8587433676\n",
      "Iteration 7479 => Loss: 22.8587263528\n",
      "Iteration 7480 => Loss: 22.8587093562\n",
      "Iteration 7481 => Loss: 22.8586923777\n",
      "Iteration 7482 => Loss: 22.8586754172\n",
      "Iteration 7483 => Loss: 22.8586584747\n",
      "Iteration 7484 => Loss: 22.8586415502\n",
      "Iteration 7485 => Loss: 22.8586246437\n",
      "Iteration 7486 => Loss: 22.8586077552\n",
      "Iteration 7487 => Loss: 22.8585908847\n",
      "Iteration 7488 => Loss: 22.8585740320\n",
      "Iteration 7489 => Loss: 22.8585571973\n",
      "Iteration 7490 => Loss: 22.8585403805\n",
      "Iteration 7491 => Loss: 22.8585235816\n",
      "Iteration 7492 => Loss: 22.8585068005\n",
      "Iteration 7493 => Loss: 22.8584900372\n",
      "Iteration 7494 => Loss: 22.8584732918\n",
      "Iteration 7495 => Loss: 22.8584565642\n",
      "Iteration 7496 => Loss: 22.8584398543\n",
      "Iteration 7497 => Loss: 22.8584231623\n",
      "Iteration 7498 => Loss: 22.8584064879\n",
      "Iteration 7499 => Loss: 22.8583898313\n",
      "Iteration 7500 => Loss: 22.8583731924\n",
      "Iteration 7501 => Loss: 22.8583565712\n",
      "Iteration 7502 => Loss: 22.8583399676\n",
      "Iteration 7503 => Loss: 22.8583233817\n",
      "Iteration 7504 => Loss: 22.8583068134\n",
      "Iteration 7505 => Loss: 22.8582902628\n",
      "Iteration 7506 => Loss: 22.8582737297\n",
      "Iteration 7507 => Loss: 22.8582572142\n",
      "Iteration 7508 => Loss: 22.8582407163\n",
      "Iteration 7509 => Loss: 22.8582242359\n",
      "Iteration 7510 => Loss: 22.8582077730\n",
      "Iteration 7511 => Loss: 22.8581913276\n",
      "Iteration 7512 => Loss: 22.8581748997\n",
      "Iteration 7513 => Loss: 22.8581584893\n",
      "Iteration 7514 => Loss: 22.8581420963\n",
      "Iteration 7515 => Loss: 22.8581257207\n",
      "Iteration 7516 => Loss: 22.8581093625\n",
      "Iteration 7517 => Loss: 22.8580930218\n",
      "Iteration 7518 => Loss: 22.8580766983\n",
      "Iteration 7519 => Loss: 22.8580603923\n",
      "Iteration 7520 => Loss: 22.8580441036\n",
      "Iteration 7521 => Loss: 22.8580278322\n",
      "Iteration 7522 => Loss: 22.8580115781\n",
      "Iteration 7523 => Loss: 22.8579953412\n",
      "Iteration 7524 => Loss: 22.8579791216\n",
      "Iteration 7525 => Loss: 22.8579629193\n",
      "Iteration 7526 => Loss: 22.8579467342\n",
      "Iteration 7527 => Loss: 22.8579305663\n",
      "Iteration 7528 => Loss: 22.8579144156\n",
      "Iteration 7529 => Loss: 22.8578982820\n",
      "Iteration 7530 => Loss: 22.8578821656\n",
      "Iteration 7531 => Loss: 22.8578660664\n",
      "Iteration 7532 => Loss: 22.8578499842\n",
      "Iteration 7533 => Loss: 22.8578339191\n",
      "Iteration 7534 => Loss: 22.8578178711\n",
      "Iteration 7535 => Loss: 22.8578018402\n",
      "Iteration 7536 => Loss: 22.8577858263\n",
      "Iteration 7537 => Loss: 22.8577698295\n",
      "Iteration 7538 => Loss: 22.8577538496\n",
      "Iteration 7539 => Loss: 22.8577378867\n",
      "Iteration 7540 => Loss: 22.8577219408\n",
      "Iteration 7541 => Loss: 22.8577060119\n",
      "Iteration 7542 => Loss: 22.8576900998\n",
      "Iteration 7543 => Loss: 22.8576742047\n",
      "Iteration 7544 => Loss: 22.8576583265\n",
      "Iteration 7545 => Loss: 22.8576424652\n",
      "Iteration 7546 => Loss: 22.8576266207\n",
      "Iteration 7547 => Loss: 22.8576107931\n",
      "Iteration 7548 => Loss: 22.8575949823\n",
      "Iteration 7549 => Loss: 22.8575791883\n",
      "Iteration 7550 => Loss: 22.8575634111\n",
      "Iteration 7551 => Loss: 22.8575476506\n",
      "Iteration 7552 => Loss: 22.8575319069\n",
      "Iteration 7553 => Loss: 22.8575161800\n",
      "Iteration 7554 => Loss: 22.8575004697\n",
      "Iteration 7555 => Loss: 22.8574847762\n",
      "Iteration 7556 => Loss: 22.8574690994\n",
      "Iteration 7557 => Loss: 22.8574534392\n",
      "Iteration 7558 => Loss: 22.8574377956\n",
      "Iteration 7559 => Loss: 22.8574221687\n",
      "Iteration 7560 => Loss: 22.8574065584\n",
      "Iteration 7561 => Loss: 22.8573909647\n",
      "Iteration 7562 => Loss: 22.8573753876\n",
      "Iteration 7563 => Loss: 22.8573598270\n",
      "Iteration 7564 => Loss: 22.8573442829\n",
      "Iteration 7565 => Loss: 22.8573287554\n",
      "Iteration 7566 => Loss: 22.8573132444\n",
      "Iteration 7567 => Loss: 22.8572977499\n",
      "Iteration 7568 => Loss: 22.8572822719\n",
      "Iteration 7569 => Loss: 22.8572668103\n",
      "Iteration 7570 => Loss: 22.8572513651\n",
      "Iteration 7571 => Loss: 22.8572359364\n",
      "Iteration 7572 => Loss: 22.8572205240\n",
      "Iteration 7573 => Loss: 22.8572051281\n",
      "Iteration 7574 => Loss: 22.8571897485\n",
      "Iteration 7575 => Loss: 22.8571743852\n",
      "Iteration 7576 => Loss: 22.8571590383\n",
      "Iteration 7577 => Loss: 22.8571437077\n",
      "Iteration 7578 => Loss: 22.8571283934\n",
      "Iteration 7579 => Loss: 22.8571130954\n",
      "Iteration 7580 => Loss: 22.8570978136\n",
      "Iteration 7581 => Loss: 22.8570825481\n",
      "Iteration 7582 => Loss: 22.8570672988\n",
      "Iteration 7583 => Loss: 22.8570520657\n",
      "Iteration 7584 => Loss: 22.8570368488\n",
      "Iteration 7585 => Loss: 22.8570216481\n",
      "Iteration 7586 => Loss: 22.8570064635\n",
      "Iteration 7587 => Loss: 22.8569912951\n",
      "Iteration 7588 => Loss: 22.8569761428\n",
      "Iteration 7589 => Loss: 22.8569610066\n",
      "Iteration 7590 => Loss: 22.8569458865\n",
      "Iteration 7591 => Loss: 22.8569307825\n",
      "Iteration 7592 => Loss: 22.8569156945\n",
      "Iteration 7593 => Loss: 22.8569006226\n",
      "Iteration 7594 => Loss: 22.8568855667\n",
      "Iteration 7595 => Loss: 22.8568705268\n",
      "Iteration 7596 => Loss: 22.8568555029\n",
      "Iteration 7597 => Loss: 22.8568404949\n",
      "Iteration 7598 => Loss: 22.8568255029\n",
      "Iteration 7599 => Loss: 22.8568105269\n",
      "Iteration 7600 => Loss: 22.8567955667\n",
      "Iteration 7601 => Loss: 22.8567806225\n",
      "Iteration 7602 => Loss: 22.8567656941\n",
      "Iteration 7603 => Loss: 22.8567507816\n",
      "Iteration 7604 => Loss: 22.8567358850\n",
      "Iteration 7605 => Loss: 22.8567210042\n",
      "Iteration 7606 => Loss: 22.8567061392\n",
      "Iteration 7607 => Loss: 22.8566912900\n",
      "Iteration 7608 => Loss: 22.8566764566\n",
      "Iteration 7609 => Loss: 22.8566616390\n",
      "Iteration 7610 => Loss: 22.8566468371\n",
      "Iteration 7611 => Loss: 22.8566320510\n",
      "Iteration 7612 => Loss: 22.8566172806\n",
      "Iteration 7613 => Loss: 22.8566025258\n",
      "Iteration 7614 => Loss: 22.8565877868\n",
      "Iteration 7615 => Loss: 22.8565730634\n",
      "Iteration 7616 => Loss: 22.8565583557\n",
      "Iteration 7617 => Loss: 22.8565436636\n",
      "Iteration 7618 => Loss: 22.8565289871\n",
      "Iteration 7619 => Loss: 22.8565143263\n",
      "Iteration 7620 => Loss: 22.8564996810\n",
      "Iteration 7621 => Loss: 22.8564850513\n",
      "Iteration 7622 => Loss: 22.8564704371\n",
      "Iteration 7623 => Loss: 22.8564558385\n",
      "Iteration 7624 => Loss: 22.8564412554\n",
      "Iteration 7625 => Loss: 22.8564266877\n",
      "Iteration 7626 => Loss: 22.8564121356\n",
      "Iteration 7627 => Loss: 22.8563975990\n",
      "Iteration 7628 => Loss: 22.8563830777\n",
      "Iteration 7629 => Loss: 22.8563685720\n",
      "Iteration 7630 => Loss: 22.8563540816\n",
      "Iteration 7631 => Loss: 22.8563396067\n",
      "Iteration 7632 => Loss: 22.8563251471\n",
      "Iteration 7633 => Loss: 22.8563107029\n",
      "Iteration 7634 => Loss: 22.8562962741\n",
      "Iteration 7635 => Loss: 22.8562818606\n",
      "Iteration 7636 => Loss: 22.8562674624\n",
      "Iteration 7637 => Loss: 22.8562530795\n",
      "Iteration 7638 => Loss: 22.8562387119\n",
      "Iteration 7639 => Loss: 22.8562243596\n",
      "Iteration 7640 => Loss: 22.8562100226\n",
      "Iteration 7641 => Loss: 22.8561957007\n",
      "Iteration 7642 => Loss: 22.8561813941\n",
      "Iteration 7643 => Loss: 22.8561671028\n",
      "Iteration 7644 => Loss: 22.8561528266\n",
      "Iteration 7645 => Loss: 22.8561385655\n",
      "Iteration 7646 => Loss: 22.8561243197\n",
      "Iteration 7647 => Loss: 22.8561100890\n",
      "Iteration 7648 => Loss: 22.8560958734\n",
      "Iteration 7649 => Loss: 22.8560816729\n",
      "Iteration 7650 => Loss: 22.8560674875\n",
      "Iteration 7651 => Loss: 22.8560533172\n",
      "Iteration 7652 => Loss: 22.8560391620\n",
      "Iteration 7653 => Loss: 22.8560250218\n",
      "Iteration 7654 => Loss: 22.8560108966\n",
      "Iteration 7655 => Loss: 22.8559967864\n",
      "Iteration 7656 => Loss: 22.8559826913\n",
      "Iteration 7657 => Loss: 22.8559686111\n",
      "Iteration 7658 => Loss: 22.8559545459\n",
      "Iteration 7659 => Loss: 22.8559404957\n",
      "Iteration 7660 => Loss: 22.8559264603\n",
      "Iteration 7661 => Loss: 22.8559124399\n",
      "Iteration 7662 => Loss: 22.8558984345\n",
      "Iteration 7663 => Loss: 22.8558844438\n",
      "Iteration 7664 => Loss: 22.8558704681\n",
      "Iteration 7665 => Loss: 22.8558565072\n",
      "Iteration 7666 => Loss: 22.8558425612\n",
      "Iteration 7667 => Loss: 22.8558286300\n",
      "Iteration 7668 => Loss: 22.8558147136\n",
      "Iteration 7669 => Loss: 22.8558008120\n",
      "Iteration 7670 => Loss: 22.8557869251\n",
      "Iteration 7671 => Loss: 22.8557730531\n",
      "Iteration 7672 => Loss: 22.8557591957\n",
      "Iteration 7673 => Loss: 22.8557453531\n",
      "Iteration 7674 => Loss: 22.8557315252\n",
      "Iteration 7675 => Loss: 22.8557177121\n",
      "Iteration 7676 => Loss: 22.8557039135\n",
      "Iteration 7677 => Loss: 22.8556901297\n",
      "Iteration 7678 => Loss: 22.8556763605\n",
      "Iteration 7679 => Loss: 22.8556626060\n",
      "Iteration 7680 => Loss: 22.8556488661\n",
      "Iteration 7681 => Loss: 22.8556351407\n",
      "Iteration 7682 => Loss: 22.8556214300\n",
      "Iteration 7683 => Loss: 22.8556077338\n",
      "Iteration 7684 => Loss: 22.8555940523\n",
      "Iteration 7685 => Loss: 22.8555803852\n",
      "Iteration 7686 => Loss: 22.8555667327\n",
      "Iteration 7687 => Loss: 22.8555530947\n",
      "Iteration 7688 => Loss: 22.8555394711\n",
      "Iteration 7689 => Loss: 22.8555258621\n",
      "Iteration 7690 => Loss: 22.8555122675\n",
      "Iteration 7691 => Loss: 22.8554986874\n",
      "Iteration 7692 => Loss: 22.8554851217\n",
      "Iteration 7693 => Loss: 22.8554715705\n",
      "Iteration 7694 => Loss: 22.8554580336\n",
      "Iteration 7695 => Loss: 22.8554445111\n",
      "Iteration 7696 => Loss: 22.8554310030\n",
      "Iteration 7697 => Loss: 22.8554175093\n",
      "Iteration 7698 => Loss: 22.8554040299\n",
      "Iteration 7699 => Loss: 22.8553905648\n",
      "Iteration 7700 => Loss: 22.8553771141\n",
      "Iteration 7701 => Loss: 22.8553636776\n",
      "Iteration 7702 => Loss: 22.8553502555\n",
      "Iteration 7703 => Loss: 22.8553368476\n",
      "Iteration 7704 => Loss: 22.8553234539\n",
      "Iteration 7705 => Loss: 22.8553100745\n",
      "Iteration 7706 => Loss: 22.8552967093\n",
      "Iteration 7707 => Loss: 22.8552833583\n",
      "Iteration 7708 => Loss: 22.8552700215\n",
      "Iteration 7709 => Loss: 22.8552566989\n",
      "Iteration 7710 => Loss: 22.8552433904\n",
      "Iteration 7711 => Loss: 22.8552300961\n",
      "Iteration 7712 => Loss: 22.8552168160\n",
      "Iteration 7713 => Loss: 22.8552035499\n",
      "Iteration 7714 => Loss: 22.8551902979\n",
      "Iteration 7715 => Loss: 22.8551770601\n",
      "Iteration 7716 => Loss: 22.8551638363\n",
      "Iteration 7717 => Loss: 22.8551506265\n",
      "Iteration 7718 => Loss: 22.8551374308\n",
      "Iteration 7719 => Loss: 22.8551242491\n",
      "Iteration 7720 => Loss: 22.8551110815\n",
      "Iteration 7721 => Loss: 22.8550979278\n",
      "Iteration 7722 => Loss: 22.8550847881\n",
      "Iteration 7723 => Loss: 22.8550716624\n",
      "Iteration 7724 => Loss: 22.8550585506\n",
      "Iteration 7725 => Loss: 22.8550454528\n",
      "Iteration 7726 => Loss: 22.8550323689\n",
      "Iteration 7727 => Loss: 22.8550192989\n",
      "Iteration 7728 => Loss: 22.8550062428\n",
      "Iteration 7729 => Loss: 22.8549932006\n",
      "Iteration 7730 => Loss: 22.8549801722\n",
      "Iteration 7731 => Loss: 22.8549671577\n",
      "Iteration 7732 => Loss: 22.8549541570\n",
      "Iteration 7733 => Loss: 22.8549411702\n",
      "Iteration 7734 => Loss: 22.8549281971\n",
      "Iteration 7735 => Loss: 22.8549152378\n",
      "Iteration 7736 => Loss: 22.8549022924\n",
      "Iteration 7737 => Loss: 22.8548893606\n",
      "Iteration 7738 => Loss: 22.8548764426\n",
      "Iteration 7739 => Loss: 22.8548635384\n",
      "Iteration 7740 => Loss: 22.8548506479\n",
      "Iteration 7741 => Loss: 22.8548377710\n",
      "Iteration 7742 => Loss: 22.8548249079\n",
      "Iteration 7743 => Loss: 22.8548120584\n",
      "Iteration 7744 => Loss: 22.8547992226\n",
      "Iteration 7745 => Loss: 22.8547864004\n",
      "Iteration 7746 => Loss: 22.8547735919\n",
      "Iteration 7747 => Loss: 22.8547607970\n",
      "Iteration 7748 => Loss: 22.8547480157\n",
      "Iteration 7749 => Loss: 22.8547352479\n",
      "Iteration 7750 => Loss: 22.8547224938\n",
      "Iteration 7751 => Loss: 22.8547097531\n",
      "Iteration 7752 => Loss: 22.8546970261\n",
      "Iteration 7753 => Loss: 22.8546843125\n",
      "Iteration 7754 => Loss: 22.8546716125\n",
      "Iteration 7755 => Loss: 22.8546589260\n",
      "Iteration 7756 => Loss: 22.8546462530\n",
      "Iteration 7757 => Loss: 22.8546335934\n",
      "Iteration 7758 => Loss: 22.8546209473\n",
      "Iteration 7759 => Loss: 22.8546083146\n",
      "Iteration 7760 => Loss: 22.8545956954\n",
      "Iteration 7761 => Loss: 22.8545830896\n",
      "Iteration 7762 => Loss: 22.8545704971\n",
      "Iteration 7763 => Loss: 22.8545579181\n",
      "Iteration 7764 => Loss: 22.8545453524\n",
      "Iteration 7765 => Loss: 22.8545328001\n",
      "Iteration 7766 => Loss: 22.8545202612\n",
      "Iteration 7767 => Loss: 22.8545077355\n",
      "Iteration 7768 => Loss: 22.8544952232\n",
      "Iteration 7769 => Loss: 22.8544827242\n",
      "Iteration 7770 => Loss: 22.8544702384\n",
      "Iteration 7771 => Loss: 22.8544577660\n",
      "Iteration 7772 => Loss: 22.8544453068\n",
      "Iteration 7773 => Loss: 22.8544328608\n",
      "Iteration 7774 => Loss: 22.8544204281\n",
      "Iteration 7775 => Loss: 22.8544080086\n",
      "Iteration 7776 => Loss: 22.8543956022\n",
      "Iteration 7777 => Loss: 22.8543832091\n",
      "Iteration 7778 => Loss: 22.8543708292\n",
      "Iteration 7779 => Loss: 22.8543584624\n",
      "Iteration 7780 => Loss: 22.8543461087\n",
      "Iteration 7781 => Loss: 22.8543337682\n",
      "Iteration 7782 => Loss: 22.8543214408\n",
      "Iteration 7783 => Loss: 22.8543091265\n",
      "Iteration 7784 => Loss: 22.8542968253\n",
      "Iteration 7785 => Loss: 22.8542845372\n",
      "Iteration 7786 => Loss: 22.8542722621\n",
      "Iteration 7787 => Loss: 22.8542600001\n",
      "Iteration 7788 => Loss: 22.8542477511\n",
      "Iteration 7789 => Loss: 22.8542355151\n",
      "Iteration 7790 => Loss: 22.8542232922\n",
      "Iteration 7791 => Loss: 22.8542110822\n",
      "Iteration 7792 => Loss: 22.8541988852\n",
      "Iteration 7793 => Loss: 22.8541867012\n",
      "Iteration 7794 => Loss: 22.8541745301\n",
      "Iteration 7795 => Loss: 22.8541623720\n",
      "Iteration 7796 => Loss: 22.8541502268\n",
      "Iteration 7797 => Loss: 22.8541380945\n",
      "Iteration 7798 => Loss: 22.8541259751\n",
      "Iteration 7799 => Loss: 22.8541138686\n",
      "Iteration 7800 => Loss: 22.8541017749\n",
      "Iteration 7801 => Loss: 22.8540896941\n",
      "Iteration 7802 => Loss: 22.8540776262\n",
      "Iteration 7803 => Loss: 22.8540655710\n",
      "Iteration 7804 => Loss: 22.8540535287\n",
      "Iteration 7805 => Loss: 22.8540414992\n",
      "Iteration 7806 => Loss: 22.8540294825\n",
      "Iteration 7807 => Loss: 22.8540174785\n",
      "Iteration 7808 => Loss: 22.8540054873\n",
      "Iteration 7809 => Loss: 22.8539935089\n",
      "Iteration 7810 => Loss: 22.8539815432\n",
      "Iteration 7811 => Loss: 22.8539695902\n",
      "Iteration 7812 => Loss: 22.8539576499\n",
      "Iteration 7813 => Loss: 22.8539457223\n",
      "Iteration 7814 => Loss: 22.8539338074\n",
      "Iteration 7815 => Loss: 22.8539219052\n",
      "Iteration 7816 => Loss: 22.8539100156\n",
      "Iteration 7817 => Loss: 22.8538981386\n",
      "Iteration 7818 => Loss: 22.8538862743\n",
      "Iteration 7819 => Loss: 22.8538744225\n",
      "Iteration 7820 => Loss: 22.8538625834\n",
      "Iteration 7821 => Loss: 22.8538507569\n",
      "Iteration 7822 => Loss: 22.8538389429\n",
      "Iteration 7823 => Loss: 22.8538271415\n",
      "Iteration 7824 => Loss: 22.8538153526\n",
      "Iteration 7825 => Loss: 22.8538035763\n",
      "Iteration 7826 => Loss: 22.8537918125\n",
      "Iteration 7827 => Loss: 22.8537800612\n",
      "Iteration 7828 => Loss: 22.8537683223\n",
      "Iteration 7829 => Loss: 22.8537565960\n",
      "Iteration 7830 => Loss: 22.8537448821\n",
      "Iteration 7831 => Loss: 22.8537331807\n",
      "Iteration 7832 => Loss: 22.8537214917\n",
      "Iteration 7833 => Loss: 22.8537098151\n",
      "Iteration 7834 => Loss: 22.8536981510\n",
      "Iteration 7835 => Loss: 22.8536864992\n",
      "Iteration 7836 => Loss: 22.8536748599\n",
      "Iteration 7837 => Loss: 22.8536632329\n",
      "Iteration 7838 => Loss: 22.8536516182\n",
      "Iteration 7839 => Loss: 22.8536400160\n",
      "Iteration 7840 => Loss: 22.8536284260\n",
      "Iteration 7841 => Loss: 22.8536168484\n",
      "Iteration 7842 => Loss: 22.8536052830\n",
      "Iteration 7843 => Loss: 22.8535937300\n",
      "Iteration 7844 => Loss: 22.8535821892\n",
      "Iteration 7845 => Loss: 22.8535706608\n",
      "Iteration 7846 => Loss: 22.8535591445\n",
      "Iteration 7847 => Loss: 22.8535476405\n",
      "Iteration 7848 => Loss: 22.8535361488\n",
      "Iteration 7849 => Loss: 22.8535246692\n",
      "Iteration 7850 => Loss: 22.8535132019\n",
      "Iteration 7851 => Loss: 22.8535017467\n",
      "Iteration 7852 => Loss: 22.8534903037\n",
      "Iteration 7853 => Loss: 22.8534788729\n",
      "Iteration 7854 => Loss: 22.8534674543\n",
      "Iteration 7855 => Loss: 22.8534560477\n",
      "Iteration 7856 => Loss: 22.8534446533\n",
      "Iteration 7857 => Loss: 22.8534332711\n",
      "Iteration 7858 => Loss: 22.8534219009\n",
      "Iteration 7859 => Loss: 22.8534105428\n",
      "Iteration 7860 => Loss: 22.8533991967\n",
      "Iteration 7861 => Loss: 22.8533878628\n",
      "Iteration 7862 => Loss: 22.8533765408\n",
      "Iteration 7863 => Loss: 22.8533652309\n",
      "Iteration 7864 => Loss: 22.8533539331\n",
      "Iteration 7865 => Loss: 22.8533426472\n",
      "Iteration 7866 => Loss: 22.8533313734\n",
      "Iteration 7867 => Loss: 22.8533201115\n",
      "Iteration 7868 => Loss: 22.8533088616\n",
      "Iteration 7869 => Loss: 22.8532976236\n",
      "Iteration 7870 => Loss: 22.8532863976\n",
      "Iteration 7871 => Loss: 22.8532751836\n",
      "Iteration 7872 => Loss: 22.8532639814\n",
      "Iteration 7873 => Loss: 22.8532527912\n",
      "Iteration 7874 => Loss: 22.8532416128\n",
      "Iteration 7875 => Loss: 22.8532304464\n",
      "Iteration 7876 => Loss: 22.8532192918\n",
      "Iteration 7877 => Loss: 22.8532081491\n",
      "Iteration 7878 => Loss: 22.8531970182\n",
      "Iteration 7879 => Loss: 22.8531858991\n",
      "Iteration 7880 => Loss: 22.8531747919\n",
      "Iteration 7881 => Loss: 22.8531636964\n",
      "Iteration 7882 => Loss: 22.8531526128\n",
      "Iteration 7883 => Loss: 22.8531415409\n",
      "Iteration 7884 => Loss: 22.8531304809\n",
      "Iteration 7885 => Loss: 22.8531194325\n",
      "Iteration 7886 => Loss: 22.8531083959\n",
      "Iteration 7887 => Loss: 22.8530973711\n",
      "Iteration 7888 => Loss: 22.8530863579\n",
      "Iteration 7889 => Loss: 22.8530753565\n",
      "Iteration 7890 => Loss: 22.8530643668\n",
      "Iteration 7891 => Loss: 22.8530533887\n",
      "Iteration 7892 => Loss: 22.8530424223\n",
      "Iteration 7893 => Loss: 22.8530314676\n",
      "Iteration 7894 => Loss: 22.8530205245\n",
      "Iteration 7895 => Loss: 22.8530095931\n",
      "Iteration 7896 => Loss: 22.8529986733\n",
      "Iteration 7897 => Loss: 22.8529877650\n",
      "Iteration 7898 => Loss: 22.8529768684\n",
      "Iteration 7899 => Loss: 22.8529659834\n",
      "Iteration 7900 => Loss: 22.8529551099\n",
      "Iteration 7901 => Loss: 22.8529442480\n",
      "Iteration 7902 => Loss: 22.8529333976\n",
      "Iteration 7903 => Loss: 22.8529225588\n",
      "Iteration 7904 => Loss: 22.8529117315\n",
      "Iteration 7905 => Loss: 22.8529009156\n",
      "Iteration 7906 => Loss: 22.8528901113\n",
      "Iteration 7907 => Loss: 22.8528793185\n",
      "Iteration 7908 => Loss: 22.8528685372\n",
      "Iteration 7909 => Loss: 22.8528577673\n",
      "Iteration 7910 => Loss: 22.8528470088\n",
      "Iteration 7911 => Loss: 22.8528362618\n",
      "Iteration 7912 => Loss: 22.8528255262\n",
      "Iteration 7913 => Loss: 22.8528148021\n",
      "Iteration 7914 => Loss: 22.8528040893\n",
      "Iteration 7915 => Loss: 22.8527933879\n",
      "Iteration 7916 => Loss: 22.8527826979\n",
      "Iteration 7917 => Loss: 22.8527720193\n",
      "Iteration 7918 => Loss: 22.8527613520\n",
      "Iteration 7919 => Loss: 22.8527506960\n",
      "Iteration 7920 => Loss: 22.8527400514\n",
      "Iteration 7921 => Loss: 22.8527294181\n",
      "Iteration 7922 => Loss: 22.8527187961\n",
      "Iteration 7923 => Loss: 22.8527081854\n",
      "Iteration 7924 => Loss: 22.8526975859\n",
      "Iteration 7925 => Loss: 22.8526869977\n",
      "Iteration 7926 => Loss: 22.8526764208\n",
      "Iteration 7927 => Loss: 22.8526658551\n",
      "Iteration 7928 => Loss: 22.8526553007\n",
      "Iteration 7929 => Loss: 22.8526447575\n",
      "Iteration 7930 => Loss: 22.8526342255\n",
      "Iteration 7931 => Loss: 22.8526237046\n",
      "Iteration 7932 => Loss: 22.8526131950\n",
      "Iteration 7933 => Loss: 22.8526026965\n",
      "Iteration 7934 => Loss: 22.8525922092\n",
      "Iteration 7935 => Loss: 22.8525817331\n",
      "Iteration 7936 => Loss: 22.8525712680\n",
      "Iteration 7937 => Loss: 22.8525608141\n",
      "Iteration 7938 => Loss: 22.8525503714\n",
      "Iteration 7939 => Loss: 22.8525399397\n",
      "Iteration 7940 => Loss: 22.8525295191\n",
      "Iteration 7941 => Loss: 22.8525191096\n",
      "Iteration 7942 => Loss: 22.8525087111\n",
      "Iteration 7943 => Loss: 22.8524983237\n",
      "Iteration 7944 => Loss: 22.8524879473\n",
      "Iteration 7945 => Loss: 22.8524775820\n",
      "Iteration 7946 => Loss: 22.8524672277\n",
      "Iteration 7947 => Loss: 22.8524568844\n",
      "Iteration 7948 => Loss: 22.8524465521\n",
      "Iteration 7949 => Loss: 22.8524362307\n",
      "Iteration 7950 => Loss: 22.8524259204\n",
      "Iteration 7951 => Loss: 22.8524156210\n",
      "Iteration 7952 => Loss: 22.8524053325\n",
      "Iteration 7953 => Loss: 22.8523950550\n",
      "Iteration 7954 => Loss: 22.8523847884\n",
      "Iteration 7955 => Loss: 22.8523745328\n",
      "Iteration 7956 => Loss: 22.8523642880\n",
      "Iteration 7957 => Loss: 22.8523540541\n",
      "Iteration 7958 => Loss: 22.8523438311\n",
      "Iteration 7959 => Loss: 22.8523336190\n",
      "Iteration 7960 => Loss: 22.8523234177\n",
      "Iteration 7961 => Loss: 22.8523132272\n",
      "Iteration 7962 => Loss: 22.8523030476\n",
      "Iteration 7963 => Loss: 22.8522928788\n",
      "Iteration 7964 => Loss: 22.8522827209\n",
      "Iteration 7965 => Loss: 22.8522725737\n",
      "Iteration 7966 => Loss: 22.8522624373\n",
      "Iteration 7967 => Loss: 22.8522523117\n",
      "Iteration 7968 => Loss: 22.8522421968\n",
      "Iteration 7969 => Loss: 22.8522320927\n",
      "Iteration 7970 => Loss: 22.8522219993\n",
      "Iteration 7971 => Loss: 22.8522119167\n",
      "Iteration 7972 => Loss: 22.8522018448\n",
      "Iteration 7973 => Loss: 22.8521917836\n",
      "Iteration 7974 => Loss: 22.8521817331\n",
      "Iteration 7975 => Loss: 22.8521716932\n",
      "Iteration 7976 => Loss: 22.8521616641\n",
      "Iteration 7977 => Loss: 22.8521516456\n",
      "Iteration 7978 => Loss: 22.8521416377\n",
      "Iteration 7979 => Loss: 22.8521316405\n",
      "Iteration 7980 => Loss: 22.8521216539\n",
      "Iteration 7981 => Loss: 22.8521116780\n",
      "Iteration 7982 => Loss: 22.8521017126\n",
      "Iteration 7983 => Loss: 22.8520917578\n",
      "Iteration 7984 => Loss: 22.8520818136\n",
      "Iteration 7985 => Loss: 22.8520718800\n",
      "Iteration 7986 => Loss: 22.8520619570\n",
      "Iteration 7987 => Loss: 22.8520520444\n",
      "Iteration 7988 => Loss: 22.8520421425\n",
      "Iteration 7989 => Loss: 22.8520322510\n",
      "Iteration 7990 => Loss: 22.8520223701\n",
      "Iteration 7991 => Loss: 22.8520124996\n",
      "Iteration 7992 => Loss: 22.8520026397\n",
      "Iteration 7993 => Loss: 22.8519927902\n",
      "Iteration 7994 => Loss: 22.8519829513\n",
      "Iteration 7995 => Loss: 22.8519731227\n",
      "Iteration 7996 => Loss: 22.8519633046\n",
      "Iteration 7997 => Loss: 22.8519534970\n",
      "Iteration 7998 => Loss: 22.8519436998\n",
      "Iteration 7999 => Loss: 22.8519339130\n",
      "Iteration 8000 => Loss: 22.8519241366\n",
      "Iteration 8001 => Loss: 22.8519143705\n",
      "Iteration 8002 => Loss: 22.8519046149\n",
      "Iteration 8003 => Loss: 22.8518948697\n",
      "Iteration 8004 => Loss: 22.8518851347\n",
      "Iteration 8005 => Loss: 22.8518754102\n",
      "Iteration 8006 => Loss: 22.8518656960\n",
      "Iteration 8007 => Loss: 22.8518559921\n",
      "Iteration 8008 => Loss: 22.8518462985\n",
      "Iteration 8009 => Loss: 22.8518366152\n",
      "Iteration 8010 => Loss: 22.8518269423\n",
      "Iteration 8011 => Loss: 22.8518172796\n",
      "Iteration 8012 => Loss: 22.8518076271\n",
      "Iteration 8013 => Loss: 22.8517979850\n",
      "Iteration 8014 => Loss: 22.8517883531\n",
      "Iteration 8015 => Loss: 22.8517787314\n",
      "Iteration 8016 => Loss: 22.8517691199\n",
      "Iteration 8017 => Loss: 22.8517595187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8018 => Loss: 22.8517499277\n",
      "Iteration 8019 => Loss: 22.8517403468\n",
      "Iteration 8020 => Loss: 22.8517307762\n",
      "Iteration 8021 => Loss: 22.8517212157\n",
      "Iteration 8022 => Loss: 22.8517116654\n",
      "Iteration 8023 => Loss: 22.8517021252\n",
      "Iteration 8024 => Loss: 22.8516925952\n",
      "Iteration 8025 => Loss: 22.8516830753\n",
      "Iteration 8026 => Loss: 22.8516735656\n",
      "Iteration 8027 => Loss: 22.8516640659\n",
      "Iteration 8028 => Loss: 22.8516545763\n",
      "Iteration 8029 => Loss: 22.8516450969\n",
      "Iteration 8030 => Loss: 22.8516356275\n",
      "Iteration 8031 => Loss: 22.8516261681\n",
      "Iteration 8032 => Loss: 22.8516167189\n",
      "Iteration 8033 => Loss: 22.8516072796\n",
      "Iteration 8034 => Loss: 22.8515978504\n",
      "Iteration 8035 => Loss: 22.8515884312\n",
      "Iteration 8036 => Loss: 22.8515790221\n",
      "Iteration 8037 => Loss: 22.8515696229\n",
      "Iteration 8038 => Loss: 22.8515602337\n",
      "Iteration 8039 => Loss: 22.8515508545\n",
      "Iteration 8040 => Loss: 22.8515414853\n",
      "Iteration 8041 => Loss: 22.8515321261\n",
      "Iteration 8042 => Loss: 22.8515227768\n",
      "Iteration 8043 => Loss: 22.8515134374\n",
      "Iteration 8044 => Loss: 22.8515041079\n",
      "Iteration 8045 => Loss: 22.8514947884\n",
      "Iteration 8046 => Loss: 22.8514854788\n",
      "Iteration 8047 => Loss: 22.8514761790\n",
      "Iteration 8048 => Loss: 22.8514668892\n",
      "Iteration 8049 => Loss: 22.8514576092\n",
      "Iteration 8050 => Loss: 22.8514483391\n",
      "Iteration 8051 => Loss: 22.8514390789\n",
      "Iteration 8052 => Loss: 22.8514298285\n",
      "Iteration 8053 => Loss: 22.8514205879\n",
      "Iteration 8054 => Loss: 22.8514113571\n",
      "Iteration 8055 => Loss: 22.8514021362\n",
      "Iteration 8056 => Loss: 22.8513929251\n",
      "Iteration 8057 => Loss: 22.8513837237\n",
      "Iteration 8058 => Loss: 22.8513745322\n",
      "Iteration 8059 => Loss: 22.8513653504\n",
      "Iteration 8060 => Loss: 22.8513561783\n",
      "Iteration 8061 => Loss: 22.8513470160\n",
      "Iteration 8062 => Loss: 22.8513378635\n",
      "Iteration 8063 => Loss: 22.8513287207\n",
      "Iteration 8064 => Loss: 22.8513195876\n",
      "Iteration 8065 => Loss: 22.8513104642\n",
      "Iteration 8066 => Loss: 22.8513013505\n",
      "Iteration 8067 => Loss: 22.8512922465\n",
      "Iteration 8068 => Loss: 22.8512831522\n",
      "Iteration 8069 => Loss: 22.8512740675\n",
      "Iteration 8070 => Loss: 22.8512649925\n",
      "Iteration 8071 => Loss: 22.8512559272\n",
      "Iteration 8072 => Loss: 22.8512468714\n",
      "Iteration 8073 => Loss: 22.8512378253\n",
      "Iteration 8074 => Loss: 22.8512287889\n",
      "Iteration 8075 => Loss: 22.8512197620\n",
      "Iteration 8076 => Loss: 22.8512107447\n",
      "Iteration 8077 => Loss: 22.8512017370\n",
      "Iteration 8078 => Loss: 22.8511927389\n",
      "Iteration 8079 => Loss: 22.8511837504\n",
      "Iteration 8080 => Loss: 22.8511747714\n",
      "Iteration 8081 => Loss: 22.8511658019\n",
      "Iteration 8082 => Loss: 22.8511568420\n",
      "Iteration 8083 => Loss: 22.8511478916\n",
      "Iteration 8084 => Loss: 22.8511389507\n",
      "Iteration 8085 => Loss: 22.8511300193\n",
      "Iteration 8086 => Loss: 22.8511210974\n",
      "Iteration 8087 => Loss: 22.8511121850\n",
      "Iteration 8088 => Loss: 22.8511032821\n",
      "Iteration 8089 => Loss: 22.8510943887\n",
      "Iteration 8090 => Loss: 22.8510855047\n",
      "Iteration 8091 => Loss: 22.8510766301\n",
      "Iteration 8092 => Loss: 22.8510677650\n",
      "Iteration 8093 => Loss: 22.8510589092\n",
      "Iteration 8094 => Loss: 22.8510500630\n",
      "Iteration 8095 => Loss: 22.8510412261\n",
      "Iteration 8096 => Loss: 22.8510323986\n",
      "Iteration 8097 => Loss: 22.8510235805\n",
      "Iteration 8098 => Loss: 22.8510147717\n",
      "Iteration 8099 => Loss: 22.8510059723\n",
      "Iteration 8100 => Loss: 22.8509971823\n",
      "Iteration 8101 => Loss: 22.8509884016\n",
      "Iteration 8102 => Loss: 22.8509796303\n",
      "Iteration 8103 => Loss: 22.8509708683\n",
      "Iteration 8104 => Loss: 22.8509621156\n",
      "Iteration 8105 => Loss: 22.8509533722\n",
      "Iteration 8106 => Loss: 22.8509446380\n",
      "Iteration 8107 => Loss: 22.8509359132\n",
      "Iteration 8108 => Loss: 22.8509271977\n",
      "Iteration 8109 => Loss: 22.8509184914\n",
      "Iteration 8110 => Loss: 22.8509097943\n",
      "Iteration 8111 => Loss: 22.8509011066\n",
      "Iteration 8112 => Loss: 22.8508924280\n",
      "Iteration 8113 => Loss: 22.8508837587\n",
      "Iteration 8114 => Loss: 22.8508750986\n",
      "Iteration 8115 => Loss: 22.8508664477\n",
      "Iteration 8116 => Loss: 22.8508578059\n",
      "Iteration 8117 => Loss: 22.8508491734\n",
      "Iteration 8118 => Loss: 22.8508405501\n",
      "Iteration 8119 => Loss: 22.8508319359\n",
      "Iteration 8120 => Loss: 22.8508233309\n",
      "Iteration 8121 => Loss: 22.8508147350\n",
      "Iteration 8122 => Loss: 22.8508061482\n",
      "Iteration 8123 => Loss: 22.8507975706\n",
      "Iteration 8124 => Loss: 22.8507890021\n",
      "Iteration 8125 => Loss: 22.8507804427\n",
      "Iteration 8126 => Loss: 22.8507718924\n",
      "Iteration 8127 => Loss: 22.8507633512\n",
      "Iteration 8128 => Loss: 22.8507548191\n",
      "Iteration 8129 => Loss: 22.8507462961\n",
      "Iteration 8130 => Loss: 22.8507377821\n",
      "Iteration 8131 => Loss: 22.8507292771\n",
      "Iteration 8132 => Loss: 22.8507207812\n",
      "Iteration 8133 => Loss: 22.8507122944\n",
      "Iteration 8134 => Loss: 22.8507038165\n",
      "Iteration 8135 => Loss: 22.8506953477\n",
      "Iteration 8136 => Loss: 22.8506868878\n",
      "Iteration 8137 => Loss: 22.8506784370\n",
      "Iteration 8138 => Loss: 22.8506699951\n",
      "Iteration 8139 => Loss: 22.8506615622\n",
      "Iteration 8140 => Loss: 22.8506531383\n",
      "Iteration 8141 => Loss: 22.8506447234\n",
      "Iteration 8142 => Loss: 22.8506363173\n",
      "Iteration 8143 => Loss: 22.8506279202\n",
      "Iteration 8144 => Loss: 22.8506195321\n",
      "Iteration 8145 => Loss: 22.8506111528\n",
      "Iteration 8146 => Loss: 22.8506027825\n",
      "Iteration 8147 => Loss: 22.8505944211\n",
      "Iteration 8148 => Loss: 22.8505860685\n",
      "Iteration 8149 => Loss: 22.8505777248\n",
      "Iteration 8150 => Loss: 22.8505693900\n",
      "Iteration 8151 => Loss: 22.8505610641\n",
      "Iteration 8152 => Loss: 22.8505527470\n",
      "Iteration 8153 => Loss: 22.8505444387\n",
      "Iteration 8154 => Loss: 22.8505361393\n",
      "Iteration 8155 => Loss: 22.8505278487\n",
      "Iteration 8156 => Loss: 22.8505195669\n",
      "Iteration 8157 => Loss: 22.8505112939\n",
      "Iteration 8158 => Loss: 22.8505030297\n",
      "Iteration 8159 => Loss: 22.8504947743\n",
      "Iteration 8160 => Loss: 22.8504865277\n",
      "Iteration 8161 => Loss: 22.8504782898\n",
      "Iteration 8162 => Loss: 22.8504700607\n",
      "Iteration 8163 => Loss: 22.8504618404\n",
      "Iteration 8164 => Loss: 22.8504536287\n",
      "Iteration 8165 => Loss: 22.8504454258\n",
      "Iteration 8166 => Loss: 22.8504372317\n",
      "Iteration 8167 => Loss: 22.8504290462\n",
      "Iteration 8168 => Loss: 22.8504208694\n",
      "Iteration 8169 => Loss: 22.8504127014\n",
      "Iteration 8170 => Loss: 22.8504045420\n",
      "Iteration 8171 => Loss: 22.8503963913\n",
      "Iteration 8172 => Loss: 22.8503882492\n",
      "Iteration 8173 => Loss: 22.8503801158\n",
      "Iteration 8174 => Loss: 22.8503719911\n",
      "Iteration 8175 => Loss: 22.8503638750\n",
      "Iteration 8176 => Loss: 22.8503557675\n",
      "Iteration 8177 => Loss: 22.8503476686\n",
      "Iteration 8178 => Loss: 22.8503395783\n",
      "Iteration 8179 => Loss: 22.8503314967\n",
      "Iteration 8180 => Loss: 22.8503234236\n",
      "Iteration 8181 => Loss: 22.8503153591\n",
      "Iteration 8182 => Loss: 22.8503073032\n",
      "Iteration 8183 => Loss: 22.8502992558\n",
      "Iteration 8184 => Loss: 22.8502912171\n",
      "Iteration 8185 => Loss: 22.8502831868\n",
      "Iteration 8186 => Loss: 22.8502751651\n",
      "Iteration 8187 => Loss: 22.8502671519\n",
      "Iteration 8188 => Loss: 22.8502591472\n",
      "Iteration 8189 => Loss: 22.8502511511\n",
      "Iteration 8190 => Loss: 22.8502431634\n",
      "Iteration 8191 => Loss: 22.8502351842\n",
      "Iteration 8192 => Loss: 22.8502272135\n",
      "Iteration 8193 => Loss: 22.8502192513\n",
      "Iteration 8194 => Loss: 22.8502112975\n",
      "Iteration 8195 => Loss: 22.8502033522\n",
      "Iteration 8196 => Loss: 22.8501954154\n",
      "Iteration 8197 => Loss: 22.8501874870\n",
      "Iteration 8198 => Loss: 22.8501795670\n",
      "Iteration 8199 => Loss: 22.8501716554\n",
      "Iteration 8200 => Loss: 22.8501637522\n",
      "Iteration 8201 => Loss: 22.8501558575\n",
      "Iteration 8202 => Loss: 22.8501479711\n",
      "Iteration 8203 => Loss: 22.8501400931\n",
      "Iteration 8204 => Loss: 22.8501322235\n",
      "Iteration 8205 => Loss: 22.8501243623\n",
      "Iteration 8206 => Loss: 22.8501165094\n",
      "Iteration 8207 => Loss: 22.8501086648\n",
      "Iteration 8208 => Loss: 22.8501008286\n",
      "Iteration 8209 => Loss: 22.8500930008\n",
      "Iteration 8210 => Loss: 22.8500851812\n",
      "Iteration 8211 => Loss: 22.8500773700\n",
      "Iteration 8212 => Loss: 22.8500695670\n",
      "Iteration 8213 => Loss: 22.8500617724\n",
      "Iteration 8214 => Loss: 22.8500539860\n",
      "Iteration 8215 => Loss: 22.8500462079\n",
      "Iteration 8216 => Loss: 22.8500384381\n",
      "Iteration 8217 => Loss: 22.8500306766\n",
      "Iteration 8218 => Loss: 22.8500229233\n",
      "Iteration 8219 => Loss: 22.8500151782\n",
      "Iteration 8220 => Loss: 22.8500074414\n",
      "Iteration 8221 => Loss: 22.8499997128\n",
      "Iteration 8222 => Loss: 22.8499919924\n",
      "Iteration 8223 => Loss: 22.8499842802\n",
      "Iteration 8224 => Loss: 22.8499765762\n",
      "Iteration 8225 => Loss: 22.8499688804\n",
      "Iteration 8226 => Loss: 22.8499611928\n",
      "Iteration 8227 => Loss: 22.8499535133\n",
      "Iteration 8228 => Loss: 22.8499458421\n",
      "Iteration 8229 => Loss: 22.8499381789\n",
      "Iteration 8230 => Loss: 22.8499305240\n",
      "Iteration 8231 => Loss: 22.8499228771\n",
      "Iteration 8232 => Loss: 22.8499152384\n",
      "Iteration 8233 => Loss: 22.8499076078\n",
      "Iteration 8234 => Loss: 22.8498999853\n",
      "Iteration 8235 => Loss: 22.8498923709\n",
      "Iteration 8236 => Loss: 22.8498847646\n",
      "Iteration 8237 => Loss: 22.8498771664\n",
      "Iteration 8238 => Loss: 22.8498695763\n",
      "Iteration 8239 => Loss: 22.8498619942\n",
      "Iteration 8240 => Loss: 22.8498544202\n",
      "Iteration 8241 => Loss: 22.8498468543\n",
      "Iteration 8242 => Loss: 22.8498392964\n",
      "Iteration 8243 => Loss: 22.8498317465\n",
      "Iteration 8244 => Loss: 22.8498242047\n",
      "Iteration 8245 => Loss: 22.8498166708\n",
      "Iteration 8246 => Loss: 22.8498091450\n",
      "Iteration 8247 => Loss: 22.8498016272\n",
      "Iteration 8248 => Loss: 22.8497941174\n",
      "Iteration 8249 => Loss: 22.8497866155\n",
      "Iteration 8250 => Loss: 22.8497791217\n",
      "Iteration 8251 => Loss: 22.8497716357\n",
      "Iteration 8252 => Loss: 22.8497641578\n",
      "Iteration 8253 => Loss: 22.8497566878\n",
      "Iteration 8254 => Loss: 22.8497492257\n",
      "Iteration 8255 => Loss: 22.8497417716\n",
      "Iteration 8256 => Loss: 22.8497343254\n",
      "Iteration 8257 => Loss: 22.8497268871\n",
      "Iteration 8258 => Loss: 22.8497194567\n",
      "Iteration 8259 => Loss: 22.8497120342\n",
      "Iteration 8260 => Loss: 22.8497046197\n",
      "Iteration 8261 => Loss: 22.8496972129\n",
      "Iteration 8262 => Loss: 22.8496898141\n",
      "Iteration 8263 => Loss: 22.8496824231\n",
      "Iteration 8264 => Loss: 22.8496750400\n",
      "Iteration 8265 => Loss: 22.8496676647\n",
      "Iteration 8266 => Loss: 22.8496602973\n",
      "Iteration 8267 => Loss: 22.8496529377\n",
      "Iteration 8268 => Loss: 22.8496455859\n",
      "Iteration 8269 => Loss: 22.8496382420\n",
      "Iteration 8270 => Loss: 22.8496309058\n",
      "Iteration 8271 => Loss: 22.8496235775\n",
      "Iteration 8272 => Loss: 22.8496162569\n",
      "Iteration 8273 => Loss: 22.8496089441\n",
      "Iteration 8274 => Loss: 22.8496016391\n",
      "Iteration 8275 => Loss: 22.8495943418\n",
      "Iteration 8276 => Loss: 22.8495870524\n",
      "Iteration 8277 => Loss: 22.8495797706\n",
      "Iteration 8278 => Loss: 22.8495724966\n",
      "Iteration 8279 => Loss: 22.8495652303\n",
      "Iteration 8280 => Loss: 22.8495579718\n",
      "Iteration 8281 => Loss: 22.8495507210\n",
      "Iteration 8282 => Loss: 22.8495434778\n",
      "Iteration 8283 => Loss: 22.8495362424\n",
      "Iteration 8284 => Loss: 22.8495290147\n",
      "Iteration 8285 => Loss: 22.8495217946\n",
      "Iteration 8286 => Loss: 22.8495145823\n",
      "Iteration 8287 => Loss: 22.8495073776\n",
      "Iteration 8288 => Loss: 22.8495001805\n",
      "Iteration 8289 => Loss: 22.8494929911\n",
      "Iteration 8290 => Loss: 22.8494858094\n",
      "Iteration 8291 => Loss: 22.8494786352\n",
      "Iteration 8292 => Loss: 22.8494714687\n",
      "Iteration 8293 => Loss: 22.8494643099\n",
      "Iteration 8294 => Loss: 22.8494571586\n",
      "Iteration 8295 => Loss: 22.8494500149\n",
      "Iteration 8296 => Loss: 22.8494428788\n",
      "Iteration 8297 => Loss: 22.8494357504\n",
      "Iteration 8298 => Loss: 22.8494286294\n",
      "Iteration 8299 => Loss: 22.8494215161\n",
      "Iteration 8300 => Loss: 22.8494144103\n",
      "Iteration 8301 => Loss: 22.8494073121\n",
      "Iteration 8302 => Loss: 22.8494002214\n",
      "Iteration 8303 => Loss: 22.8493931383\n",
      "Iteration 8304 => Loss: 22.8493860627\n",
      "Iteration 8305 => Loss: 22.8493789946\n",
      "Iteration 8306 => Loss: 22.8493719340\n",
      "Iteration 8307 => Loss: 22.8493648809\n",
      "Iteration 8308 => Loss: 22.8493578353\n",
      "Iteration 8309 => Loss: 22.8493507972\n",
      "Iteration 8310 => Loss: 22.8493437666\n",
      "Iteration 8311 => Loss: 22.8493367435\n",
      "Iteration 8312 => Loss: 22.8493297278\n",
      "Iteration 8313 => Loss: 22.8493227196\n",
      "Iteration 8314 => Loss: 22.8493157189\n",
      "Iteration 8315 => Loss: 22.8493087255\n",
      "Iteration 8316 => Loss: 22.8493017397\n",
      "Iteration 8317 => Loss: 22.8492947612\n",
      "Iteration 8318 => Loss: 22.8492877902\n",
      "Iteration 8319 => Loss: 22.8492808265\n",
      "Iteration 8320 => Loss: 22.8492738703\n",
      "Iteration 8321 => Loss: 22.8492669215\n",
      "Iteration 8322 => Loss: 22.8492599800\n",
      "Iteration 8323 => Loss: 22.8492530459\n",
      "Iteration 8324 => Loss: 22.8492461192\n",
      "Iteration 8325 => Loss: 22.8492391999\n",
      "Iteration 8326 => Loss: 22.8492322879\n",
      "Iteration 8327 => Loss: 22.8492253833\n",
      "Iteration 8328 => Loss: 22.8492184860\n",
      "Iteration 8329 => Loss: 22.8492115960\n",
      "Iteration 8330 => Loss: 22.8492047134\n",
      "Iteration 8331 => Loss: 22.8491978381\n",
      "Iteration 8332 => Loss: 22.8491909700\n",
      "Iteration 8333 => Loss: 22.8491841093\n",
      "Iteration 8334 => Loss: 22.8491772559\n",
      "Iteration 8335 => Loss: 22.8491704098\n",
      "Iteration 8336 => Loss: 22.8491635709\n",
      "Iteration 8337 => Loss: 22.8491567393\n",
      "Iteration 8338 => Loss: 22.8491499150\n",
      "Iteration 8339 => Loss: 22.8491430979\n",
      "Iteration 8340 => Loss: 22.8491362881\n",
      "Iteration 8341 => Loss: 22.8491294855\n",
      "Iteration 8342 => Loss: 22.8491226901\n",
      "Iteration 8343 => Loss: 22.8491159020\n",
      "Iteration 8344 => Loss: 22.8491091211\n",
      "Iteration 8345 => Loss: 22.8491023474\n",
      "Iteration 8346 => Loss: 22.8490955809\n",
      "Iteration 8347 => Loss: 22.8490888216\n",
      "Iteration 8348 => Loss: 22.8490820694\n",
      "Iteration 8349 => Loss: 22.8490753245\n",
      "Iteration 8350 => Loss: 22.8490685867\n",
      "Iteration 8351 => Loss: 22.8490618561\n",
      "Iteration 8352 => Loss: 22.8490551326\n",
      "Iteration 8353 => Loss: 22.8490484163\n",
      "Iteration 8354 => Loss: 22.8490417071\n",
      "Iteration 8355 => Loss: 22.8490350050\n",
      "Iteration 8356 => Loss: 22.8490283101\n",
      "Iteration 8357 => Loss: 22.8490216223\n",
      "Iteration 8358 => Loss: 22.8490149416\n",
      "Iteration 8359 => Loss: 22.8490082680\n",
      "Iteration 8360 => Loss: 22.8490016015\n",
      "Iteration 8361 => Loss: 22.8489949421\n",
      "Iteration 8362 => Loss: 22.8489882897\n",
      "Iteration 8363 => Loss: 22.8489816445\n",
      "Iteration 8364 => Loss: 22.8489750062\n",
      "Iteration 8365 => Loss: 22.8489683751\n",
      "Iteration 8366 => Loss: 22.8489617510\n",
      "Iteration 8367 => Loss: 22.8489551339\n",
      "Iteration 8368 => Loss: 22.8489485239\n",
      "Iteration 8369 => Loss: 22.8489419209\n",
      "Iteration 8370 => Loss: 22.8489353249\n",
      "Iteration 8371 => Loss: 22.8489287360\n",
      "Iteration 8372 => Loss: 22.8489221540\n",
      "Iteration 8373 => Loss: 22.8489155790\n",
      "Iteration 8374 => Loss: 22.8489090110\n",
      "Iteration 8375 => Loss: 22.8489024501\n",
      "Iteration 8376 => Loss: 22.8488958960\n",
      "Iteration 8377 => Loss: 22.8488893490\n",
      "Iteration 8378 => Loss: 22.8488828089\n",
      "Iteration 8379 => Loss: 22.8488762757\n",
      "Iteration 8380 => Loss: 22.8488697495\n",
      "Iteration 8381 => Loss: 22.8488632303\n",
      "Iteration 8382 => Loss: 22.8488567179\n",
      "Iteration 8383 => Loss: 22.8488502125\n",
      "Iteration 8384 => Loss: 22.8488437140\n",
      "Iteration 8385 => Loss: 22.8488372224\n",
      "Iteration 8386 => Loss: 22.8488307377\n",
      "Iteration 8387 => Loss: 22.8488242599\n",
      "Iteration 8388 => Loss: 22.8488177890\n",
      "Iteration 8389 => Loss: 22.8488113250\n",
      "Iteration 8390 => Loss: 22.8488048678\n",
      "Iteration 8391 => Loss: 22.8487984176\n",
      "Iteration 8392 => Loss: 22.8487919741\n",
      "Iteration 8393 => Loss: 22.8487855375\n",
      "Iteration 8394 => Loss: 22.8487791078\n",
      "Iteration 8395 => Loss: 22.8487726849\n",
      "Iteration 8396 => Loss: 22.8487662688\n",
      "Iteration 8397 => Loss: 22.8487598595\n",
      "Iteration 8398 => Loss: 22.8487534571\n",
      "Iteration 8399 => Loss: 22.8487470614\n",
      "Iteration 8400 => Loss: 22.8487406726\n",
      "Iteration 8401 => Loss: 22.8487342905\n",
      "Iteration 8402 => Loss: 22.8487279152\n",
      "Iteration 8403 => Loss: 22.8487215467\n",
      "Iteration 8404 => Loss: 22.8487151850\n",
      "Iteration 8405 => Loss: 22.8487088300\n",
      "Iteration 8406 => Loss: 22.8487024818\n",
      "Iteration 8407 => Loss: 22.8486961404\n",
      "Iteration 8408 => Loss: 22.8486898056\n",
      "Iteration 8409 => Loss: 22.8486834777\n",
      "Iteration 8410 => Loss: 22.8486771564\n",
      "Iteration 8411 => Loss: 22.8486708419\n",
      "Iteration 8412 => Loss: 22.8486645340\n",
      "Iteration 8413 => Loss: 22.8486582329\n",
      "Iteration 8414 => Loss: 22.8486519385\n",
      "Iteration 8415 => Loss: 22.8486456507\n",
      "Iteration 8416 => Loss: 22.8486393697\n",
      "Iteration 8417 => Loss: 22.8486330953\n",
      "Iteration 8418 => Loss: 22.8486268276\n",
      "Iteration 8419 => Loss: 22.8486205666\n",
      "Iteration 8420 => Loss: 22.8486143122\n",
      "Iteration 8421 => Loss: 22.8486080644\n",
      "Iteration 8422 => Loss: 22.8486018233\n",
      "Iteration 8423 => Loss: 22.8485955889\n",
      "Iteration 8424 => Loss: 22.8485893610\n",
      "Iteration 8425 => Loss: 22.8485831398\n",
      "Iteration 8426 => Loss: 22.8485769252\n",
      "Iteration 8427 => Loss: 22.8485707172\n",
      "Iteration 8428 => Loss: 22.8485645158\n",
      "Iteration 8429 => Loss: 22.8485583210\n",
      "Iteration 8430 => Loss: 22.8485521328\n",
      "Iteration 8431 => Loss: 22.8485459511\n",
      "Iteration 8432 => Loss: 22.8485397761\n",
      "Iteration 8433 => Loss: 22.8485336076\n",
      "Iteration 8434 => Loss: 22.8485274456\n",
      "Iteration 8435 => Loss: 22.8485212902\n",
      "Iteration 8436 => Loss: 22.8485151413\n",
      "Iteration 8437 => Loss: 22.8485089990\n",
      "Iteration 8438 => Loss: 22.8485028632\n",
      "Iteration 8439 => Loss: 22.8484967340\n",
      "Iteration 8440 => Loss: 22.8484906112\n",
      "Iteration 8441 => Loss: 22.8484844950\n",
      "Iteration 8442 => Loss: 22.8484783852\n",
      "Iteration 8443 => Loss: 22.8484722820\n",
      "Iteration 8444 => Loss: 22.8484661852\n",
      "Iteration 8445 => Loss: 22.8484600949\n",
      "Iteration 8446 => Loss: 22.8484540111\n",
      "Iteration 8447 => Loss: 22.8484479338\n",
      "Iteration 8448 => Loss: 22.8484418629\n",
      "Iteration 8449 => Loss: 22.8484357984\n",
      "Iteration 8450 => Loss: 22.8484297405\n",
      "Iteration 8451 => Loss: 22.8484236889\n",
      "Iteration 8452 => Loss: 22.8484176438\n",
      "Iteration 8453 => Loss: 22.8484116051\n",
      "Iteration 8454 => Loss: 22.8484055729\n",
      "Iteration 8455 => Loss: 22.8483995470\n",
      "Iteration 8456 => Loss: 22.8483935276\n",
      "Iteration 8457 => Loss: 22.8483875145\n",
      "Iteration 8458 => Loss: 22.8483815078\n",
      "Iteration 8459 => Loss: 22.8483755076\n",
      "Iteration 8460 => Loss: 22.8483695137\n",
      "Iteration 8461 => Loss: 22.8483635262\n",
      "Iteration 8462 => Loss: 22.8483575450\n",
      "Iteration 8463 => Loss: 22.8483515702\n",
      "Iteration 8464 => Loss: 22.8483456017\n",
      "Iteration 8465 => Loss: 22.8483396396\n",
      "Iteration 8466 => Loss: 22.8483336839\n",
      "Iteration 8467 => Loss: 22.8483277344\n",
      "Iteration 8468 => Loss: 22.8483217913\n",
      "Iteration 8469 => Loss: 22.8483158545\n",
      "Iteration 8470 => Loss: 22.8483099240\n",
      "Iteration 8471 => Loss: 22.8483039999\n",
      "Iteration 8472 => Loss: 22.8482980820\n",
      "Iteration 8473 => Loss: 22.8482921704\n",
      "Iteration 8474 => Loss: 22.8482862651\n",
      "Iteration 8475 => Loss: 22.8482803660\n",
      "Iteration 8476 => Loss: 22.8482744733\n",
      "Iteration 8477 => Loss: 22.8482685868\n",
      "Iteration 8478 => Loss: 22.8482627065\n",
      "Iteration 8479 => Loss: 22.8482568325\n",
      "Iteration 8480 => Loss: 22.8482509648\n",
      "Iteration 8481 => Loss: 22.8482451033\n",
      "Iteration 8482 => Loss: 22.8482392480\n",
      "Iteration 8483 => Loss: 22.8482333990\n",
      "Iteration 8484 => Loss: 22.8482275561\n",
      "Iteration 8485 => Loss: 22.8482217195\n",
      "Iteration 8486 => Loss: 22.8482158891\n",
      "Iteration 8487 => Loss: 22.8482100648\n",
      "Iteration 8488 => Loss: 22.8482042468\n",
      "Iteration 8489 => Loss: 22.8481984350\n",
      "Iteration 8490 => Loss: 22.8481926293\n",
      "Iteration 8491 => Loss: 22.8481868298\n",
      "Iteration 8492 => Loss: 22.8481810365\n",
      "Iteration 8493 => Loss: 22.8481752493\n",
      "Iteration 8494 => Loss: 22.8481694683\n",
      "Iteration 8495 => Loss: 22.8481636934\n",
      "Iteration 8496 => Loss: 22.8481579246\n",
      "Iteration 8497 => Loss: 22.8481521620\n",
      "Iteration 8498 => Loss: 22.8481464055\n",
      "Iteration 8499 => Loss: 22.8481406552\n",
      "Iteration 8500 => Loss: 22.8481349109\n",
      "Iteration 8501 => Loss: 22.8481291728\n",
      "Iteration 8502 => Loss: 22.8481234407\n",
      "Iteration 8503 => Loss: 22.8481177148\n",
      "Iteration 8504 => Loss: 22.8481119949\n",
      "Iteration 8505 => Loss: 22.8481062811\n",
      "Iteration 8506 => Loss: 22.8481005734\n",
      "Iteration 8507 => Loss: 22.8480948718\n",
      "Iteration 8508 => Loss: 22.8480891762\n",
      "Iteration 8509 => Loss: 22.8480834867\n",
      "Iteration 8510 => Loss: 22.8480778032\n",
      "Iteration 8511 => Loss: 22.8480721257\n",
      "Iteration 8512 => Loss: 22.8480664543\n",
      "Iteration 8513 => Loss: 22.8480607889\n",
      "Iteration 8514 => Loss: 22.8480551296\n",
      "Iteration 8515 => Loss: 22.8480494762\n",
      "Iteration 8516 => Loss: 22.8480438289\n",
      "Iteration 8517 => Loss: 22.8480381876\n",
      "Iteration 8518 => Loss: 22.8480325523\n",
      "Iteration 8519 => Loss: 22.8480269229\n",
      "Iteration 8520 => Loss: 22.8480212996\n",
      "Iteration 8521 => Loss: 22.8480156822\n",
      "Iteration 8522 => Loss: 22.8480100708\n",
      "Iteration 8523 => Loss: 22.8480044653\n",
      "Iteration 8524 => Loss: 22.8479988658\n",
      "Iteration 8525 => Loss: 22.8479932723\n",
      "Iteration 8526 => Loss: 22.8479876847\n",
      "Iteration 8527 => Loss: 22.8479821031\n",
      "Iteration 8528 => Loss: 22.8479765274\n",
      "Iteration 8529 => Loss: 22.8479709576\n",
      "Iteration 8530 => Loss: 22.8479653937\n",
      "Iteration 8531 => Loss: 22.8479598357\n",
      "Iteration 8532 => Loss: 22.8479542837\n",
      "Iteration 8533 => Loss: 22.8479487376\n",
      "Iteration 8534 => Loss: 22.8479431973\n",
      "Iteration 8535 => Loss: 22.8479376630\n",
      "Iteration 8536 => Loss: 22.8479321345\n",
      "Iteration 8537 => Loss: 22.8479266119\n",
      "Iteration 8538 => Loss: 22.8479210952\n",
      "Iteration 8539 => Loss: 22.8479155843\n",
      "Iteration 8540 => Loss: 22.8479100793\n",
      "Iteration 8541 => Loss: 22.8479045801\n",
      "Iteration 8542 => Loss: 22.8478990868\n",
      "Iteration 8543 => Loss: 22.8478935993\n",
      "Iteration 8544 => Loss: 22.8478881177\n",
      "Iteration 8545 => Loss: 22.8478826419\n",
      "Iteration 8546 => Loss: 22.8478771719\n",
      "Iteration 8547 => Loss: 22.8478717077\n",
      "Iteration 8548 => Loss: 22.8478662494\n",
      "Iteration 8549 => Loss: 22.8478607968\n",
      "Iteration 8550 => Loss: 22.8478553500\n",
      "Iteration 8551 => Loss: 22.8478499091\n",
      "Iteration 8552 => Loss: 22.8478444739\n",
      "Iteration 8553 => Loss: 22.8478390444\n",
      "Iteration 8554 => Loss: 22.8478336208\n",
      "Iteration 8555 => Loss: 22.8478282029\n",
      "Iteration 8556 => Loss: 22.8478227908\n",
      "Iteration 8557 => Loss: 22.8478173844\n",
      "Iteration 8558 => Loss: 22.8478119838\n",
      "Iteration 8559 => Loss: 22.8478065889\n",
      "Iteration 8560 => Loss: 22.8478011998\n",
      "Iteration 8561 => Loss: 22.8477958164\n",
      "Iteration 8562 => Loss: 22.8477904387\n",
      "Iteration 8563 => Loss: 22.8477850667\n",
      "Iteration 8564 => Loss: 22.8477797004\n",
      "Iteration 8565 => Loss: 22.8477743398\n",
      "Iteration 8566 => Loss: 22.8477689850\n",
      "Iteration 8567 => Loss: 22.8477636358\n",
      "Iteration 8568 => Loss: 22.8477582923\n",
      "Iteration 8569 => Loss: 22.8477529545\n",
      "Iteration 8570 => Loss: 22.8477476224\n",
      "Iteration 8571 => Loss: 22.8477422959\n",
      "Iteration 8572 => Loss: 22.8477369751\n",
      "Iteration 8573 => Loss: 22.8477316600\n",
      "Iteration 8574 => Loss: 22.8477263505\n",
      "Iteration 8575 => Loss: 22.8477210466\n",
      "Iteration 8576 => Loss: 22.8477157484\n",
      "Iteration 8577 => Loss: 22.8477104558\n",
      "Iteration 8578 => Loss: 22.8477051688\n",
      "Iteration 8579 => Loss: 22.8476998875\n",
      "Iteration 8580 => Loss: 22.8476946118\n",
      "Iteration 8581 => Loss: 22.8476893417\n",
      "Iteration 8582 => Loss: 22.8476840771\n",
      "Iteration 8583 => Loss: 22.8476788182\n",
      "Iteration 8584 => Loss: 22.8476735649\n",
      "Iteration 8585 => Loss: 22.8476683171\n",
      "Iteration 8586 => Loss: 22.8476630750\n",
      "Iteration 8587 => Loss: 22.8476578384\n",
      "Iteration 8588 => Loss: 22.8476526074\n",
      "Iteration 8589 => Loss: 22.8476473819\n",
      "Iteration 8590 => Loss: 22.8476421620\n",
      "Iteration 8591 => Loss: 22.8476369476\n",
      "Iteration 8592 => Loss: 22.8476317388\n",
      "Iteration 8593 => Loss: 22.8476265355\n",
      "Iteration 8594 => Loss: 22.8476213378\n",
      "Iteration 8595 => Loss: 22.8476161455\n",
      "Iteration 8596 => Loss: 22.8476109588\n",
      "Iteration 8597 => Loss: 22.8476057776\n",
      "Iteration 8598 => Loss: 22.8476006019\n",
      "Iteration 8599 => Loss: 22.8475954317\n",
      "Iteration 8600 => Loss: 22.8475902670\n",
      "Iteration 8601 => Loss: 22.8475851078\n",
      "Iteration 8602 => Loss: 22.8475799541\n",
      "Iteration 8603 => Loss: 22.8475748059\n",
      "Iteration 8604 => Loss: 22.8475696631\n",
      "Iteration 8605 => Loss: 22.8475645258\n",
      "Iteration 8606 => Loss: 22.8475593940\n",
      "Iteration 8607 => Loss: 22.8475542676\n",
      "Iteration 8608 => Loss: 22.8475491467\n",
      "Iteration 8609 => Loss: 22.8475440312\n",
      "Iteration 8610 => Loss: 22.8475389211\n",
      "Iteration 8611 => Loss: 22.8475338165\n",
      "Iteration 8612 => Loss: 22.8475287173\n",
      "Iteration 8613 => Loss: 22.8475236235\n",
      "Iteration 8614 => Loss: 22.8475185352\n",
      "Iteration 8615 => Loss: 22.8475134522\n",
      "Iteration 8616 => Loss: 22.8475083747\n",
      "Iteration 8617 => Loss: 22.8475033025\n",
      "Iteration 8618 => Loss: 22.8474982358\n",
      "Iteration 8619 => Loss: 22.8474931744\n",
      "Iteration 8620 => Loss: 22.8474881184\n",
      "Iteration 8621 => Loss: 22.8474830678\n",
      "Iteration 8622 => Loss: 22.8474780225\n",
      "Iteration 8623 => Loss: 22.8474729826\n",
      "Iteration 8624 => Loss: 22.8474679481\n",
      "Iteration 8625 => Loss: 22.8474629189\n",
      "Iteration 8626 => Loss: 22.8474578951\n",
      "Iteration 8627 => Loss: 22.8474528766\n",
      "Iteration 8628 => Loss: 22.8474478634\n",
      "Iteration 8629 => Loss: 22.8474428556\n",
      "Iteration 8630 => Loss: 22.8474378531\n",
      "Iteration 8631 => Loss: 22.8474328559\n",
      "Iteration 8632 => Loss: 22.8474278640\n",
      "Iteration 8633 => Loss: 22.8474228775\n",
      "Iteration 8634 => Loss: 22.8474178962\n",
      "Iteration 8635 => Loss: 22.8474129202\n",
      "Iteration 8636 => Loss: 22.8474079495\n",
      "Iteration 8637 => Loss: 22.8474029841\n",
      "Iteration 8638 => Loss: 22.8473980240\n",
      "Iteration 8639 => Loss: 22.8473930692\n",
      "Iteration 8640 => Loss: 22.8473881196\n",
      "Iteration 8641 => Loss: 22.8473831753\n",
      "Iteration 8642 => Loss: 22.8473782362\n",
      "Iteration 8643 => Loss: 22.8473733024\n",
      "Iteration 8644 => Loss: 22.8473683738\n",
      "Iteration 8645 => Loss: 22.8473634505\n",
      "Iteration 8646 => Loss: 22.8473585324\n",
      "Iteration 8647 => Loss: 22.8473536195\n",
      "Iteration 8648 => Loss: 22.8473487118\n",
      "Iteration 8649 => Loss: 22.8473438094\n",
      "Iteration 8650 => Loss: 22.8473389122\n",
      "Iteration 8651 => Loss: 22.8473340202\n",
      "Iteration 8652 => Loss: 22.8473291334\n",
      "Iteration 8653 => Loss: 22.8473242517\n",
      "Iteration 8654 => Loss: 22.8473193753\n",
      "Iteration 8655 => Loss: 22.8473145041\n",
      "Iteration 8656 => Loss: 22.8473096380\n",
      "Iteration 8657 => Loss: 22.8473047771\n",
      "Iteration 8658 => Loss: 22.8472999214\n",
      "Iteration 8659 => Loss: 22.8472950708\n",
      "Iteration 8660 => Loss: 22.8472902254\n",
      "Iteration 8661 => Loss: 22.8472853851\n",
      "Iteration 8662 => Loss: 22.8472805500\n",
      "Iteration 8663 => Loss: 22.8472757200\n",
      "Iteration 8664 => Loss: 22.8472708952\n",
      "Iteration 8665 => Loss: 22.8472660754\n",
      "Iteration 8666 => Loss: 22.8472612609\n",
      "Iteration 8667 => Loss: 22.8472564514\n",
      "Iteration 8668 => Loss: 22.8472516470\n",
      "Iteration 8669 => Loss: 22.8472468478\n",
      "Iteration 8670 => Loss: 22.8472420536\n",
      "Iteration 8671 => Loss: 22.8472372646\n",
      "Iteration 8672 => Loss: 22.8472324806\n",
      "Iteration 8673 => Loss: 22.8472277017\n",
      "Iteration 8674 => Loss: 22.8472229279\n",
      "Iteration 8675 => Loss: 22.8472181592\n",
      "Iteration 8676 => Loss: 22.8472133955\n",
      "Iteration 8677 => Loss: 22.8472086369\n",
      "Iteration 8678 => Loss: 22.8472038834\n",
      "Iteration 8679 => Loss: 22.8471991349\n",
      "Iteration 8680 => Loss: 22.8471943915\n",
      "Iteration 8681 => Loss: 22.8471896531\n",
      "Iteration 8682 => Loss: 22.8471849197\n",
      "Iteration 8683 => Loss: 22.8471801914\n",
      "Iteration 8684 => Loss: 22.8471754681\n",
      "Iteration 8685 => Loss: 22.8471707498\n",
      "Iteration 8686 => Loss: 22.8471660365\n",
      "Iteration 8687 => Loss: 22.8471613283\n",
      "Iteration 8688 => Loss: 22.8471566250\n",
      "Iteration 8689 => Loss: 22.8471519268\n",
      "Iteration 8690 => Loss: 22.8471472335\n",
      "Iteration 8691 => Loss: 22.8471425453\n",
      "Iteration 8692 => Loss: 22.8471378620\n",
      "Iteration 8693 => Loss: 22.8471331837\n",
      "Iteration 8694 => Loss: 22.8471285104\n",
      "Iteration 8695 => Loss: 22.8471238420\n",
      "Iteration 8696 => Loss: 22.8471191786\n",
      "Iteration 8697 => Loss: 22.8471145201\n",
      "Iteration 8698 => Loss: 22.8471098667\n",
      "Iteration 8699 => Loss: 22.8471052181\n",
      "Iteration 8700 => Loss: 22.8471005745\n",
      "Iteration 8701 => Loss: 22.8470959358\n",
      "Iteration 8702 => Loss: 22.8470913021\n",
      "Iteration 8703 => Loss: 22.8470866733\n",
      "Iteration 8704 => Loss: 22.8470820494\n",
      "Iteration 8705 => Loss: 22.8470774304\n",
      "Iteration 8706 => Loss: 22.8470728164\n",
      "Iteration 8707 => Loss: 22.8470682072\n",
      "Iteration 8708 => Loss: 22.8470636029\n",
      "Iteration 8709 => Loss: 22.8470590036\n",
      "Iteration 8710 => Loss: 22.8470544091\n",
      "Iteration 8711 => Loss: 22.8470498195\n",
      "Iteration 8712 => Loss: 22.8470452348\n",
      "Iteration 8713 => Loss: 22.8470406549\n",
      "Iteration 8714 => Loss: 22.8470360799\n",
      "Iteration 8715 => Loss: 22.8470315098\n",
      "Iteration 8716 => Loss: 22.8470269446\n",
      "Iteration 8717 => Loss: 22.8470223842\n",
      "Iteration 8718 => Loss: 22.8470178286\n",
      "Iteration 8719 => Loss: 22.8470132779\n",
      "Iteration 8720 => Loss: 22.8470087320\n",
      "Iteration 8721 => Loss: 22.8470041910\n",
      "Iteration 8722 => Loss: 22.8469996548\n",
      "Iteration 8723 => Loss: 22.8469951234\n",
      "Iteration 8724 => Loss: 22.8469905968\n",
      "Iteration 8725 => Loss: 22.8469860751\n",
      "Iteration 8726 => Loss: 22.8469815581\n",
      "Iteration 8727 => Loss: 22.8469770459\n",
      "Iteration 8728 => Loss: 22.8469725386\n",
      "Iteration 8729 => Loss: 22.8469680360\n",
      "Iteration 8730 => Loss: 22.8469635382\n",
      "Iteration 8731 => Loss: 22.8469590452\n",
      "Iteration 8732 => Loss: 22.8469545570\n",
      "Iteration 8733 => Loss: 22.8469500735\n",
      "Iteration 8734 => Loss: 22.8469455949\n",
      "Iteration 8735 => Loss: 22.8469411209\n",
      "Iteration 8736 => Loss: 22.8469366518\n",
      "Iteration 8737 => Loss: 22.8469321873\n",
      "Iteration 8738 => Loss: 22.8469277277\n",
      "Iteration 8739 => Loss: 22.8469232727\n",
      "Iteration 8740 => Loss: 22.8469188225\n",
      "Iteration 8741 => Loss: 22.8469143770\n",
      "Iteration 8742 => Loss: 22.8469099363\n",
      "Iteration 8743 => Loss: 22.8469055003\n",
      "Iteration 8744 => Loss: 22.8469010690\n",
      "Iteration 8745 => Loss: 22.8468966424\n",
      "Iteration 8746 => Loss: 22.8468922205\n",
      "Iteration 8747 => Loss: 22.8468878033\n",
      "Iteration 8748 => Loss: 22.8468833908\n",
      "Iteration 8749 => Loss: 22.8468789830\n",
      "Iteration 8750 => Loss: 22.8468745799\n",
      "Iteration 8751 => Loss: 22.8468701814\n",
      "Iteration 8752 => Loss: 22.8468657877\n",
      "Iteration 8753 => Loss: 22.8468613986\n",
      "Iteration 8754 => Loss: 22.8468570141\n",
      "Iteration 8755 => Loss: 22.8468526344\n",
      "Iteration 8756 => Loss: 22.8468482592\n",
      "Iteration 8757 => Loss: 22.8468438888\n",
      "Iteration 8758 => Loss: 22.8468395230\n",
      "Iteration 8759 => Loss: 22.8468351618\n",
      "Iteration 8760 => Loss: 22.8468308052\n",
      "Iteration 8761 => Loss: 22.8468264533\n",
      "Iteration 8762 => Loss: 22.8468221061\n",
      "Iteration 8763 => Loss: 22.8468177634\n",
      "Iteration 8764 => Loss: 22.8468134253\n",
      "Iteration 8765 => Loss: 22.8468090919\n",
      "Iteration 8766 => Loss: 22.8468047631\n",
      "Iteration 8767 => Loss: 22.8468004389\n",
      "Iteration 8768 => Loss: 22.8467961192\n",
      "Iteration 8769 => Loss: 22.8467918042\n",
      "Iteration 8770 => Loss: 22.8467874937\n",
      "Iteration 8771 => Loss: 22.8467831879\n",
      "Iteration 8772 => Loss: 22.8467788866\n",
      "Iteration 8773 => Loss: 22.8467745899\n",
      "Iteration 8774 => Loss: 22.8467702977\n",
      "Iteration 8775 => Loss: 22.8467660101\n",
      "Iteration 8776 => Loss: 22.8467617271\n",
      "Iteration 8777 => Loss: 22.8467574486\n",
      "Iteration 8778 => Loss: 22.8467531747\n",
      "Iteration 8779 => Loss: 22.8467489053\n",
      "Iteration 8780 => Loss: 22.8467446404\n",
      "Iteration 8781 => Loss: 22.8467403801\n",
      "Iteration 8782 => Loss: 22.8467361243\n",
      "Iteration 8783 => Loss: 22.8467318730\n",
      "Iteration 8784 => Loss: 22.8467276263\n",
      "Iteration 8785 => Loss: 22.8467233841\n",
      "Iteration 8786 => Loss: 22.8467191463\n",
      "Iteration 8787 => Loss: 22.8467149131\n",
      "Iteration 8788 => Loss: 22.8467106844\n",
      "Iteration 8789 => Loss: 22.8467064602\n",
      "Iteration 8790 => Loss: 22.8467022404\n",
      "Iteration 8791 => Loss: 22.8466980252\n",
      "Iteration 8792 => Loss: 22.8466938144\n",
      "Iteration 8793 => Loss: 22.8466896081\n",
      "Iteration 8794 => Loss: 22.8466854063\n",
      "Iteration 8795 => Loss: 22.8466812090\n",
      "Iteration 8796 => Loss: 22.8466770161\n",
      "Iteration 8797 => Loss: 22.8466728276\n",
      "Iteration 8798 => Loss: 22.8466686437\n",
      "Iteration 8799 => Loss: 22.8466644641\n",
      "Iteration 8800 => Loss: 22.8466602890\n",
      "Iteration 8801 => Loss: 22.8466561184\n",
      "Iteration 8802 => Loss: 22.8466519522\n",
      "Iteration 8803 => Loss: 22.8466477904\n",
      "Iteration 8804 => Loss: 22.8466436330\n",
      "Iteration 8805 => Loss: 22.8466394800\n",
      "Iteration 8806 => Loss: 22.8466353315\n",
      "Iteration 8807 => Loss: 22.8466311874\n",
      "Iteration 8808 => Loss: 22.8466270477\n",
      "Iteration 8809 => Loss: 22.8466229123\n",
      "Iteration 8810 => Loss: 22.8466187814\n",
      "Iteration 8811 => Loss: 22.8466146549\n",
      "Iteration 8812 => Loss: 22.8466105327\n",
      "Iteration 8813 => Loss: 22.8466064150\n",
      "Iteration 8814 => Loss: 22.8466023016\n",
      "Iteration 8815 => Loss: 22.8465981926\n",
      "Iteration 8816 => Loss: 22.8465940879\n",
      "Iteration 8817 => Loss: 22.8465899876\n",
      "Iteration 8818 => Loss: 22.8465858917\n",
      "Iteration 8819 => Loss: 22.8465818001\n",
      "Iteration 8820 => Loss: 22.8465777129\n",
      "Iteration 8821 => Loss: 22.8465736300\n",
      "Iteration 8822 => Loss: 22.8465695515\n",
      "Iteration 8823 => Loss: 22.8465654773\n",
      "Iteration 8824 => Loss: 22.8465614074\n",
      "Iteration 8825 => Loss: 22.8465573419\n",
      "Iteration 8826 => Loss: 22.8465532807\n",
      "Iteration 8827 => Loss: 22.8465492238\n",
      "Iteration 8828 => Loss: 22.8465451712\n",
      "Iteration 8829 => Loss: 22.8465411229\n",
      "Iteration 8830 => Loss: 22.8465370789\n",
      "Iteration 8831 => Loss: 22.8465330392\n",
      "Iteration 8832 => Loss: 22.8465290038\n",
      "Iteration 8833 => Loss: 22.8465249727\n",
      "Iteration 8834 => Loss: 22.8465209459\n",
      "Iteration 8835 => Loss: 22.8465169234\n",
      "Iteration 8836 => Loss: 22.8465129051\n",
      "Iteration 8837 => Loss: 22.8465088911\n",
      "Iteration 8838 => Loss: 22.8465048814\n",
      "Iteration 8839 => Loss: 22.8465008759\n",
      "Iteration 8840 => Loss: 22.8464968747\n",
      "Iteration 8841 => Loss: 22.8464928778\n",
      "Iteration 8842 => Loss: 22.8464888851\n",
      "Iteration 8843 => Loss: 22.8464848966\n",
      "Iteration 8844 => Loss: 22.8464809124\n",
      "Iteration 8845 => Loss: 22.8464769324\n",
      "Iteration 8846 => Loss: 22.8464729567\n",
      "Iteration 8847 => Loss: 22.8464689852\n",
      "Iteration 8848 => Loss: 22.8464650179\n",
      "Iteration 8849 => Loss: 22.8464610548\n",
      "Iteration 8850 => Loss: 22.8464570959\n",
      "Iteration 8851 => Loss: 22.8464531412\n",
      "Iteration 8852 => Loss: 22.8464491908\n",
      "Iteration 8853 => Loss: 22.8464452445\n",
      "Iteration 8854 => Loss: 22.8464413025\n",
      "Iteration 8855 => Loss: 22.8464373646\n",
      "Iteration 8856 => Loss: 22.8464334309\n",
      "Iteration 8857 => Loss: 22.8464295014\n",
      "Iteration 8858 => Loss: 22.8464255760\n",
      "Iteration 8859 => Loss: 22.8464216549\n",
      "Iteration 8860 => Loss: 22.8464177379\n",
      "Iteration 8861 => Loss: 22.8464138251\n",
      "Iteration 8862 => Loss: 22.8464099164\n",
      "Iteration 8863 => Loss: 22.8464060119\n",
      "Iteration 8864 => Loss: 22.8464021115\n",
      "Iteration 8865 => Loss: 22.8463982153\n",
      "Iteration 8866 => Loss: 22.8463943232\n",
      "Iteration 8867 => Loss: 22.8463904353\n",
      "Iteration 8868 => Loss: 22.8463865515\n",
      "Iteration 8869 => Loss: 22.8463826718\n",
      "Iteration 8870 => Loss: 22.8463787963\n",
      "Iteration 8871 => Loss: 22.8463749248\n",
      "Iteration 8872 => Loss: 22.8463710575\n",
      "Iteration 8873 => Loss: 22.8463671943\n",
      "Iteration 8874 => Loss: 22.8463633352\n",
      "Iteration 8875 => Loss: 22.8463594802\n",
      "Iteration 8876 => Loss: 22.8463556293\n",
      "Iteration 8877 => Loss: 22.8463517825\n",
      "Iteration 8878 => Loss: 22.8463479398\n",
      "Iteration 8879 => Loss: 22.8463441011\n",
      "Iteration 8880 => Loss: 22.8463402666\n",
      "Iteration 8881 => Loss: 22.8463364361\n",
      "Iteration 8882 => Loss: 22.8463326097\n",
      "Iteration 8883 => Loss: 22.8463287874\n",
      "Iteration 8884 => Loss: 22.8463249691\n",
      "Iteration 8885 => Loss: 22.8463211549\n",
      "Iteration 8886 => Loss: 22.8463173447\n",
      "Iteration 8887 => Loss: 22.8463135386\n",
      "Iteration 8888 => Loss: 22.8463097365\n",
      "Iteration 8889 => Loss: 22.8463059385\n",
      "Iteration 8890 => Loss: 22.8463021445\n",
      "Iteration 8891 => Loss: 22.8462983546\n",
      "Iteration 8892 => Loss: 22.8462945686\n",
      "Iteration 8893 => Loss: 22.8462907867\n",
      "Iteration 8894 => Loss: 22.8462870089\n",
      "Iteration 8895 => Loss: 22.8462832350\n",
      "Iteration 8896 => Loss: 22.8462794651\n",
      "Iteration 8897 => Loss: 22.8462756993\n",
      "Iteration 8898 => Loss: 22.8462719374\n",
      "Iteration 8899 => Loss: 22.8462681796\n",
      "Iteration 8900 => Loss: 22.8462644257\n",
      "Iteration 8901 => Loss: 22.8462606759\n",
      "Iteration 8902 => Loss: 22.8462569300\n",
      "Iteration 8903 => Loss: 22.8462531881\n",
      "Iteration 8904 => Loss: 22.8462494502\n",
      "Iteration 8905 => Loss: 22.8462457163\n",
      "Iteration 8906 => Loss: 22.8462419863\n",
      "Iteration 8907 => Loss: 22.8462382603\n",
      "Iteration 8908 => Loss: 22.8462345382\n",
      "Iteration 8909 => Loss: 22.8462308201\n",
      "Iteration 8910 => Loss: 22.8462271060\n",
      "Iteration 8911 => Loss: 22.8462233958\n",
      "Iteration 8912 => Loss: 22.8462196896\n",
      "Iteration 8913 => Loss: 22.8462159873\n",
      "Iteration 8914 => Loss: 22.8462122889\n",
      "Iteration 8915 => Loss: 22.8462085945\n",
      "Iteration 8916 => Loss: 22.8462049039\n",
      "Iteration 8917 => Loss: 22.8462012174\n",
      "Iteration 8918 => Loss: 22.8461975347\n",
      "Iteration 8919 => Loss: 22.8461938559\n",
      "Iteration 8920 => Loss: 22.8461901811\n",
      "Iteration 8921 => Loss: 22.8461865101\n",
      "Iteration 8922 => Loss: 22.8461828431\n",
      "Iteration 8923 => Loss: 22.8461791800\n",
      "Iteration 8924 => Loss: 22.8461755207\n",
      "Iteration 8925 => Loss: 22.8461718654\n",
      "Iteration 8926 => Loss: 22.8461682139\n",
      "Iteration 8927 => Loss: 22.8461645663\n",
      "Iteration 8928 => Loss: 22.8461609226\n",
      "Iteration 8929 => Loss: 22.8461572828\n",
      "Iteration 8930 => Loss: 22.8461536468\n",
      "Iteration 8931 => Loss: 22.8461500147\n",
      "Iteration 8932 => Loss: 22.8461463864\n",
      "Iteration 8933 => Loss: 22.8461427620\n",
      "Iteration 8934 => Loss: 22.8461391415\n",
      "Iteration 8935 => Loss: 22.8461355248\n",
      "Iteration 8936 => Loss: 22.8461319120\n",
      "Iteration 8937 => Loss: 22.8461283030\n",
      "Iteration 8938 => Loss: 22.8461246978\n",
      "Iteration 8939 => Loss: 22.8461210965\n",
      "Iteration 8940 => Loss: 22.8461174990\n",
      "Iteration 8941 => Loss: 22.8461139053\n",
      "Iteration 8942 => Loss: 22.8461103154\n",
      "Iteration 8943 => Loss: 22.8461067294\n",
      "Iteration 8944 => Loss: 22.8461031472\n",
      "Iteration 8945 => Loss: 22.8460995687\n",
      "Iteration 8946 => Loss: 22.8460959941\n",
      "Iteration 8947 => Loss: 22.8460924233\n",
      "Iteration 8948 => Loss: 22.8460888563\n",
      "Iteration 8949 => Loss: 22.8460852930\n",
      "Iteration 8950 => Loss: 22.8460817336\n",
      "Iteration 8951 => Loss: 22.8460781779\n",
      "Iteration 8952 => Loss: 22.8460746261\n",
      "Iteration 8953 => Loss: 22.8460710779\n",
      "Iteration 8954 => Loss: 22.8460675336\n",
      "Iteration 8955 => Loss: 22.8460639930\n",
      "Iteration 8956 => Loss: 22.8460604562\n",
      "Iteration 8957 => Loss: 22.8460569232\n",
      "Iteration 8958 => Loss: 22.8460533939\n",
      "Iteration 8959 => Loss: 22.8460498684\n",
      "Iteration 8960 => Loss: 22.8460463466\n",
      "Iteration 8961 => Loss: 22.8460428285\n",
      "Iteration 8962 => Loss: 22.8460393142\n",
      "Iteration 8963 => Loss: 22.8460358037\n",
      "Iteration 8964 => Loss: 22.8460322968\n",
      "Iteration 8965 => Loss: 22.8460287937\n",
      "Iteration 8966 => Loss: 22.8460252943\n",
      "Iteration 8967 => Loss: 22.8460217986\n",
      "Iteration 8968 => Loss: 22.8460183067\n",
      "Iteration 8969 => Loss: 22.8460148185\n",
      "Iteration 8970 => Loss: 22.8460113339\n",
      "Iteration 8971 => Loss: 22.8460078531\n",
      "Iteration 8972 => Loss: 22.8460043760\n",
      "Iteration 8973 => Loss: 22.8460009025\n",
      "Iteration 8974 => Loss: 22.8459974328\n",
      "Iteration 8975 => Loss: 22.8459939667\n",
      "Iteration 8976 => Loss: 22.8459905044\n",
      "Iteration 8977 => Loss: 22.8459870457\n",
      "Iteration 8978 => Loss: 22.8459835907\n",
      "Iteration 8979 => Loss: 22.8459801393\n",
      "Iteration 8980 => Loss: 22.8459766917\n",
      "Iteration 8981 => Loss: 22.8459732477\n",
      "Iteration 8982 => Loss: 22.8459698073\n",
      "Iteration 8983 => Loss: 22.8459663706\n",
      "Iteration 8984 => Loss: 22.8459629376\n",
      "Iteration 8985 => Loss: 22.8459595082\n",
      "Iteration 8986 => Loss: 22.8459560825\n",
      "Iteration 8987 => Loss: 22.8459526604\n",
      "Iteration 8988 => Loss: 22.8459492419\n",
      "Iteration 8989 => Loss: 22.8459458271\n",
      "Iteration 8990 => Loss: 22.8459424159\n",
      "Iteration 8991 => Loss: 22.8459390083\n",
      "Iteration 8992 => Loss: 22.8459356044\n",
      "Iteration 8993 => Loss: 22.8459322040\n",
      "Iteration 8994 => Loss: 22.8459288073\n",
      "Iteration 8995 => Loss: 22.8459254142\n",
      "Iteration 8996 => Loss: 22.8459220247\n",
      "Iteration 8997 => Loss: 22.8459186388\n",
      "Iteration 8998 => Loss: 22.8459152565\n",
      "Iteration 8999 => Loss: 22.8459118778\n",
      "Iteration 9000 => Loss: 22.8459085027\n",
      "Iteration 9001 => Loss: 22.8459051312\n",
      "Iteration 9002 => Loss: 22.8459017633\n",
      "Iteration 9003 => Loss: 22.8458983989\n",
      "Iteration 9004 => Loss: 22.8458950381\n",
      "Iteration 9005 => Loss: 22.8458916809\n",
      "Iteration 9006 => Loss: 22.8458883273\n",
      "Iteration 9007 => Loss: 22.8458849772\n",
      "Iteration 9008 => Loss: 22.8458816307\n",
      "Iteration 9009 => Loss: 22.8458782877\n",
      "Iteration 9010 => Loss: 22.8458749483\n",
      "Iteration 9011 => Loss: 22.8458716125\n",
      "Iteration 9012 => Loss: 22.8458682802\n",
      "Iteration 9013 => Loss: 22.8458649514\n",
      "Iteration 9014 => Loss: 22.8458616262\n",
      "Iteration 9015 => Loss: 22.8458583045\n",
      "Iteration 9016 => Loss: 22.8458549863\n",
      "Iteration 9017 => Loss: 22.8458516717\n",
      "Iteration 9018 => Loss: 22.8458483606\n",
      "Iteration 9019 => Loss: 22.8458450530\n",
      "Iteration 9020 => Loss: 22.8458417489\n",
      "Iteration 9021 => Loss: 22.8458384483\n",
      "Iteration 9022 => Loss: 22.8458351513\n",
      "Iteration 9023 => Loss: 22.8458318577\n",
      "Iteration 9024 => Loss: 22.8458285677\n",
      "Iteration 9025 => Loss: 22.8458252811\n",
      "Iteration 9026 => Loss: 22.8458219981\n",
      "Iteration 9027 => Loss: 22.8458187185\n",
      "Iteration 9028 => Loss: 22.8458154424\n",
      "Iteration 9029 => Loss: 22.8458121698\n",
      "Iteration 9030 => Loss: 22.8458089007\n",
      "Iteration 9031 => Loss: 22.8458056350\n",
      "Iteration 9032 => Loss: 22.8458023729\n",
      "Iteration 9033 => Loss: 22.8457991142\n",
      "Iteration 9034 => Loss: 22.8457958589\n",
      "Iteration 9035 => Loss: 22.8457926071\n",
      "Iteration 9036 => Loss: 22.8457893588\n",
      "Iteration 9037 => Loss: 22.8457861139\n",
      "Iteration 9038 => Loss: 22.8457828725\n",
      "Iteration 9039 => Loss: 22.8457796345\n",
      "Iteration 9040 => Loss: 22.8457764000\n",
      "Iteration 9041 => Loss: 22.8457731689\n",
      "Iteration 9042 => Loss: 22.8457699412\n",
      "Iteration 9043 => Loss: 22.8457667170\n",
      "Iteration 9044 => Loss: 22.8457634962\n",
      "Iteration 9045 => Loss: 22.8457602788\n",
      "Iteration 9046 => Loss: 22.8457570648\n",
      "Iteration 9047 => Loss: 22.8457538543\n",
      "Iteration 9048 => Loss: 22.8457506472\n",
      "Iteration 9049 => Loss: 22.8457474434\n",
      "Iteration 9050 => Loss: 22.8457442431\n",
      "Iteration 9051 => Loss: 22.8457410462\n",
      "Iteration 9052 => Loss: 22.8457378527\n",
      "Iteration 9053 => Loss: 22.8457346626\n",
      "Iteration 9054 => Loss: 22.8457314758\n",
      "Iteration 9055 => Loss: 22.8457282925\n",
      "Iteration 9056 => Loss: 22.8457251125\n",
      "Iteration 9057 => Loss: 22.8457219359\n",
      "Iteration 9058 => Loss: 22.8457187627\n",
      "Iteration 9059 => Loss: 22.8457155929\n",
      "Iteration 9060 => Loss: 22.8457124264\n",
      "Iteration 9061 => Loss: 22.8457092633\n",
      "Iteration 9062 => Loss: 22.8457061036\n",
      "Iteration 9063 => Loss: 22.8457029472\n",
      "Iteration 9064 => Loss: 22.8456997942\n",
      "Iteration 9065 => Loss: 22.8456966445\n",
      "Iteration 9066 => Loss: 22.8456934982\n",
      "Iteration 9067 => Loss: 22.8456903552\n",
      "Iteration 9068 => Loss: 22.8456872156\n",
      "Iteration 9069 => Loss: 22.8456840793\n",
      "Iteration 9070 => Loss: 22.8456809464\n",
      "Iteration 9071 => Loss: 22.8456778167\n",
      "Iteration 9072 => Loss: 22.8456746904\n",
      "Iteration 9073 => Loss: 22.8456715674\n",
      "Iteration 9074 => Loss: 22.8456684478\n",
      "Iteration 9075 => Loss: 22.8456653314\n",
      "Iteration 9076 => Loss: 22.8456622184\n",
      "Iteration 9077 => Loss: 22.8456591087\n",
      "Iteration 9078 => Loss: 22.8456560022\n",
      "Iteration 9079 => Loss: 22.8456528991\n",
      "Iteration 9080 => Loss: 22.8456497993\n",
      "Iteration 9081 => Loss: 22.8456467028\n",
      "Iteration 9082 => Loss: 22.8456436095\n",
      "Iteration 9083 => Loss: 22.8456405196\n",
      "Iteration 9084 => Loss: 22.8456374329\n",
      "Iteration 9085 => Loss: 22.8456343495\n",
      "Iteration 9086 => Loss: 22.8456312694\n",
      "Iteration 9087 => Loss: 22.8456281926\n",
      "Iteration 9088 => Loss: 22.8456251191\n",
      "Iteration 9089 => Loss: 22.8456220488\n",
      "Iteration 9090 => Loss: 22.8456189817\n",
      "Iteration 9091 => Loss: 22.8456159180\n",
      "Iteration 9092 => Loss: 22.8456128575\n",
      "Iteration 9093 => Loss: 22.8456098002\n",
      "Iteration 9094 => Loss: 22.8456067462\n",
      "Iteration 9095 => Loss: 22.8456036954\n",
      "Iteration 9096 => Loss: 22.8456006479\n",
      "Iteration 9097 => Loss: 22.8455976036\n",
      "Iteration 9098 => Loss: 22.8455945626\n",
      "Iteration 9099 => Loss: 22.8455915248\n",
      "Iteration 9100 => Loss: 22.8455884902\n",
      "Iteration 9101 => Loss: 22.8455854589\n",
      "Iteration 9102 => Loss: 22.8455824307\n",
      "Iteration 9103 => Loss: 22.8455794058\n",
      "Iteration 9104 => Loss: 22.8455763841\n",
      "Iteration 9105 => Loss: 22.8455733656\n",
      "Iteration 9106 => Loss: 22.8455703503\n",
      "Iteration 9107 => Loss: 22.8455673383\n",
      "Iteration 9108 => Loss: 22.8455643294\n",
      "Iteration 9109 => Loss: 22.8455613237\n",
      "Iteration 9110 => Loss: 22.8455583213\n",
      "Iteration 9111 => Loss: 22.8455553220\n",
      "Iteration 9112 => Loss: 22.8455523259\n",
      "Iteration 9113 => Loss: 22.8455493330\n",
      "Iteration 9114 => Loss: 22.8455463432\n",
      "Iteration 9115 => Loss: 22.8455433567\n",
      "Iteration 9116 => Loss: 22.8455403733\n",
      "Iteration 9117 => Loss: 22.8455373931\n",
      "Iteration 9118 => Loss: 22.8455344160\n",
      "Iteration 9119 => Loss: 22.8455314422\n",
      "Iteration 9120 => Loss: 22.8455284715\n",
      "Iteration 9121 => Loss: 22.8455255039\n",
      "Iteration 9122 => Loss: 22.8455225395\n",
      "Iteration 9123 => Loss: 22.8455195782\n",
      "Iteration 9124 => Loss: 22.8455166201\n",
      "Iteration 9125 => Loss: 22.8455136652\n",
      "Iteration 9126 => Loss: 22.8455107134\n",
      "Iteration 9127 => Loss: 22.8455077647\n",
      "Iteration 9128 => Loss: 22.8455048191\n",
      "Iteration 9129 => Loss: 22.8455018767\n",
      "Iteration 9130 => Loss: 22.8454989374\n",
      "Iteration 9131 => Loss: 22.8454960013\n",
      "Iteration 9132 => Loss: 22.8454930682\n",
      "Iteration 9133 => Loss: 22.8454901383\n",
      "Iteration 9134 => Loss: 22.8454872115\n",
      "Iteration 9135 => Loss: 22.8454842878\n",
      "Iteration 9136 => Loss: 22.8454813672\n",
      "Iteration 9137 => Loss: 22.8454784497\n",
      "Iteration 9138 => Loss: 22.8454755353\n",
      "Iteration 9139 => Loss: 22.8454726241\n",
      "Iteration 9140 => Loss: 22.8454697159\n",
      "Iteration 9141 => Loss: 22.8454668108\n",
      "Iteration 9142 => Loss: 22.8454639088\n",
      "Iteration 9143 => Loss: 22.8454610098\n",
      "Iteration 9144 => Loss: 22.8454581140\n",
      "Iteration 9145 => Loss: 22.8454552212\n",
      "Iteration 9146 => Loss: 22.8454523315\n",
      "Iteration 9147 => Loss: 22.8454494449\n",
      "Iteration 9148 => Loss: 22.8454465613\n",
      "Iteration 9149 => Loss: 22.8454436809\n",
      "Iteration 9150 => Loss: 22.8454408034\n",
      "Iteration 9151 => Loss: 22.8454379291\n",
      "Iteration 9152 => Loss: 22.8454350578\n",
      "Iteration 9153 => Loss: 22.8454321895\n",
      "Iteration 9154 => Loss: 22.8454293243\n",
      "Iteration 9155 => Loss: 22.8454264621\n",
      "Iteration 9156 => Loss: 22.8454236030\n",
      "Iteration 9157 => Loss: 22.8454207469\n",
      "Iteration 9158 => Loss: 22.8454178939\n",
      "Iteration 9159 => Loss: 22.8454150439\n",
      "Iteration 9160 => Loss: 22.8454121969\n",
      "Iteration 9161 => Loss: 22.8454093529\n",
      "Iteration 9162 => Loss: 22.8454065120\n",
      "Iteration 9163 => Loss: 22.8454036741\n",
      "Iteration 9164 => Loss: 22.8454008392\n",
      "Iteration 9165 => Loss: 22.8453980073\n",
      "Iteration 9166 => Loss: 22.8453951784\n",
      "Iteration 9167 => Loss: 22.8453923525\n",
      "Iteration 9168 => Loss: 22.8453895297\n",
      "Iteration 9169 => Loss: 22.8453867098\n",
      "Iteration 9170 => Loss: 22.8453838929\n",
      "Iteration 9171 => Loss: 22.8453810791\n",
      "Iteration 9172 => Loss: 22.8453782682\n",
      "Iteration 9173 => Loss: 22.8453754603\n",
      "Iteration 9174 => Loss: 22.8453726554\n",
      "Iteration 9175 => Loss: 22.8453698534\n",
      "Iteration 9176 => Loss: 22.8453670545\n",
      "Iteration 9177 => Loss: 22.8453642585\n",
      "Iteration 9178 => Loss: 22.8453614655\n",
      "Iteration 9179 => Loss: 22.8453586755\n",
      "Iteration 9180 => Loss: 22.8453558884\n",
      "Iteration 9181 => Loss: 22.8453531043\n",
      "Iteration 9182 => Loss: 22.8453503232\n",
      "Iteration 9183 => Loss: 22.8453475450\n",
      "Iteration 9184 => Loss: 22.8453447698\n",
      "Iteration 9185 => Loss: 22.8453419975\n",
      "Iteration 9186 => Loss: 22.8453392281\n",
      "Iteration 9187 => Loss: 22.8453364617\n",
      "Iteration 9188 => Loss: 22.8453336983\n",
      "Iteration 9189 => Loss: 22.8453309378\n",
      "Iteration 9190 => Loss: 22.8453281802\n",
      "Iteration 9191 => Loss: 22.8453254255\n",
      "Iteration 9192 => Loss: 22.8453226738\n",
      "Iteration 9193 => Loss: 22.8453199250\n",
      "Iteration 9194 => Loss: 22.8453171791\n",
      "Iteration 9195 => Loss: 22.8453144362\n",
      "Iteration 9196 => Loss: 22.8453116961\n",
      "Iteration 9197 => Loss: 22.8453089590\n",
      "Iteration 9198 => Loss: 22.8453062248\n",
      "Iteration 9199 => Loss: 22.8453034935\n",
      "Iteration 9200 => Loss: 22.8453007651\n",
      "Iteration 9201 => Loss: 22.8452980396\n",
      "Iteration 9202 => Loss: 22.8452953169\n",
      "Iteration 9203 => Loss: 22.8452925972\n",
      "Iteration 9204 => Loss: 22.8452898804\n",
      "Iteration 9205 => Loss: 22.8452871665\n",
      "Iteration 9206 => Loss: 22.8452844554\n",
      "Iteration 9207 => Loss: 22.8452817472\n",
      "Iteration 9208 => Loss: 22.8452790419\n",
      "Iteration 9209 => Loss: 22.8452763395\n",
      "Iteration 9210 => Loss: 22.8452736400\n",
      "Iteration 9211 => Loss: 22.8452709433\n",
      "Iteration 9212 => Loss: 22.8452682495\n",
      "Iteration 9213 => Loss: 22.8452655585\n",
      "Iteration 9214 => Loss: 22.8452628705\n",
      "Iteration 9215 => Loss: 22.8452601852\n",
      "Iteration 9216 => Loss: 22.8452575029\n",
      "Iteration 9217 => Loss: 22.8452548233\n",
      "Iteration 9218 => Loss: 22.8452521467\n",
      "Iteration 9219 => Loss: 22.8452494728\n",
      "Iteration 9220 => Loss: 22.8452468018\n",
      "Iteration 9221 => Loss: 22.8452441337\n",
      "Iteration 9222 => Loss: 22.8452414684\n",
      "Iteration 9223 => Loss: 22.8452388059\n",
      "Iteration 9224 => Loss: 22.8452361463\n",
      "Iteration 9225 => Loss: 22.8452334894\n",
      "Iteration 9226 => Loss: 22.8452308354\n",
      "Iteration 9227 => Loss: 22.8452281843\n",
      "Iteration 9228 => Loss: 22.8452255359\n",
      "Iteration 9229 => Loss: 22.8452228904\n",
      "Iteration 9230 => Loss: 22.8452202476\n",
      "Iteration 9231 => Loss: 22.8452176077\n",
      "Iteration 9232 => Loss: 22.8452149706\n",
      "Iteration 9233 => Loss: 22.8452123363\n",
      "Iteration 9234 => Loss: 22.8452097048\n",
      "Iteration 9235 => Loss: 22.8452070761\n",
      "Iteration 9236 => Loss: 22.8452044501\n",
      "Iteration 9237 => Loss: 22.8452018270\n",
      "Iteration 9238 => Loss: 22.8451992067\n",
      "Iteration 9239 => Loss: 22.8451965891\n",
      "Iteration 9240 => Loss: 22.8451939743\n",
      "Iteration 9241 => Loss: 22.8451913624\n",
      "Iteration 9242 => Loss: 22.8451887531\n",
      "Iteration 9243 => Loss: 22.8451861467\n",
      "Iteration 9244 => Loss: 22.8451835430\n",
      "Iteration 9245 => Loss: 22.8451809421\n",
      "Iteration 9246 => Loss: 22.8451783440\n",
      "Iteration 9247 => Loss: 22.8451757486\n",
      "Iteration 9248 => Loss: 22.8451731560\n",
      "Iteration 9249 => Loss: 22.8451705661\n",
      "Iteration 9250 => Loss: 22.8451679790\n",
      "Iteration 9251 => Loss: 22.8451653946\n",
      "Iteration 9252 => Loss: 22.8451628130\n",
      "Iteration 9253 => Loss: 22.8451602342\n",
      "Iteration 9254 => Loss: 22.8451576580\n",
      "Iteration 9255 => Loss: 22.8451550846\n",
      "Iteration 9256 => Loss: 22.8451525140\n",
      "Iteration 9257 => Loss: 22.8451499461\n",
      "Iteration 9258 => Loss: 22.8451473809\n",
      "Iteration 9259 => Loss: 22.8451448184\n",
      "Iteration 9260 => Loss: 22.8451422587\n",
      "Iteration 9261 => Loss: 22.8451397017\n",
      "Iteration 9262 => Loss: 22.8451371473\n",
      "Iteration 9263 => Loss: 22.8451345958\n",
      "Iteration 9264 => Loss: 22.8451320469\n",
      "Iteration 9265 => Loss: 22.8451295007\n",
      "Iteration 9266 => Loss: 22.8451269573\n",
      "Iteration 9267 => Loss: 22.8451244165\n",
      "Iteration 9268 => Loss: 22.8451218785\n",
      "Iteration 9269 => Loss: 22.8451193431\n",
      "Iteration 9270 => Loss: 22.8451168104\n",
      "Iteration 9271 => Loss: 22.8451142805\n",
      "Iteration 9272 => Loss: 22.8451117532\n",
      "Iteration 9273 => Loss: 22.8451092286\n",
      "Iteration 9274 => Loss: 22.8451067067\n",
      "Iteration 9275 => Loss: 22.8451041875\n",
      "Iteration 9276 => Loss: 22.8451016709\n",
      "Iteration 9277 => Loss: 22.8450991570\n",
      "Iteration 9278 => Loss: 22.8450966458\n",
      "Iteration 9279 => Loss: 22.8450941373\n",
      "Iteration 9280 => Loss: 22.8450916314\n",
      "Iteration 9281 => Loss: 22.8450891282\n",
      "Iteration 9282 => Loss: 22.8450866277\n",
      "Iteration 9283 => Loss: 22.8450841298\n",
      "Iteration 9284 => Loss: 22.8450816346\n",
      "Iteration 9285 => Loss: 22.8450791420\n",
      "Iteration 9286 => Loss: 22.8450766520\n",
      "Iteration 9287 => Loss: 22.8450741648\n",
      "Iteration 9288 => Loss: 22.8450716801\n",
      "Iteration 9289 => Loss: 22.8450691981\n",
      "Iteration 9290 => Loss: 22.8450667188\n",
      "Iteration 9291 => Loss: 22.8450642420\n",
      "Iteration 9292 => Loss: 22.8450617680\n",
      "Iteration 9293 => Loss: 22.8450592965\n",
      "Iteration 9294 => Loss: 22.8450568277\n",
      "Iteration 9295 => Loss: 22.8450543615\n",
      "Iteration 9296 => Loss: 22.8450518979\n",
      "Iteration 9297 => Loss: 22.8450494369\n",
      "Iteration 9298 => Loss: 22.8450469785\n",
      "Iteration 9299 => Loss: 22.8450445228\n",
      "Iteration 9300 => Loss: 22.8450420697\n",
      "Iteration 9301 => Loss: 22.8450396192\n",
      "Iteration 9302 => Loss: 22.8450371712\n",
      "Iteration 9303 => Loss: 22.8450347259\n",
      "Iteration 9304 => Loss: 22.8450322832\n",
      "Iteration 9305 => Loss: 22.8450298431\n",
      "Iteration 9306 => Loss: 22.8450274056\n",
      "Iteration 9307 => Loss: 22.8450249706\n",
      "Iteration 9308 => Loss: 22.8450225383\n",
      "Iteration 9309 => Loss: 22.8450201085\n",
      "Iteration 9310 => Loss: 22.8450176813\n",
      "Iteration 9311 => Loss: 22.8450152567\n",
      "Iteration 9312 => Loss: 22.8450128347\n",
      "Iteration 9313 => Loss: 22.8450104153\n",
      "Iteration 9314 => Loss: 22.8450079984\n",
      "Iteration 9315 => Loss: 22.8450055841\n",
      "Iteration 9316 => Loss: 22.8450031724\n",
      "Iteration 9317 => Loss: 22.8450007632\n",
      "Iteration 9318 => Loss: 22.8449983566\n",
      "Iteration 9319 => Loss: 22.8449959525\n",
      "Iteration 9320 => Loss: 22.8449935510\n",
      "Iteration 9321 => Loss: 22.8449911521\n",
      "Iteration 9322 => Loss: 22.8449887557\n",
      "Iteration 9323 => Loss: 22.8449863618\n",
      "Iteration 9324 => Loss: 22.8449839705\n",
      "Iteration 9325 => Loss: 22.8449815818\n",
      "Iteration 9326 => Loss: 22.8449791955\n",
      "Iteration 9327 => Loss: 22.8449768118\n",
      "Iteration 9328 => Loss: 22.8449744307\n",
      "Iteration 9329 => Loss: 22.8449720521\n",
      "Iteration 9330 => Loss: 22.8449696760\n",
      "Iteration 9331 => Loss: 22.8449673024\n",
      "Iteration 9332 => Loss: 22.8449649314\n",
      "Iteration 9333 => Loss: 22.8449625628\n",
      "Iteration 9334 => Loss: 22.8449601968\n",
      "Iteration 9335 => Loss: 22.8449578333\n",
      "Iteration 9336 => Loss: 22.8449554724\n",
      "Iteration 9337 => Loss: 22.8449531139\n",
      "Iteration 9338 => Loss: 22.8449507579\n",
      "Iteration 9339 => Loss: 22.8449484045\n",
      "Iteration 9340 => Loss: 22.8449460535\n",
      "Iteration 9341 => Loss: 22.8449437050\n",
      "Iteration 9342 => Loss: 22.8449413591\n",
      "Iteration 9343 => Loss: 22.8449390156\n",
      "Iteration 9344 => Loss: 22.8449366746\n",
      "Iteration 9345 => Loss: 22.8449343362\n",
      "Iteration 9346 => Loss: 22.8449320001\n",
      "Iteration 9347 => Loss: 22.8449296666\n",
      "Iteration 9348 => Loss: 22.8449273356\n",
      "Iteration 9349 => Loss: 22.8449250070\n",
      "Iteration 9350 => Loss: 22.8449226809\n",
      "Iteration 9351 => Loss: 22.8449203573\n",
      "Iteration 9352 => Loss: 22.8449180362\n",
      "Iteration 9353 => Loss: 22.8449157175\n",
      "Iteration 9354 => Loss: 22.8449134013\n",
      "Iteration 9355 => Loss: 22.8449110875\n",
      "Iteration 9356 => Loss: 22.8449087763\n",
      "Iteration 9357 => Loss: 22.8449064674\n",
      "Iteration 9358 => Loss: 22.8449041610\n",
      "Iteration 9359 => Loss: 22.8449018571\n",
      "Iteration 9360 => Loss: 22.8448995556\n",
      "Iteration 9361 => Loss: 22.8448972566\n",
      "Iteration 9362 => Loss: 22.8448949600\n",
      "Iteration 9363 => Loss: 22.8448926659\n",
      "Iteration 9364 => Loss: 22.8448903742\n",
      "Iteration 9365 => Loss: 22.8448880849\n",
      "Iteration 9366 => Loss: 22.8448857980\n",
      "Iteration 9367 => Loss: 22.8448835136\n",
      "Iteration 9368 => Loss: 22.8448812317\n",
      "Iteration 9369 => Loss: 22.8448789521\n",
      "Iteration 9370 => Loss: 22.8448766750\n",
      "Iteration 9371 => Loss: 22.8448744003\n",
      "Iteration 9372 => Loss: 22.8448721280\n",
      "Iteration 9373 => Loss: 22.8448698581\n",
      "Iteration 9374 => Loss: 22.8448675906\n",
      "Iteration 9375 => Loss: 22.8448653256\n",
      "Iteration 9376 => Loss: 22.8448630629\n",
      "Iteration 9377 => Loss: 22.8448608027\n",
      "Iteration 9378 => Loss: 22.8448585449\n",
      "Iteration 9379 => Loss: 22.8448562894\n",
      "Iteration 9380 => Loss: 22.8448540364\n",
      "Iteration 9381 => Loss: 22.8448517857\n",
      "Iteration 9382 => Loss: 22.8448495375\n",
      "Iteration 9383 => Loss: 22.8448472916\n",
      "Iteration 9384 => Loss: 22.8448450481\n",
      "Iteration 9385 => Loss: 22.8448428070\n",
      "Iteration 9386 => Loss: 22.8448405683\n",
      "Iteration 9387 => Loss: 22.8448383320\n",
      "Iteration 9388 => Loss: 22.8448360980\n",
      "Iteration 9389 => Loss: 22.8448338665\n",
      "Iteration 9390 => Loss: 22.8448316373\n",
      "Iteration 9391 => Loss: 22.8448294104\n",
      "Iteration 9392 => Loss: 22.8448271860\n",
      "Iteration 9393 => Loss: 22.8448249639\n",
      "Iteration 9394 => Loss: 22.8448227441\n",
      "Iteration 9395 => Loss: 22.8448205267\n",
      "Iteration 9396 => Loss: 22.8448183117\n",
      "Iteration 9397 => Loss: 22.8448160990\n",
      "Iteration 9398 => Loss: 22.8448138887\n",
      "Iteration 9399 => Loss: 22.8448116807\n",
      "Iteration 9400 => Loss: 22.8448094751\n",
      "Iteration 9401 => Loss: 22.8448072718\n",
      "Iteration 9402 => Loss: 22.8448050709\n",
      "Iteration 9403 => Loss: 22.8448028723\n",
      "Iteration 9404 => Loss: 22.8448006760\n",
      "Iteration 9405 => Loss: 22.8447984821\n",
      "Iteration 9406 => Loss: 22.8447962905\n",
      "Iteration 9407 => Loss: 22.8447941013\n",
      "Iteration 9408 => Loss: 22.8447919143\n",
      "Iteration 9409 => Loss: 22.8447897297\n",
      "Iteration 9410 => Loss: 22.8447875474\n",
      "Iteration 9411 => Loss: 22.8447853675\n",
      "Iteration 9412 => Loss: 22.8447831898\n",
      "Iteration 9413 => Loss: 22.8447810145\n",
      "Iteration 9414 => Loss: 22.8447788414\n",
      "Iteration 9415 => Loss: 22.8447766707\n",
      "Iteration 9416 => Loss: 22.8447745023\n",
      "Iteration 9417 => Loss: 22.8447723362\n",
      "Iteration 9418 => Loss: 22.8447701724\n",
      "Iteration 9419 => Loss: 22.8447680109\n",
      "Iteration 9420 => Loss: 22.8447658517\n",
      "Iteration 9421 => Loss: 22.8447636948\n",
      "Iteration 9422 => Loss: 22.8447615402\n",
      "Iteration 9423 => Loss: 22.8447593879\n",
      "Iteration 9424 => Loss: 22.8447572378\n",
      "Iteration 9425 => Loss: 22.8447550901\n",
      "Iteration 9426 => Loss: 22.8447529446\n",
      "Iteration 9427 => Loss: 22.8447508014\n",
      "Iteration 9428 => Loss: 22.8447486605\n",
      "Iteration 9429 => Loss: 22.8447465219\n",
      "Iteration 9430 => Loss: 22.8447443855\n",
      "Iteration 9431 => Loss: 22.8447422514\n",
      "Iteration 9432 => Loss: 22.8447401196\n",
      "Iteration 9433 => Loss: 22.8447379900\n",
      "Iteration 9434 => Loss: 22.8447358628\n",
      "Iteration 9435 => Loss: 22.8447337377\n",
      "Iteration 9436 => Loss: 22.8447316150\n",
      "Iteration 9437 => Loss: 22.8447294944\n",
      "Iteration 9438 => Loss: 22.8447273762\n",
      "Iteration 9439 => Loss: 22.8447252602\n",
      "Iteration 9440 => Loss: 22.8447231464\n",
      "Iteration 9441 => Loss: 22.8447210349\n",
      "Iteration 9442 => Loss: 22.8447189256\n",
      "Iteration 9443 => Loss: 22.8447168186\n",
      "Iteration 9444 => Loss: 22.8447147138\n",
      "Iteration 9445 => Loss: 22.8447126113\n",
      "Iteration 9446 => Loss: 22.8447105110\n",
      "Iteration 9447 => Loss: 22.8447084129\n",
      "Iteration 9448 => Loss: 22.8447063170\n",
      "Iteration 9449 => Loss: 22.8447042234\n",
      "Iteration 9450 => Loss: 22.8447021320\n",
      "Iteration 9451 => Loss: 22.8447000428\n",
      "Iteration 9452 => Loss: 22.8446979559\n",
      "Iteration 9453 => Loss: 22.8446958711\n",
      "Iteration 9454 => Loss: 22.8446937886\n",
      "Iteration 9455 => Loss: 22.8446917083\n",
      "Iteration 9456 => Loss: 22.8446896302\n",
      "Iteration 9457 => Loss: 22.8446875543\n",
      "Iteration 9458 => Loss: 22.8446854806\n",
      "Iteration 9459 => Loss: 22.8446834092\n",
      "Iteration 9460 => Loss: 22.8446813399\n",
      "Iteration 9461 => Loss: 22.8446792728\n",
      "Iteration 9462 => Loss: 22.8446772079\n",
      "Iteration 9463 => Loss: 22.8446751453\n",
      "Iteration 9464 => Loss: 22.8446730848\n",
      "Iteration 9465 => Loss: 22.8446710265\n",
      "Iteration 9466 => Loss: 22.8446689704\n",
      "Iteration 9467 => Loss: 22.8446669164\n",
      "Iteration 9468 => Loss: 22.8446648647\n",
      "Iteration 9469 => Loss: 22.8446628151\n",
      "Iteration 9470 => Loss: 22.8446607678\n",
      "Iteration 9471 => Loss: 22.8446587226\n",
      "Iteration 9472 => Loss: 22.8446566795\n",
      "Iteration 9473 => Loss: 22.8446546387\n",
      "Iteration 9474 => Loss: 22.8446526000\n",
      "Iteration 9475 => Loss: 22.8446505634\n",
      "Iteration 9476 => Loss: 22.8446485291\n",
      "Iteration 9477 => Loss: 22.8446464969\n",
      "Iteration 9478 => Loss: 22.8446444669\n",
      "Iteration 9479 => Loss: 22.8446424390\n",
      "Iteration 9480 => Loss: 22.8446404133\n",
      "Iteration 9481 => Loss: 22.8446383897\n",
      "Iteration 9482 => Loss: 22.8446363683\n",
      "Iteration 9483 => Loss: 22.8446343490\n",
      "Iteration 9484 => Loss: 22.8446323319\n",
      "Iteration 9485 => Loss: 22.8446303169\n",
      "Iteration 9486 => Loss: 22.8446283041\n",
      "Iteration 9487 => Loss: 22.8446262934\n",
      "Iteration 9488 => Loss: 22.8446242848\n",
      "Iteration 9489 => Loss: 22.8446222784\n",
      "Iteration 9490 => Loss: 22.8446202741\n",
      "Iteration 9491 => Loss: 22.8446182719\n",
      "Iteration 9492 => Loss: 22.8446162719\n",
      "Iteration 9493 => Loss: 22.8446142740\n",
      "Iteration 9494 => Loss: 22.8446122782\n",
      "Iteration 9495 => Loss: 22.8446102845\n",
      "Iteration 9496 => Loss: 22.8446082930\n",
      "Iteration 9497 => Loss: 22.8446063036\n",
      "Iteration 9498 => Loss: 22.8446043163\n",
      "Iteration 9499 => Loss: 22.8446023311\n",
      "Iteration 9500 => Loss: 22.8446003480\n",
      "Iteration 9501 => Loss: 22.8445983670\n",
      "Iteration 9502 => Loss: 22.8445963881\n",
      "Iteration 9503 => Loss: 22.8445944113\n",
      "Iteration 9504 => Loss: 22.8445924367\n",
      "Iteration 9505 => Loss: 22.8445904641\n",
      "Iteration 9506 => Loss: 22.8445884936\n",
      "Iteration 9507 => Loss: 22.8445865252\n",
      "Iteration 9508 => Loss: 22.8445845590\n",
      "Iteration 9509 => Loss: 22.8445825948\n",
      "Iteration 9510 => Loss: 22.8445806326\n",
      "Iteration 9511 => Loss: 22.8445786726\n",
      "Iteration 9512 => Loss: 22.8445767147\n",
      "Iteration 9513 => Loss: 22.8445747588\n",
      "Iteration 9514 => Loss: 22.8445728050\n",
      "Iteration 9515 => Loss: 22.8445708533\n",
      "Iteration 9516 => Loss: 22.8445689037\n",
      "Iteration 9517 => Loss: 22.8445669562\n",
      "Iteration 9518 => Loss: 22.8445650107\n",
      "Iteration 9519 => Loss: 22.8445630673\n",
      "Iteration 9520 => Loss: 22.8445611259\n",
      "Iteration 9521 => Loss: 22.8445591866\n",
      "Iteration 9522 => Loss: 22.8445572494\n",
      "Iteration 9523 => Loss: 22.8445553142\n",
      "Iteration 9524 => Loss: 22.8445533811\n",
      "Iteration 9525 => Loss: 22.8445514501\n",
      "Iteration 9526 => Loss: 22.8445495210\n",
      "Iteration 9527 => Loss: 22.8445475941\n",
      "Iteration 9528 => Loss: 22.8445456692\n",
      "Iteration 9529 => Loss: 22.8445437463\n",
      "Iteration 9530 => Loss: 22.8445418255\n",
      "Iteration 9531 => Loss: 22.8445399067\n",
      "Iteration 9532 => Loss: 22.8445379900\n",
      "Iteration 9533 => Loss: 22.8445360753\n",
      "Iteration 9534 => Loss: 22.8445341627\n",
      "Iteration 9535 => Loss: 22.8445322520\n",
      "Iteration 9536 => Loss: 22.8445303434\n",
      "Iteration 9537 => Loss: 22.8445284369\n",
      "Iteration 9538 => Loss: 22.8445265323\n",
      "Iteration 9539 => Loss: 22.8445246298\n",
      "Iteration 9540 => Loss: 22.8445227293\n",
      "Iteration 9541 => Loss: 22.8445208308\n",
      "Iteration 9542 => Loss: 22.8445189344\n",
      "Iteration 9543 => Loss: 22.8445170399\n",
      "Iteration 9544 => Loss: 22.8445151475\n",
      "Iteration 9545 => Loss: 22.8445132571\n",
      "Iteration 9546 => Loss: 22.8445113687\n",
      "Iteration 9547 => Loss: 22.8445094823\n",
      "Iteration 9548 => Loss: 22.8445075979\n",
      "Iteration 9549 => Loss: 22.8445057155\n",
      "Iteration 9550 => Loss: 22.8445038351\n",
      "Iteration 9551 => Loss: 22.8445019567\n",
      "Iteration 9552 => Loss: 22.8445000803\n",
      "Iteration 9553 => Loss: 22.8444982059\n",
      "Iteration 9554 => Loss: 22.8444963335\n",
      "Iteration 9555 => Loss: 22.8444944631\n",
      "Iteration 9556 => Loss: 22.8444925947\n",
      "Iteration 9557 => Loss: 22.8444907283\n",
      "Iteration 9558 => Loss: 22.8444888638\n",
      "Iteration 9559 => Loss: 22.8444870013\n",
      "Iteration 9560 => Loss: 22.8444851408\n",
      "Iteration 9561 => Loss: 22.8444832823\n",
      "Iteration 9562 => Loss: 22.8444814258\n",
      "Iteration 9563 => Loss: 22.8444795712\n",
      "Iteration 9564 => Loss: 22.8444777186\n",
      "Iteration 9565 => Loss: 22.8444758680\n",
      "Iteration 9566 => Loss: 22.8444740193\n",
      "Iteration 9567 => Loss: 22.8444721726\n",
      "Iteration 9568 => Loss: 22.8444703279\n",
      "Iteration 9569 => Loss: 22.8444684851\n",
      "Iteration 9570 => Loss: 22.8444666443\n",
      "Iteration 9571 => Loss: 22.8444648054\n",
      "Iteration 9572 => Loss: 22.8444629685\n",
      "Iteration 9573 => Loss: 22.8444611336\n",
      "Iteration 9574 => Loss: 22.8444593006\n",
      "Iteration 9575 => Loss: 22.8444574695\n",
      "Iteration 9576 => Loss: 22.8444556404\n",
      "Iteration 9577 => Loss: 22.8444538133\n",
      "Iteration 9578 => Loss: 22.8444519881\n",
      "Iteration 9579 => Loss: 22.8444501648\n",
      "Iteration 9580 => Loss: 22.8444483434\n",
      "Iteration 9581 => Loss: 22.8444465240\n",
      "Iteration 9582 => Loss: 22.8444447066\n",
      "Iteration 9583 => Loss: 22.8444428910\n",
      "Iteration 9584 => Loss: 22.8444410774\n",
      "Iteration 9585 => Loss: 22.8444392657\n",
      "Iteration 9586 => Loss: 22.8444374560\n",
      "Iteration 9587 => Loss: 22.8444356482\n",
      "Iteration 9588 => Loss: 22.8444338423\n",
      "Iteration 9589 => Loss: 22.8444320383\n",
      "Iteration 9590 => Loss: 22.8444302362\n",
      "Iteration 9591 => Loss: 22.8444284360\n",
      "Iteration 9592 => Loss: 22.8444266378\n",
      "Iteration 9593 => Loss: 22.8444248415\n",
      "Iteration 9594 => Loss: 22.8444230470\n",
      "Iteration 9595 => Loss: 22.8444212545\n",
      "Iteration 9596 => Loss: 22.8444194639\n",
      "Iteration 9597 => Loss: 22.8444176752\n",
      "Iteration 9598 => Loss: 22.8444158884\n",
      "Iteration 9599 => Loss: 22.8444141035\n",
      "Iteration 9600 => Loss: 22.8444123205\n",
      "Iteration 9601 => Loss: 22.8444105394\n",
      "Iteration 9602 => Loss: 22.8444087602\n",
      "Iteration 9603 => Loss: 22.8444069828\n",
      "Iteration 9604 => Loss: 22.8444052074\n",
      "Iteration 9605 => Loss: 22.8444034339\n",
      "Iteration 9606 => Loss: 22.8444016622\n",
      "Iteration 9607 => Loss: 22.8443998924\n",
      "Iteration 9608 => Loss: 22.8443981245\n",
      "Iteration 9609 => Loss: 22.8443963585\n",
      "Iteration 9610 => Loss: 22.8443945943\n",
      "Iteration 9611 => Loss: 22.8443928321\n",
      "Iteration 9612 => Loss: 22.8443910717\n",
      "Iteration 9613 => Loss: 22.8443893132\n",
      "Iteration 9614 => Loss: 22.8443875565\n",
      "Iteration 9615 => Loss: 22.8443858017\n",
      "Iteration 9616 => Loss: 22.8443840488\n",
      "Iteration 9617 => Loss: 22.8443822977\n",
      "Iteration 9618 => Loss: 22.8443805485\n",
      "Iteration 9619 => Loss: 22.8443788012\n",
      "Iteration 9620 => Loss: 22.8443770557\n",
      "Iteration 9621 => Loss: 22.8443753121\n",
      "Iteration 9622 => Loss: 22.8443735703\n",
      "Iteration 9623 => Loss: 22.8443718304\n",
      "Iteration 9624 => Loss: 22.8443700923\n",
      "Iteration 9625 => Loss: 22.8443683561\n",
      "Iteration 9626 => Loss: 22.8443666217\n",
      "Iteration 9627 => Loss: 22.8443648892\n",
      "Iteration 9628 => Loss: 22.8443631585\n",
      "Iteration 9629 => Loss: 22.8443614296\n",
      "Iteration 9630 => Loss: 22.8443597026\n",
      "Iteration 9631 => Loss: 22.8443579774\n",
      "Iteration 9632 => Loss: 22.8443562541\n",
      "Iteration 9633 => Loss: 22.8443545326\n",
      "Iteration 9634 => Loss: 22.8443528129\n",
      "Iteration 9635 => Loss: 22.8443510950\n",
      "Iteration 9636 => Loss: 22.8443493790\n",
      "Iteration 9637 => Loss: 22.8443476648\n",
      "Iteration 9638 => Loss: 22.8443459524\n",
      "Iteration 9639 => Loss: 22.8443442419\n",
      "Iteration 9640 => Loss: 22.8443425331\n",
      "Iteration 9641 => Loss: 22.8443408262\n",
      "Iteration 9642 => Loss: 22.8443391211\n",
      "Iteration 9643 => Loss: 22.8443374178\n",
      "Iteration 9644 => Loss: 22.8443357163\n",
      "Iteration 9645 => Loss: 22.8443340166\n",
      "Iteration 9646 => Loss: 22.8443323187\n",
      "Iteration 9647 => Loss: 22.8443306226\n",
      "Iteration 9648 => Loss: 22.8443289284\n",
      "Iteration 9649 => Loss: 22.8443272359\n",
      "Iteration 9650 => Loss: 22.8443255452\n",
      "Iteration 9651 => Loss: 22.8443238564\n",
      "Iteration 9652 => Loss: 22.8443221693\n",
      "Iteration 9653 => Loss: 22.8443204840\n",
      "Iteration 9654 => Loss: 22.8443188005\n",
      "Iteration 9655 => Loss: 22.8443171188\n",
      "Iteration 9656 => Loss: 22.8443154389\n",
      "Iteration 9657 => Loss: 22.8443137608\n",
      "Iteration 9658 => Loss: 22.8443120844\n",
      "Iteration 9659 => Loss: 22.8443104099\n",
      "Iteration 9660 => Loss: 22.8443087371\n",
      "Iteration 9661 => Loss: 22.8443070661\n",
      "Iteration 9662 => Loss: 22.8443053969\n",
      "Iteration 9663 => Loss: 22.8443037294\n",
      "Iteration 9664 => Loss: 22.8443020637\n",
      "Iteration 9665 => Loss: 22.8443003998\n",
      "Iteration 9666 => Loss: 22.8442987377\n",
      "Iteration 9667 => Loss: 22.8442970773\n",
      "Iteration 9668 => Loss: 22.8442954187\n",
      "Iteration 9669 => Loss: 22.8442937618\n",
      "Iteration 9670 => Loss: 22.8442921067\n",
      "Iteration 9671 => Loss: 22.8442904534\n",
      "Iteration 9672 => Loss: 22.8442888018\n",
      "Iteration 9673 => Loss: 22.8442871520\n",
      "Iteration 9674 => Loss: 22.8442855040\n",
      "Iteration 9675 => Loss: 22.8442838577\n",
      "Iteration 9676 => Loss: 22.8442822131\n",
      "Iteration 9677 => Loss: 22.8442805703\n",
      "Iteration 9678 => Loss: 22.8442789292\n",
      "Iteration 9679 => Loss: 22.8442772899\n",
      "Iteration 9680 => Loss: 22.8442756523\n",
      "Iteration 9681 => Loss: 22.8442740165\n",
      "Iteration 9682 => Loss: 22.8442723824\n",
      "Iteration 9683 => Loss: 22.8442707500\n",
      "Iteration 9684 => Loss: 22.8442691194\n",
      "Iteration 9685 => Loss: 22.8442674905\n",
      "Iteration 9686 => Loss: 22.8442658634\n",
      "Iteration 9687 => Loss: 22.8442642379\n",
      "Iteration 9688 => Loss: 22.8442626142\n",
      "Iteration 9689 => Loss: 22.8442609923\n",
      "Iteration 9690 => Loss: 22.8442593720\n",
      "Iteration 9691 => Loss: 22.8442577535\n",
      "Iteration 9692 => Loss: 22.8442561367\n",
      "Iteration 9693 => Loss: 22.8442545216\n",
      "Iteration 9694 => Loss: 22.8442529082\n",
      "Iteration 9695 => Loss: 22.8442512965\n",
      "Iteration 9696 => Loss: 22.8442496866\n",
      "Iteration 9697 => Loss: 22.8442480784\n",
      "Iteration 9698 => Loss: 22.8442464718\n",
      "Iteration 9699 => Loss: 22.8442448670\n",
      "Iteration 9700 => Loss: 22.8442432639\n",
      "Iteration 9701 => Loss: 22.8442416625\n",
      "Iteration 9702 => Loss: 22.8442400628\n",
      "Iteration 9703 => Loss: 22.8442384648\n",
      "Iteration 9704 => Loss: 22.8442368685\n",
      "Iteration 9705 => Loss: 22.8442352739\n",
      "Iteration 9706 => Loss: 22.8442336809\n",
      "Iteration 9707 => Loss: 22.8442320897\n",
      "Iteration 9708 => Loss: 22.8442305002\n",
      "Iteration 9709 => Loss: 22.8442289124\n",
      "Iteration 9710 => Loss: 22.8442273262\n",
      "Iteration 9711 => Loss: 22.8442257417\n",
      "Iteration 9712 => Loss: 22.8442241590\n",
      "Iteration 9713 => Loss: 22.8442225779\n",
      "Iteration 9714 => Loss: 22.8442209984\n",
      "Iteration 9715 => Loss: 22.8442194207\n",
      "Iteration 9716 => Loss: 22.8442178446\n",
      "Iteration 9717 => Loss: 22.8442162702\n",
      "Iteration 9718 => Loss: 22.8442146975\n",
      "Iteration 9719 => Loss: 22.8442131265\n",
      "Iteration 9720 => Loss: 22.8442115571\n",
      "Iteration 9721 => Loss: 22.8442099894\n",
      "Iteration 9722 => Loss: 22.8442084234\n",
      "Iteration 9723 => Loss: 22.8442068590\n",
      "Iteration 9724 => Loss: 22.8442052963\n",
      "Iteration 9725 => Loss: 22.8442037352\n",
      "Iteration 9726 => Loss: 22.8442021758\n",
      "Iteration 9727 => Loss: 22.8442006181\n",
      "Iteration 9728 => Loss: 22.8441990620\n",
      "Iteration 9729 => Loss: 22.8441975076\n",
      "Iteration 9730 => Loss: 22.8441959548\n",
      "Iteration 9731 => Loss: 22.8441944037\n",
      "Iteration 9732 => Loss: 22.8441928543\n",
      "Iteration 9733 => Loss: 22.8441913064\n",
      "Iteration 9734 => Loss: 22.8441897603\n",
      "Iteration 9735 => Loss: 22.8441882157\n",
      "Iteration 9736 => Loss: 22.8441866728\n",
      "Iteration 9737 => Loss: 22.8441851316\n",
      "Iteration 9738 => Loss: 22.8441835920\n",
      "Iteration 9739 => Loss: 22.8441820540\n",
      "Iteration 9740 => Loss: 22.8441805176\n",
      "Iteration 9741 => Loss: 22.8441789829\n",
      "Iteration 9742 => Loss: 22.8441774499\n",
      "Iteration 9743 => Loss: 22.8441759184\n",
      "Iteration 9744 => Loss: 22.8441743886\n",
      "Iteration 9745 => Loss: 22.8441728604\n",
      "Iteration 9746 => Loss: 22.8441713338\n",
      "Iteration 9747 => Loss: 22.8441698089\n",
      "Iteration 9748 => Loss: 22.8441682855\n",
      "Iteration 9749 => Loss: 22.8441667638\n",
      "Iteration 9750 => Loss: 22.8441652437\n",
      "Iteration 9751 => Loss: 22.8441637253\n",
      "Iteration 9752 => Loss: 22.8441622084\n",
      "Iteration 9753 => Loss: 22.8441606932\n",
      "Iteration 9754 => Loss: 22.8441591795\n",
      "Iteration 9755 => Loss: 22.8441576675\n",
      "Iteration 9756 => Loss: 22.8441561571\n",
      "Iteration 9757 => Loss: 22.8441546483\n",
      "Iteration 9758 => Loss: 22.8441531410\n",
      "Iteration 9759 => Loss: 22.8441516354\n",
      "Iteration 9760 => Loss: 22.8441501314\n",
      "Iteration 9761 => Loss: 22.8441486290\n",
      "Iteration 9762 => Loss: 22.8441471282\n",
      "Iteration 9763 => Loss: 22.8441456290\n",
      "Iteration 9764 => Loss: 22.8441441314\n",
      "Iteration 9765 => Loss: 22.8441426353\n",
      "Iteration 9766 => Loss: 22.8441411409\n",
      "Iteration 9767 => Loss: 22.8441396480\n",
      "Iteration 9768 => Loss: 22.8441381568\n",
      "Iteration 9769 => Loss: 22.8441366671\n",
      "Iteration 9770 => Loss: 22.8441351790\n",
      "Iteration 9771 => Loss: 22.8441336925\n",
      "Iteration 9772 => Loss: 22.8441322075\n",
      "Iteration 9773 => Loss: 22.8441307242\n",
      "Iteration 9774 => Loss: 22.8441292424\n",
      "Iteration 9775 => Loss: 22.8441277622\n",
      "Iteration 9776 => Loss: 22.8441262836\n",
      "Iteration 9777 => Loss: 22.8441248065\n",
      "Iteration 9778 => Loss: 22.8441233310\n",
      "Iteration 9779 => Loss: 22.8441218571\n",
      "Iteration 9780 => Loss: 22.8441203847\n",
      "Iteration 9781 => Loss: 22.8441189139\n",
      "Iteration 9782 => Loss: 22.8441174447\n",
      "Iteration 9783 => Loss: 22.8441159771\n",
      "Iteration 9784 => Loss: 22.8441145109\n",
      "Iteration 9785 => Loss: 22.8441130464\n",
      "Iteration 9786 => Loss: 22.8441115834\n",
      "Iteration 9787 => Loss: 22.8441101220\n",
      "Iteration 9788 => Loss: 22.8441086621\n",
      "Iteration 9789 => Loss: 22.8441072038\n",
      "Iteration 9790 => Loss: 22.8441057470\n",
      "Iteration 9791 => Loss: 22.8441042918\n",
      "Iteration 9792 => Loss: 22.8441028381\n",
      "Iteration 9793 => Loss: 22.8441013859\n",
      "Iteration 9794 => Loss: 22.8440999353\n",
      "Iteration 9795 => Loss: 22.8440984863\n",
      "Iteration 9796 => Loss: 22.8440970388\n",
      "Iteration 9797 => Loss: 22.8440955928\n",
      "Iteration 9798 => Loss: 22.8440941484\n",
      "Iteration 9799 => Loss: 22.8440927055\n",
      "Iteration 9800 => Loss: 22.8440912641\n",
      "Iteration 9801 => Loss: 22.8440898243\n",
      "Iteration 9802 => Loss: 22.8440883860\n",
      "Iteration 9803 => Loss: 22.8440869492\n",
      "Iteration 9804 => Loss: 22.8440855139\n",
      "Iteration 9805 => Loss: 22.8440840802\n",
      "Iteration 9806 => Loss: 22.8440826480\n",
      "Iteration 9807 => Loss: 22.8440812173\n",
      "Iteration 9808 => Loss: 22.8440797882\n",
      "Iteration 9809 => Loss: 22.8440783605\n",
      "Iteration 9810 => Loss: 22.8440769344\n",
      "Iteration 9811 => Loss: 22.8440755098\n",
      "Iteration 9812 => Loss: 22.8440740867\n",
      "Iteration 9813 => Loss: 22.8440726652\n",
      "Iteration 9814 => Loss: 22.8440712451\n",
      "Iteration 9815 => Loss: 22.8440698265\n",
      "Iteration 9816 => Loss: 22.8440684095\n",
      "Iteration 9817 => Loss: 22.8440669939\n",
      "Iteration 9818 => Loss: 22.8440655799\n",
      "Iteration 9819 => Loss: 22.8440641674\n",
      "Iteration 9820 => Loss: 22.8440627563\n",
      "Iteration 9821 => Loss: 22.8440613468\n",
      "Iteration 9822 => Loss: 22.8440599388\n",
      "Iteration 9823 => Loss: 22.8440585322\n",
      "Iteration 9824 => Loss: 22.8440571272\n",
      "Iteration 9825 => Loss: 22.8440557236\n",
      "Iteration 9826 => Loss: 22.8440543216\n",
      "Iteration 9827 => Loss: 22.8440529210\n",
      "Iteration 9828 => Loss: 22.8440515219\n",
      "Iteration 9829 => Loss: 22.8440501244\n",
      "Iteration 9830 => Loss: 22.8440487283\n",
      "Iteration 9831 => Loss: 22.8440473336\n",
      "Iteration 9832 => Loss: 22.8440459405\n",
      "Iteration 9833 => Loss: 22.8440445488\n",
      "Iteration 9834 => Loss: 22.8440431587\n",
      "Iteration 9835 => Loss: 22.8440417700\n",
      "Iteration 9836 => Loss: 22.8440403827\n",
      "Iteration 9837 => Loss: 22.8440389970\n",
      "Iteration 9838 => Loss: 22.8440376127\n",
      "Iteration 9839 => Loss: 22.8440362299\n",
      "Iteration 9840 => Loss: 22.8440348486\n",
      "Iteration 9841 => Loss: 22.8440334687\n",
      "Iteration 9842 => Loss: 22.8440320903\n",
      "Iteration 9843 => Loss: 22.8440307134\n",
      "Iteration 9844 => Loss: 22.8440293379\n",
      "Iteration 9845 => Loss: 22.8440279639\n",
      "Iteration 9846 => Loss: 22.8440265913\n",
      "Iteration 9847 => Loss: 22.8440252202\n",
      "Iteration 9848 => Loss: 22.8440238506\n",
      "Iteration 9849 => Loss: 22.8440224824\n",
      "Iteration 9850 => Loss: 22.8440211157\n",
      "Iteration 9851 => Loss: 22.8440197504\n",
      "Iteration 9852 => Loss: 22.8440183866\n",
      "Iteration 9853 => Loss: 22.8440170243\n",
      "Iteration 9854 => Loss: 22.8440156633\n",
      "Iteration 9855 => Loss: 22.8440143039\n",
      "Iteration 9856 => Loss: 22.8440129458\n",
      "Iteration 9857 => Loss: 22.8440115893\n",
      "Iteration 9858 => Loss: 22.8440102341\n",
      "Iteration 9859 => Loss: 22.8440088804\n",
      "Iteration 9860 => Loss: 22.8440075281\n",
      "Iteration 9861 => Loss: 22.8440061773\n",
      "Iteration 9862 => Loss: 22.8440048279\n",
      "Iteration 9863 => Loss: 22.8440034800\n",
      "Iteration 9864 => Loss: 22.8440021334\n",
      "Iteration 9865 => Loss: 22.8440007884\n",
      "Iteration 9866 => Loss: 22.8439994447\n",
      "Iteration 9867 => Loss: 22.8439981025\n",
      "Iteration 9868 => Loss: 22.8439967617\n",
      "Iteration 9869 => Loss: 22.8439954223\n",
      "Iteration 9870 => Loss: 22.8439940843\n",
      "Iteration 9871 => Loss: 22.8439927478\n",
      "Iteration 9872 => Loss: 22.8439914127\n",
      "Iteration 9873 => Loss: 22.8439900790\n",
      "Iteration 9874 => Loss: 22.8439887467\n",
      "Iteration 9875 => Loss: 22.8439874158\n",
      "Iteration 9876 => Loss: 22.8439860864\n",
      "Iteration 9877 => Loss: 22.8439847584\n",
      "Iteration 9878 => Loss: 22.8439834317\n",
      "Iteration 9879 => Loss: 22.8439821065\n",
      "Iteration 9880 => Loss: 22.8439807827\n",
      "Iteration 9881 => Loss: 22.8439794603\n",
      "Iteration 9882 => Loss: 22.8439781393\n",
      "Iteration 9883 => Loss: 22.8439768197\n",
      "Iteration 9884 => Loss: 22.8439755016\n",
      "Iteration 9885 => Loss: 22.8439741848\n",
      "Iteration 9886 => Loss: 22.8439728694\n",
      "Iteration 9887 => Loss: 22.8439715554\n",
      "Iteration 9888 => Loss: 22.8439702428\n",
      "Iteration 9889 => Loss: 22.8439689316\n",
      "Iteration 9890 => Loss: 22.8439676218\n",
      "Iteration 9891 => Loss: 22.8439663134\n",
      "Iteration 9892 => Loss: 22.8439650064\n",
      "Iteration 9893 => Loss: 22.8439637008\n",
      "Iteration 9894 => Loss: 22.8439623965\n",
      "Iteration 9895 => Loss: 22.8439610937\n",
      "Iteration 9896 => Loss: 22.8439597922\n",
      "Iteration 9897 => Loss: 22.8439584921\n",
      "Iteration 9898 => Loss: 22.8439571934\n",
      "Iteration 9899 => Loss: 22.8439558961\n",
      "Iteration 9900 => Loss: 22.8439546002\n",
      "Iteration 9901 => Loss: 22.8439533056\n",
      "Iteration 9902 => Loss: 22.8439520124\n",
      "Iteration 9903 => Loss: 22.8439507206\n",
      "Iteration 9904 => Loss: 22.8439494302\n",
      "Iteration 9905 => Loss: 22.8439481411\n",
      "Iteration 9906 => Loss: 22.8439468534\n",
      "Iteration 9907 => Loss: 22.8439455671\n",
      "Iteration 9908 => Loss: 22.8439442821\n",
      "Iteration 9909 => Loss: 22.8439429985\n",
      "Iteration 9910 => Loss: 22.8439417163\n",
      "Iteration 9911 => Loss: 22.8439404354\n",
      "Iteration 9912 => Loss: 22.8439391559\n",
      "Iteration 9913 => Loss: 22.8439378778\n",
      "Iteration 9914 => Loss: 22.8439366010\n",
      "Iteration 9915 => Loss: 22.8439353255\n",
      "Iteration 9916 => Loss: 22.8439340515\n",
      "Iteration 9917 => Loss: 22.8439327787\n",
      "Iteration 9918 => Loss: 22.8439315074\n",
      "Iteration 9919 => Loss: 22.8439302374\n",
      "Iteration 9920 => Loss: 22.8439289687\n",
      "Iteration 9921 => Loss: 22.8439277014\n",
      "Iteration 9922 => Loss: 22.8439264354\n",
      "Iteration 9923 => Loss: 22.8439251708\n",
      "Iteration 9924 => Loss: 22.8439239075\n",
      "Iteration 9925 => Loss: 22.8439226455\n",
      "Iteration 9926 => Loss: 22.8439213849\n",
      "Iteration 9927 => Loss: 22.8439201257\n",
      "Iteration 9928 => Loss: 22.8439188678\n",
      "Iteration 9929 => Loss: 22.8439176112\n",
      "Iteration 9930 => Loss: 22.8439163559\n",
      "Iteration 9931 => Loss: 22.8439151020\n",
      "Iteration 9932 => Loss: 22.8439138495\n",
      "Iteration 9933 => Loss: 22.8439125982\n",
      "Iteration 9934 => Loss: 22.8439113483\n",
      "Iteration 9935 => Loss: 22.8439100997\n",
      "Iteration 9936 => Loss: 22.8439088524\n",
      "Iteration 9937 => Loss: 22.8439076065\n",
      "Iteration 9938 => Loss: 22.8439063619\n",
      "Iteration 9939 => Loss: 22.8439051186\n",
      "Iteration 9940 => Loss: 22.8439038766\n",
      "Iteration 9941 => Loss: 22.8439026360\n",
      "Iteration 9942 => Loss: 22.8439013967\n",
      "Iteration 9943 => Loss: 22.8439001587\n",
      "Iteration 9944 => Loss: 22.8438989220\n",
      "Iteration 9945 => Loss: 22.8438976866\n",
      "Iteration 9946 => Loss: 22.8438964525\n",
      "Iteration 9947 => Loss: 22.8438952198\n",
      "Iteration 9948 => Loss: 22.8438939883\n",
      "Iteration 9949 => Loss: 22.8438927582\n",
      "Iteration 9950 => Loss: 22.8438915293\n",
      "Iteration 9951 => Loss: 22.8438903018\n",
      "Iteration 9952 => Loss: 22.8438890756\n",
      "Iteration 9953 => Loss: 22.8438878507\n",
      "Iteration 9954 => Loss: 22.8438866271\n",
      "Iteration 9955 => Loss: 22.8438854048\n",
      "Iteration 9956 => Loss: 22.8438841838\n",
      "Iteration 9957 => Loss: 22.8438829640\n",
      "Iteration 9958 => Loss: 22.8438817456\n",
      "Iteration 9959 => Loss: 22.8438805285\n",
      "Iteration 9960 => Loss: 22.8438793127\n",
      "Iteration 9961 => Loss: 22.8438780981\n",
      "Iteration 9962 => Loss: 22.8438768849\n",
      "Iteration 9963 => Loss: 22.8438756729\n",
      "Iteration 9964 => Loss: 22.8438744623\n",
      "Iteration 9965 => Loss: 22.8438732529\n",
      "Iteration 9966 => Loss: 22.8438720448\n",
      "Iteration 9967 => Loss: 22.8438708380\n",
      "Iteration 9968 => Loss: 22.8438696325\n",
      "Iteration 9969 => Loss: 22.8438684282\n",
      "Iteration 9970 => Loss: 22.8438672253\n",
      "Iteration 9971 => Loss: 22.8438660236\n",
      "Iteration 9972 => Loss: 22.8438648232\n",
      "Iteration 9973 => Loss: 22.8438636240\n",
      "Iteration 9974 => Loss: 22.8438624262\n",
      "Iteration 9975 => Loss: 22.8438612296\n",
      "Iteration 9976 => Loss: 22.8438600343\n",
      "Iteration 9977 => Loss: 22.8438588402\n",
      "Iteration 9978 => Loss: 22.8438576475\n",
      "Iteration 9979 => Loss: 22.8438564559\n",
      "Iteration 9980 => Loss: 22.8438552657\n",
      "Iteration 9981 => Loss: 22.8438540767\n",
      "Iteration 9982 => Loss: 22.8438528890\n",
      "Iteration 9983 => Loss: 22.8438517026\n",
      "Iteration 9984 => Loss: 22.8438505174\n",
      "Iteration 9985 => Loss: 22.8438493335\n",
      "Iteration 9986 => Loss: 22.8438481508\n",
      "Iteration 9987 => Loss: 22.8438469694\n",
      "Iteration 9988 => Loss: 22.8438457892\n",
      "Iteration 9989 => Loss: 22.8438446103\n",
      "Iteration 9990 => Loss: 22.8438434327\n",
      "Iteration 9991 => Loss: 22.8438422563\n",
      "Iteration 9992 => Loss: 22.8438410811\n",
      "Iteration 9993 => Loss: 22.8438399072\n",
      "Iteration 9994 => Loss: 22.8438387346\n",
      "Iteration 9995 => Loss: 22.8438375632\n",
      "Iteration 9996 => Loss: 22.8438363930\n",
      "Iteration 9997 => Loss: 22.8438352241\n",
      "Iteration 9998 => Loss: 22.8438340565\n",
      "Iteration 9999 => Loss: 22.8438328900\n",
      "Iteration 10000 => Loss: 22.8438317248\n",
      "Iteration 10001 => Loss: 22.8438305609\n",
      "Iteration 10002 => Loss: 22.8438293982\n",
      "Iteration 10003 => Loss: 22.8438282367\n",
      "Iteration 10004 => Loss: 22.8438270764\n",
      "Iteration 10005 => Loss: 22.8438259174\n",
      "Iteration 10006 => Loss: 22.8438247597\n",
      "Iteration 10007 => Loss: 22.8438236031\n",
      "Iteration 10008 => Loss: 22.8438224478\n",
      "Iteration 10009 => Loss: 22.8438212937\n",
      "Iteration 10010 => Loss: 22.8438201408\n",
      "Iteration 10011 => Loss: 22.8438189892\n",
      "Iteration 10012 => Loss: 22.8438178388\n",
      "Iteration 10013 => Loss: 22.8438166896\n",
      "Iteration 10014 => Loss: 22.8438155416\n",
      "Iteration 10015 => Loss: 22.8438143949\n",
      "Iteration 10016 => Loss: 22.8438132494\n",
      "Iteration 10017 => Loss: 22.8438121050\n",
      "Iteration 10018 => Loss: 22.8438109620\n",
      "Iteration 10019 => Loss: 22.8438098201\n",
      "Iteration 10020 => Loss: 22.8438086794\n",
      "Iteration 10021 => Loss: 22.8438075400\n",
      "Iteration 10022 => Loss: 22.8438064017\n",
      "Iteration 10023 => Loss: 22.8438052647\n",
      "Iteration 10024 => Loss: 22.8438041289\n",
      "Iteration 10025 => Loss: 22.8438029942\n",
      "Iteration 10026 => Loss: 22.8438018608\n",
      "Iteration 10027 => Loss: 22.8438007286\n",
      "Iteration 10028 => Loss: 22.8437995976\n",
      "Iteration 10029 => Loss: 22.8437984678\n",
      "Iteration 10030 => Loss: 22.8437973392\n",
      "Iteration 10031 => Loss: 22.8437962118\n",
      "Iteration 10032 => Loss: 22.8437950856\n",
      "Iteration 10033 => Loss: 22.8437939606\n",
      "Iteration 10034 => Loss: 22.8437928368\n",
      "Iteration 10035 => Loss: 22.8437917142\n",
      "Iteration 10036 => Loss: 22.8437905928\n",
      "Iteration 10037 => Loss: 22.8437894725\n",
      "Iteration 10038 => Loss: 22.8437883535\n",
      "Iteration 10039 => Loss: 22.8437872357\n",
      "Iteration 10040 => Loss: 22.8437861190\n",
      "Iteration 10041 => Loss: 22.8437850035\n",
      "Iteration 10042 => Loss: 22.8437838892\n",
      "Iteration 10043 => Loss: 22.8437827761\n",
      "Iteration 10044 => Loss: 22.8437816642\n",
      "Iteration 10045 => Loss: 22.8437805535\n",
      "Iteration 10046 => Loss: 22.8437794439\n",
      "Iteration 10047 => Loss: 22.8437783355\n",
      "Iteration 10048 => Loss: 22.8437772283\n",
      "Iteration 10049 => Loss: 22.8437761223\n",
      "Iteration 10050 => Loss: 22.8437750175\n",
      "Iteration 10051 => Loss: 22.8437739138\n",
      "Iteration 10052 => Loss: 22.8437728113\n",
      "Iteration 10053 => Loss: 22.8437717100\n",
      "Iteration 10054 => Loss: 22.8437706098\n",
      "Iteration 10055 => Loss: 22.8437695108\n",
      "Iteration 10056 => Loss: 22.8437684130\n",
      "Iteration 10057 => Loss: 22.8437673164\n",
      "Iteration 10058 => Loss: 22.8437662209\n",
      "Iteration 10059 => Loss: 22.8437651266\n",
      "Iteration 10060 => Loss: 22.8437640334\n",
      "Iteration 10061 => Loss: 22.8437629414\n",
      "Iteration 10062 => Loss: 22.8437618506\n",
      "Iteration 10063 => Loss: 22.8437607609\n",
      "Iteration 10064 => Loss: 22.8437596724\n",
      "Iteration 10065 => Loss: 22.8437585850\n",
      "Iteration 10066 => Loss: 22.8437574988\n",
      "Iteration 10067 => Loss: 22.8437564138\n",
      "Iteration 10068 => Loss: 22.8437553299\n",
      "Iteration 10069 => Loss: 22.8437542471\n",
      "Iteration 10070 => Loss: 22.8437531655\n",
      "Iteration 10071 => Loss: 22.8437520851\n",
      "Iteration 10072 => Loss: 22.8437510058\n",
      "Iteration 10073 => Loss: 22.8437499276\n",
      "Iteration 10074 => Loss: 22.8437488506\n",
      "Iteration 10075 => Loss: 22.8437477748\n",
      "Iteration 10076 => Loss: 22.8437467001\n",
      "Iteration 10077 => Loss: 22.8437456265\n",
      "Iteration 10078 => Loss: 22.8437445541\n",
      "Iteration 10079 => Loss: 22.8437434828\n",
      "Iteration 10080 => Loss: 22.8437424126\n",
      "Iteration 10081 => Loss: 22.8437413436\n",
      "Iteration 10082 => Loss: 22.8437402757\n",
      "Iteration 10083 => Loss: 22.8437392090\n",
      "Iteration 10084 => Loss: 22.8437381434\n",
      "Iteration 10085 => Loss: 22.8437370789\n",
      "Iteration 10086 => Loss: 22.8437360156\n",
      "Iteration 10087 => Loss: 22.8437349533\n",
      "Iteration 10088 => Loss: 22.8437338923\n",
      "Iteration 10089 => Loss: 22.8437328323\n",
      "Iteration 10090 => Loss: 22.8437317735\n",
      "Iteration 10091 => Loss: 22.8437307158\n",
      "Iteration 10092 => Loss: 22.8437296592\n",
      "Iteration 10093 => Loss: 22.8437286037\n",
      "Iteration 10094 => Loss: 22.8437275494\n",
      "Iteration 10095 => Loss: 22.8437264962\n",
      "Iteration 10096 => Loss: 22.8437254441\n",
      "Iteration 10097 => Loss: 22.8437243931\n",
      "Iteration 10098 => Loss: 22.8437233433\n",
      "Iteration 10099 => Loss: 22.8437222945\n",
      "Iteration 10100 => Loss: 22.8437212469\n",
      "Iteration 10101 => Loss: 22.8437202004\n",
      "Iteration 10102 => Loss: 22.8437191550\n",
      "Iteration 10103 => Loss: 22.8437181107\n",
      "Iteration 10104 => Loss: 22.8437170675\n",
      "Iteration 10105 => Loss: 22.8437160254\n",
      "Iteration 10106 => Loss: 22.8437149845\n",
      "Iteration 10107 => Loss: 22.8437139446\n",
      "Iteration 10108 => Loss: 22.8437129058\n",
      "Iteration 10109 => Loss: 22.8437118682\n",
      "Iteration 10110 => Loss: 22.8437108316\n",
      "Iteration 10111 => Loss: 22.8437097962\n",
      "Iteration 10112 => Loss: 22.8437087619\n",
      "Iteration 10113 => Loss: 22.8437077286\n",
      "Iteration 10114 => Loss: 22.8437066965\n",
      "Iteration 10115 => Loss: 22.8437056654\n",
      "Iteration 10116 => Loss: 22.8437046355\n",
      "Iteration 10117 => Loss: 22.8437036066\n",
      "Iteration 10118 => Loss: 22.8437025789\n",
      "Iteration 10119 => Loss: 22.8437015522\n",
      "Iteration 10120 => Loss: 22.8437005266\n",
      "Iteration 10121 => Loss: 22.8436995021\n",
      "Iteration 10122 => Loss: 22.8436984787\n",
      "Iteration 10123 => Loss: 22.8436974564\n",
      "Iteration 10124 => Loss: 22.8436964352\n",
      "Iteration 10125 => Loss: 22.8436954150\n",
      "Iteration 10126 => Loss: 22.8436943960\n",
      "Iteration 10127 => Loss: 22.8436933780\n",
      "Iteration 10128 => Loss: 22.8436923611\n",
      "Iteration 10129 => Loss: 22.8436913453\n",
      "Iteration 10130 => Loss: 22.8436903306\n",
      "Iteration 10131 => Loss: 22.8436893169\n",
      "Iteration 10132 => Loss: 22.8436883043\n",
      "Iteration 10133 => Loss: 22.8436872928\n",
      "Iteration 10134 => Loss: 22.8436862824\n",
      "Iteration 10135 => Loss: 22.8436852731\n",
      "Iteration 10136 => Loss: 22.8436842648\n",
      "Iteration 10137 => Loss: 22.8436832576\n",
      "Iteration 10138 => Loss: 22.8436822515\n",
      "Iteration 10139 => Loss: 22.8436812464\n",
      "Iteration 10140 => Loss: 22.8436802424\n",
      "Iteration 10141 => Loss: 22.8436792395\n",
      "Iteration 10142 => Loss: 22.8436782376\n",
      "Iteration 10143 => Loss: 22.8436772368\n",
      "\n",
      "w=1.0845520763, b=13.1132305380\n",
      "Prediction: x=20 => y=34.80\n"
     ]
    }
   ],
   "source": [
    "# Load data, train model\n",
    "X, Y = np.loadtxt(\"pizza.txt\", skiprows=1, unpack=True)\n",
    "w, b, history = train_with_history(X, Y, iterations=100000,\n",
    "                                   lr=0.001, precision=0.000001,\n",
    "                                   initial_w=-0, initial_b=0)\n",
    "\n",
    "print(\"\\nw=%.10f, b=%.10f\" % (w, b))\n",
    "print(\"Prediction: x=%d => y=%.2f\" % (20, predict(20, w, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare history\n",
    "history = np.array(history)\n",
    "history_w = history[:, 0]\n",
    "history_b = history[:, 1]\n",
    "history_loss = history[:, 2]\n",
    "\n",
    "# Prepare matrices for 3D plot (W, B and L for weights, biases and losses)\n",
    "MESH_SIZE = 20\n",
    "weights = np.linspace(np.min(history_w) - 10, np.max(history_w) + 10,\n",
    "                      MESH_SIZE)\n",
    "biases = np.linspace(np.min(history_b) - 100, np.max(history_b) + 100,\n",
    "                     MESH_SIZE)\n",
    "W, B = np.meshgrid(weights, biases)\n",
    "losses = np.array([loss(X, Y, w, b) for w, b in zip(np.ravel(W), np.ravel(B))])\n",
    "L = losses.reshape((MESH_SIZE, MESH_SIZE))\n",
    "\n",
    "# Plot surface\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"figure.facecolor\": \"white\"})\n",
    "ax = plt.figure().gca(projection=\"3d\")\n",
    "ax.set_zticklabels(())\n",
    "ax.set_xlabel(\"Weight\", labelpad=20, fontsize=30)\n",
    "ax.set_ylabel(\"Bias\", labelpad=20, fontsize=30)\n",
    "ax.set_zlabel(\"Loss\", labelpad=5, fontsize=30)\n",
    "ax.plot_surface(W, B, L, cmap=cm.Blues, linewidth=0, antialiased=True)\n",
    "\n",
    "# Trace the partial derivative \"slices\"\n",
    "plt.plot(weights, [history_b[0] for w in weights],\n",
    "         [loss(X, Y, w, history_b[0]) for w in weights], color=\"r\")\n",
    "plt.plot([history_w[0] for b in biases], biases,\n",
    "         [loss(X, Y, history_w[0], b) for b in biases], color=\"r\")\n",
    "\n",
    "# Display plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30760.866666666665,\n",
       " 25094.377739543488,\n",
       " 20005.675749335347,\n",
       " 15494.760696042225,\n",
       " 11561.632579664138,\n",
       " 8206.291400201075,\n",
       " 5428.737157653043,\n",
       " 3228.9698520200413,\n",
       " 1606.989483302066,\n",
       " 562.7960514991197,\n",
       " 96.38955661120286,\n",
       " 207.76999863831443,\n",
       " 896.9373775804548,\n",
       " 2163.891693437625,\n",
       " 4008.6329462098206,\n",
       " 6431.161135897051,\n",
       " 9431.476262499305,\n",
       " 13009.578326016583,\n",
       " 17165.467326448903,\n",
       " 21899.14326379623]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[loss(X, Y, w, history_b[0]) for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.        ,  -8.8509334 ,  -7.70186679,  -6.55280019,\n",
       "        -5.40373358,  -4.25466698,  -3.10560038,  -1.95653377,\n",
       "        -0.80746717,   0.34159944,   1.49066604,   2.63973264,\n",
       "         3.78879925,   4.93786585,   6.08693246,   7.23599906,\n",
       "         8.38506567,   9.53413227,  10.68319887,  11.83226548])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[history_b[0] for w in weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter to continue...-10 50\n",
      "Enter to close...0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0 0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss on a dataset with two input variables, and the path of gradient descent across it.\n",
    "# Plot surface\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"figure.facecolor\": \"white\"})\n",
    "ax = plt.figure().gca(projection=\"3d\")\n",
    "ax.set_zticklabels(())\n",
    "ax.set_xlabel(\"Weight\", labelpad=20, fontsize=30)\n",
    "ax.set_ylabel(\"Bias\", labelpad=20, fontsize=30)\n",
    "ax.set_zlabel(\"Loss\", labelpad=5, fontsize=30)\n",
    "ax.plot_surface(W, B, L, cmap=cm.gnuplot,\n",
    "                linewidth=0, antialiased=True, color='black')\n",
    "\n",
    "# Mark endpoint\n",
    "plt.plot([history_w[-1]], [history_b[-1]], [history_loss[-1]],\n",
    "         \"gX\", markersize=16)\n",
    "\n",
    "# Display plot in interactive mode\n",
    "plt.ion()\n",
    "plt.show()\n",
    "input(\"Enter to continue...\")\n",
    "\n",
    "# Mark startpoint and path\n",
    "plt.plot([history_w[0]], [history_b[0]], [history_loss[0]], \"wo\")\n",
    "plt.plot(history_w, history_b, history_loss, color=\"w\", linestyle=\"dashed\")\n",
    "\n",
    "input(\"Enter to close...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.084552076271629], [13.113230538013728], [22.843677236816042])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[history_w[-1]], [history_b[-1]], [history_loss[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
