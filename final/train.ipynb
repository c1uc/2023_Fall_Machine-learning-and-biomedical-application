{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:04.604883800Z",
     "start_time": "2024-01-07T08:16:02.632644900Z"
    }
   },
   "id": "7228c4e807601379"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6a11aa1927e04b7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:11.524736Z",
     "start_time": "2024-01-07T08:16:04.605885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/6978 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e888909df504544bb29fb7baad99b5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./sample_dataset/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 6978\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:11.526735800Z",
     "start_time": "2024-01-07T08:16:11.403895200Z"
    }
   },
   "id": "7fda81feaa4b936b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'label'],\n    num_rows: 15000\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "dss = [dataset[\"train\"].filter(lambda example: example[\"label\"] == i) for i in range(15)]\n",
    "\n",
    "dss_ = [d.select(rng.choice(len(d), 1000, replace=True)) for d in dss]\n",
    "\n",
    "dataset = concatenate_datasets(dss_)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:13.052907700Z",
     "start_time": "2024-01-07T08:16:11.411221800Z"
    }
   },
   "id": "c8593e8e2896b925",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 10500\n    })\n    test: Dataset({\n        features: ['image', 'label'],\n        num_rows: 4500\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(0.3)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:13.093965400Z",
     "start_time": "2024-01-07T08:16:13.047909200Z"
    }
   },
   "id": "7fe5b86932e4dbf2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n 'label': 4}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:13.130434200Z",
     "start_time": "2024-01-07T08:16:13.082967700Z"
    }
   },
   "id": "2400f56758e74d86"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset[\"train\"].features\n",
    "original_dataset = dataset.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:13.132951700Z",
     "start_time": "2024-01-07T08:16:13.127901300Z"
    }
   },
   "id": "18a607bd69c31f20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0bca2e1d74c5d37"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "model_name = 'google/vit-base-patch16-224'\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:14.191974500Z",
     "start_time": "2024-01-07T08:16:13.133951700Z"
    }
   },
   "id": "fad3782188a5edba"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor, Resize\n",
    "\n",
    "normalize = Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "size = (\n",
    "    processor.size[\"shortest_edge\"]\n",
    "    if \"shortest_edge\" in processor.size\n",
    "    else (processor.size[\"height\"], processor.size[\"width\"])\n",
    ")\n",
    "# _transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])\n",
    "_transforms = Compose([Resize(size), ToTensor(), normalize])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:14.679563200Z",
     "start_time": "2024-01-07T08:16:14.191974500Z"
    }
   },
   "id": "cee0f766de96db1f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:14.690588300Z",
     "start_time": "2024-01-07T08:16:14.679563200Z"
    }
   },
   "id": "6bd1847220e97e37"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset = dataset.with_transform(transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:14.700432300Z",
     "start_time": "2024-01-07T08:16:14.688590200Z"
    }
   },
   "id": "b6dec7d7fe22626c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'label': 4,\n 'pixel_values': tensor([[[-0.3961, -0.5216, -0.6314,  ..., -0.5373, -0.4902, -0.4353],\n          [-0.4118, -0.5294, -0.6314,  ..., -0.6941, -0.6314, -0.5765],\n          [-0.4196, -0.5373, -0.6314,  ..., -0.8196, -0.7569, -0.6941],\n          ...,\n          [-0.4667, -0.3882, -0.3569,  ..., -0.3020, -0.0667,  0.0980],\n          [-0.4902, -0.3647, -0.3176,  ..., -0.2863, -0.0510,  0.1059],\n          [-0.5373, -0.3412, -0.2863,  ..., -0.2784, -0.0353,  0.1137]],\n \n         [[-0.3961, -0.5216, -0.6314,  ..., -0.5373, -0.4902, -0.4353],\n          [-0.4118, -0.5294, -0.6314,  ..., -0.6941, -0.6314, -0.5765],\n          [-0.4196, -0.5373, -0.6314,  ..., -0.8196, -0.7569, -0.6941],\n          ...,\n          [-0.4667, -0.3882, -0.3569,  ..., -0.3020, -0.0667,  0.0980],\n          [-0.4902, -0.3647, -0.3176,  ..., -0.2863, -0.0510,  0.1059],\n          [-0.5373, -0.3412, -0.2863,  ..., -0.2784, -0.0353,  0.1137]],\n \n         [[-0.3961, -0.5216, -0.6314,  ..., -0.5373, -0.4902, -0.4353],\n          [-0.4118, -0.5294, -0.6314,  ..., -0.6941, -0.6314, -0.5765],\n          [-0.4196, -0.5373, -0.6314,  ..., -0.8196, -0.7569, -0.6941],\n          ...,\n          [-0.4667, -0.3882, -0.3569,  ..., -0.3020, -0.0667,  0.0980],\n          [-0.4902, -0.3647, -0.3176,  ..., -0.2863, -0.0510,  0.1059],\n          [-0.5373, -0.3412, -0.2863,  ..., -0.2784, -0.0353,  0.1137]]])}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:14.729431700Z",
     "start_time": "2024-01-07T08:16:14.702431500Z"
    }
   },
   "id": "29e7c7241baa89d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data collator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f57c8d6223dc7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:15.388410400Z",
     "start_time": "2024-01-07T08:16:14.725433900Z"
    }
   },
   "id": "8cdddb284e7e4760"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:17.886055Z",
     "start_time": "2024-01-07T08:16:15.389412500Z"
    }
   },
   "id": "a385997986f484c9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:17.896503500Z",
     "start_time": "2024-01-07T08:16:17.887056200Z"
    }
   },
   "id": "f0230ee13cad003e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd43d1f3079cab8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([15]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([15, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(device)\n",
    "\n",
    "# model = AutoModelForImageClassification.from_pretrained(\n",
    "#     \"./model_0106_572\",\n",
    "#     num_labels=len(labels),\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "#     ignore_mismatched_sizes=True\n",
    "# ).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T08:16:19.536212600Z",
     "start_time": "2024-01-07T08:16:17.892504700Z"
    }
   },
   "id": "76df463e4dc0f66b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/1640 : < :, Epoch 0.01/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=1640, training_loss=0.8045136031581135, metrics={'train_runtime': 4177.7992, 'train_samples_per_second': 25.133, 'train_steps_per_second': 0.393, 'total_flos': 8.126136800683647e+18, 'train_loss': 0.8045136031581135, 'epoch': 9.98})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sample_logs\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:25:57.624618100Z",
     "start_time": "2024-01-07T08:16:19.528213900Z"
    }
   },
   "id": "518f84fddab7130f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/282 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.8449455499649048,\n 'eval_accuracy': 0.7231111111111111,\n 'eval_runtime': 95.7134,\n 'eval_samples_per_second': 47.015,\n 'eval_steps_per_second': 2.946,\n 'epoch': 9.98}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:27:33.351399200Z",
     "start_time": "2024-01-07T09:25:57.618619200Z"
    }
   },
   "id": "59dd07c4307f2fbf"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/6978 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c130f0621504a4389975d0ccc2833f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['image', 'label'],\n        num_rows: 6978\n    })\n})"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "model_path = 'over_sample_model_epoch_10_' + time.strftime(\"%D-%T\").replace(\"/\", \"-\").replace(\":\", \"-\")\n",
    "trainer.save_model(model_path)\n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=\"./sample_dataset/dataset\")\n",
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:27:39.849488200Z",
     "start_time": "2024-01-07T09:27:33.346398400Z"
    }
   },
   "id": "6b8c6e86fe12db4a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=model_path,\n",
    "    tokenizer=processor,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:27:40.650476Z",
     "start_time": "2024-01-07T09:27:39.835489600Z"
    }
   },
   "id": "88f432f403929103"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def top_k_accuracy(data):\n",
    "    top_1 = 0\n",
    "    top_3 = 0\n",
    "    top_5 = 0\n",
    "    for d in data:\n",
    "        r = classifier(d[\"image\"])\n",
    "        l = id2label[str(d[\"label\"])]\n",
    "        for _ in range(5):\n",
    "            if l == r[_][\"label\"]:\n",
    "                if _ < 1:\n",
    "                    top_1 += 1\n",
    "                if _ < 3:\n",
    "                    top_3 += 1\n",
    "                if _ < 5:\n",
    "                    top_5 += 1\n",
    "                break\n",
    "                \n",
    "    print(f\"top 1: {top_1 / len(data)}\")\n",
    "    print(f\"top 3: {top_3 / len(data)}\")\n",
    "    print(f\"top 5: {top_5 / len(data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:27:40.672008700Z",
     "start_time": "2024-01-07T09:27:40.652482600Z"
    }
   },
   "id": "182b70001437326f",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Code\\bioML\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1: 0.7231111111111111\n",
      "top 3: 0.938\n",
      "top 5: 0.9686666666666667\n"
     ]
    }
   ],
   "source": [
    "top_k_accuracy(original_dataset[\"test\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:30:33.257120900Z",
     "start_time": "2024-01-07T09:27:40.657010Z"
    }
   },
   "id": "80249066cc044c43",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 1: 0.5911435941530524\n",
      "top 3: 0.8306104901117799\n",
      "top 5: 0.8998280309544282\n"
     ]
    }
   ],
   "source": [
    "top_k_accuracy(ds[\"train\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:35:26.382154200Z",
     "start_time": "2024-01-07T09:30:33.253120500Z"
    }
   },
   "id": "b0deca2980e2dcd4",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T09:35:26.383155800Z",
     "start_time": "2024-01-07T09:35:26.378156200Z"
    }
   },
   "id": "350b19188da86e1b",
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
